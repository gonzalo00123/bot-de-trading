import pandas as pd
import asyncio
import logging
from BinaryOptionsToolsV2.pocketoption import PocketOptionAsync
import time
import unicodedata
import os
from collections import Counter
from collections import defaultdict
from typing import Union, Dict
import sys
import numpy as np
import joblib
import pickle
import json
import traceback
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
import io
import types
from datetime import datetime, timedelta
from typing import Tuple


sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

logging.basicConfig(
    encoding='utf-8',
    level=logging.INFO
)
# --- CLASES PARA REPLICAR PINE SCRIPT TYPES ---
class Alerts:
    swingBullishBOS: bool = False
    swingBearishBOS: bool = False
    swingBullishCHoCH: bool = False
    swingBearishCHoCH: bool = False
    internalBullishBOS: bool = False
    internalBearishBOS: bool = False
    internalBullishCHoCH: bool = False
    internalBearishCHoCH: bool = False
    bullishFairValueGap: bool = False
    bearishFairValueGap: bool = False
    swingBullishOrderBlock: bool = False
    swingBearishOrderBlock: bool = False
    internalBullishOrderBlock: bool = False
    internalBearishOrderBlock: bool = False
    equalHighs: bool = False
    equalLows: bool = False

class TrailingExtremes:
    swingHigh: float = float('nan')
    swingLow: float = float('nan')
    internalHigh: float = float('nan')
    internalLow: float = float('nan')

class Pivot:
    high: float = float('nan')
    low: float = float('nan')
    indexHigh: int = -1
    indexLow: int = -1

class OrderBlock:
    def __init__(self, index: int = -1, level: float = float('nan'),
                 is_bullish: bool = False, is_swing: bool = False,
                 is_mitigated: bool = False):
        self.index = index
        self.level = level
        self.is_bullish = is_bullish
        self.is_swing = is_swing
        self.is_mitigated = is_mitigated

class FairValueGap:
    def __init__(self, index: int = -1, level: float = float('nan'),
                 is_bullish: bool = False, is_mitigated: bool = False):
        self.index = index
        self.level = level
        self.is_bullish = is_bullish
        self.is_mitigated = is_mitigated
# --- CLASE PRINCIPAL DEL INDICADOR ---
class SmartMoneyConcepts:
    def __init__(self, data_1m, data_5m):
        """
        Inicializa el analizador de Smart Money Concepts.
        
        Args:
            data_1m (pd.DataFrame): DataFrame con datos de timeframe 1M
            data_5m (pd.DataFrame): DataFrame con datos de timeframe 5M
        """
        self.data_1m = data_1m
        self.data_5m = data_5m
        self.estructura_smc = {
            "bos": None,
            "choch": None,
            "ob_bull": [],
            "ob_bear": [],
            "fvg_bull": [],
            "fvg_bear": [],
            "current_trend": None,
            "last_update": datetime.now().isoformat()
        }
        self.señales_smc = []
        self.orderblocks = []
        self.fair_value_gaps = []

    def analyze(self, ignorar_proximidad=False):
        """
        Método principal que analiza ambos timeframes.
        
        Args:
            ignorar_proximidad (bool): Si es True, no filtra por proximidad al precio actual
        """
        try:
            if self.data_1m is None or self.data_1m.empty or self.data_5m is None or self.data_5m.empty:
                logging.warning("Datos insuficientes para análisis SMC")
                return {
                    "estructura": self.estructura_smc,
                    "señales": []
                }

            # Reset de señales
            self.señales_smc = []
            self.orderblocks = []
            self.fair_value_gaps = []
            
            # Analizar ambos timeframes
            señales_1m = self.analyze_smc(self.data_1m, '1m', ignorar_proximidad)
            señales_5m = self.analyze_smc(self.data_5m, '5m', ignorar_proximidad)
            
            # Determinar tendencia actual
            self._determine_current_trend()
            
            # Actualizar estructura final
            self._update_estructura()
            
            # Combinar todas las señales
            todas_señales = señales_1m + señales_5m
            
            return {
                "estructura": self.estructura_smc,
                "señales": todas_señales
            }

        except Exception as e:
            logging.error(f"Error en analyze SMC: {e}")
            return {
                "estructura": self.estructura_smc,
                "señales": []
            }

    def analyze_smc(self, data, timeframe, ignorar_proximidad=False):
        """
        Analiza los datos para un timeframe específico.
        
        Args:
            data (pd.DataFrame): DataFrame con los datos a analizar
            timeframe (str): Timeframe de los datos ('1m' o '5m')
            ignorar_proximidad (bool): Si es True, no filtra por proximidad al precio actual
        
        Returns:
            list: Lista de señales detectadas
        """
        try:
            if data is None or data.empty:
                logging.warning(f"Datos insuficientes para análisis SMC en {timeframe}")
                return []

            current_price = data['close'].iloc[-1]

            # Detectar estructuras
            self.detect_orderblocks(data, timeframe)
            self.detect_fair_value_gaps(data, timeframe)
            self.detect_bos_choch(data, timeframe, ignorar_proximidad)
            
            # Convertir detecciones a señales
            self._convert_to_signals(current_price, timeframe)

            return self.señales_smc

        except Exception as e:
            logging.error(f"Error en analyze_smc para {timeframe}: {e}")
            return []

    def detect_orderblocks(self, data, timeframe):
        """Detecta Order Blocks en los datos"""
        try:
            lookback = 100 if timeframe == '5m' else 200
            data = data.tail(lookback)
            
            for i in range(3, len(data)-1):
                high = data['high'].iloc[i]
                low = data['low'].iloc[i]
                close = data['close'].iloc[i]
                
                # Detectar OB alcista
                if (close > data['high'].iloc[i-1] and 
                    low < data['low'].iloc[i-1:i+1].min()):
                    self.orderblocks.append({
                        "tipo": "alcista",
                        "precio": low,
                        "tiempo": data.index[i],
                        "timeframe": timeframe
                    })
                
                # Detectar OB bajista
                if (close < data['low'].iloc[i-1] and 
                    high > data['high'].iloc[i-1:i+1].max()):
                    self.orderblocks.append({
                        "tipo": "bajista",
                        "precio": high,
                        "tiempo": data.index[i],
                        "timeframe": timeframe
                    })
                    
        except Exception as e:
            logging.error(f"Error en detect_orderblocks para {timeframe}: {e}")

    def detect_fair_value_gaps(self, data, timeframe):
        """Detecta Fair Value Gaps en los datos"""
        try:
            lookback = 100 if timeframe == '5m' else 200
            data = data.tail(lookback)
            
            for i in range(1, len(data)-1):
                # FVG alcista
                if data['low'].iloc[i+1] > data['high'].iloc[i-1]:
                    self.fair_value_gaps.append({
                        "tipo": "alcista",
                        "nivel_superior": data['low'].iloc[i+1],
                        "nivel_inferior": data['high'].iloc[i-1],
                        "tiempo": data.index[i],
                        "timeframe": timeframe
                    })
                
                # FVG bajista
                if data['high'].iloc[i+1] < data['low'].iloc[i-1]:
                    self.fair_value_gaps.append({
                        "tipo": "bajista",
                        "nivel_superior": data['low'].iloc[i-1],
                        "nivel_inferior": data['high'].iloc[i+1],
                        "tiempo": data.index[i],
                        "timeframe": timeframe
                    })
                    
        except Exception as e:
            logging.error(f"Error en detect_fair_value_gaps para {timeframe}: {e}")

    def detect_bos_choch(self, data, timeframe, ignorar_proximidad=False):
        """
        Detecta Break of Structure y Change of Character
        
        Args:
            data (pd.DataFrame): DataFrame con los datos a analizar
            timeframe (str): Timeframe de los datos ('1m' o '5m')
            ignorar_proximidad (bool): Si es True, no filtra por proximidad al precio actual
        """
        try:
            lookback = 100 if timeframe == '5m' else 200
            data = data.tail(lookback)
            current_price = data['close'].iloc[-1]
            
            # Configurar filtro de proximidad
            max_distance = float('inf') if ignorar_proximidad else current_price * 0.005
            
            for i in range(3, len(data)-3):
                # Detectar BOS alcista
                if (data['high'].iloc[i] > data['high'].iloc[i-1:i].max() and
                    data['high'].iloc[i] > data['high'].iloc[i+1:i+3].max()):
                    
                    nivel = data['high'].iloc[i]
                    if ignorar_proximidad or abs(nivel - current_price) <= max_distance:
                        self.estructura_smc["bos"] = {
                            "tipo": "alcista",
                            "nivel": nivel,
                            "tiempo": data.index[i],
                            "timeframe": timeframe,
                            "proximidad": abs(nivel - current_price) / current_price
                        }
                
                # Detectar BOS bajista
                elif (data['low'].iloc[i] < data['low'].iloc[i-1:i].min() and
                    data['low'].iloc[i] < data['low'].iloc[i+1:i+3].min()):
                    
                    nivel = data['low'].iloc[i]
                    if ignorar_proximidad or abs(nivel - current_price) <= max_distance:
                        self.estructura_smc["bos"] = {
                            "tipo": "bajista",
                            "nivel": nivel,
                            "tiempo": data.index[i],
                            "timeframe": timeframe,
                            "proximidad": abs(nivel - current_price) / current_price
                        }
                
                # Detectar CHoCH
                if self.estructura_smc["bos"] and i > 5:
                    # CHoCH bajista
                    if (self.estructura_smc["bos"]["tipo"] == "alcista" and
                        data['low'].iloc[i] < data['low'].iloc[i-5:i].min()):
                        
                        nivel = data['low'].iloc[i]
                        if ignorar_proximidad or abs(nivel - current_price) <= max_distance:
                            self.estructura_smc["choch"] = {
                                "tipo": "bajista",
                                "nivel": nivel,
                                "tiempo": data.index[i],
                                "timeframe": timeframe,
                                "proximidad": abs(nivel - current_price) / current_price
                            }
                    
                    # CHoCH alcista
                    elif (self.estructura_smc["bos"]["tipo"] == "bajista" and
                        data['high'].iloc[i] > data['high'].iloc[i-5:i].max()):
                        
                        nivel = data['high'].iloc[i]
                        if ignorar_proximidad or abs(nivel - current_price) <= max_distance:
                            self.estructura_smc["choch"] = {
                                "tipo": "alcista",
                                "nivel": nivel,
                                "tiempo": data.index[i],
                                "timeframe": timeframe,
                                "proximidad": abs(nivel - current_price) / current_price
                            }
                        
        except Exception as e:
            logging.error(f"Error en detect_bos_choch para {timeframe}: {e}")

    def _convert_to_signals(self, current_price, timeframe):
        """Convierte todas las detecciones en señales"""
        try:
            # Convertir OBs a señales
            for ob in self.orderblocks:
                if ob["timeframe"] != timeframe:
                    continue
                    
                distance = abs(ob["precio"] - current_price)
                proximity_score = max(0, 1 - distance / (current_price * 0.002))
                
                señal = {
                    "Type": "Buy" if ob["tipo"] == "alcista" else "Sell",
                    "Level": ob["precio"],
                    "timestamp": ob["tiempo"].isoformat(),
                    "Categoria": "OrderBlock",
                    "Strategy": f"SMC_OB_{timeframe}",
                    "Confidence": "Alta" if proximity_score > 0.7 else "Media",
                    "Reason": f"OrderBlock {ob['tipo']} detectado en {timeframe}",
                    "OrderBlockRelacionado": True,
                    "Esquema": "OB_SMC",
                    "Nombre": f"OrderBlock {ob['tipo']} {timeframe}",
                    "proximity_score": proximity_score
                }
                self.señales_smc.append(señal)

            # Convertir FVGs a señales
            for fvg in self.fair_value_gaps:
                if fvg["timeframe"] != timeframe:
                    continue
                    
                mid_price = (fvg["nivel_superior"] + fvg["nivel_inferior"]) / 2
                distance = abs(mid_price - current_price)
                proximity_score = max(0, 1 - distance / (current_price * 0.002))
                
                señal = {
                    "Type": "Buy" if fvg["tipo"] == "alcista" else "Sell",
                    "Level": mid_price,
                    "timestamp": fvg["tiempo"].isoformat(),
                    "Categoria": "FVG",
                    "Strategy": f"SMC_FVG_{timeframe}",
                    "Confidence": "Alta" if proximity_score > 0.7 else "Media",
                    "Reason": f"Fair Value Gap {fvg['tipo']} detectado en {timeframe}",
                    "OrderBlockRelacionado": False,
                    "Esquema": "FVG_SMC",
                    "Nombre": f"FVG {fvg['tipo']} {timeframe}",
                    "proximity_score": proximity_score,
                    "nivel_superior": fvg["nivel_superior"],
                    "nivel_inferior": fvg["nivel_inferior"]
                }
                self.señales_smc.append(señal)

            # Convertir BOS/CHoCH a señales si existen
            if self.estructura_smc["bos"] and self.estructura_smc["bos"]["timeframe"] == timeframe:
                bos = self.estructura_smc["bos"]
                distance = abs(bos["nivel"] - current_price)
                proximity_score = max(0, 1 - distance / (current_price * 0.002))
                
                señal = {
                    "Type": "Buy" if bos["tipo"] == "alcista" else "Sell",
                    "Level": bos["nivel"],
                    "timestamp": bos["tiempo"].isoformat(),
                    "Categoria": "Estructura",
                    "Strategy": f"SMC_BOS_{timeframe}",
                    "Confidence": "Alta",
                    "Reason": f"Break of Structure {bos['tipo']} en {timeframe}",
                    "OrderBlockRelacionado": False,
                    "Esquema": "BOS",
                    "Nombre": f"BOS {bos['tipo']} {timeframe}",
                    "proximity_score": proximity_score
                }
                self.señales_smc.append(señal)

            if self.estructura_smc["choch"] and self.estructura_smc["choch"]["timeframe"] == timeframe:
                choch = self.estructura_smc["choch"]
                distance = abs(choch["nivel"] - current_price)
                proximity_score = max(0, 1 - distance / (current_price * 0.002))
                
                señal = {
                    "Type": "Buy" if choch["tipo"] == "alcista" else "Sell",
                    "Level": choch["nivel"],
                    "timestamp": choch["tiempo"].isoformat(),
                    "Categoria": "Estructura",
                    "Strategy": f"SMC_CHOCH_{timeframe}",
                    "Confidence": "Alta",
                    "Reason": f"Change of Character {choch['tipo']} en {timeframe}",
                    "OrderBlockRelacionado": False,
                    "Esquema": "CHoCH",
                    "Nombre": f"CHoCH {choch['tipo']} {timeframe}",
                    "proximity_score": proximity_score
                }
                self.señales_smc.append(señal)
                
        except Exception as e:
            logging.error(f"Error en convert_to_signals para {timeframe}: {e}")

    def _determine_current_trend(self):
        """Determina la tendencia actual basada en el análisis SMC"""
        try:
            if not self.data_5m.empty:
                sma20 = self.data_5m['close'].rolling(window=20).mean()
                current_price = self.data_5m['close'].iloc[-1]
                
                if current_price > sma20.iloc[-1]:
                    self.estructura_smc["current_trend"] = "Bullish"
                else:
                    self.estructura_smc["current_trend"] = "Bearish"

                # Validar con estructura BOS/CHoCH
                if self.estructura_smc["choch"]:
                    if self.estructura_smc["choch"]["tipo"] == "alcista":
                        self.estructura_smc["current_trend"] = "Bullish"
                    else:
                        self.estructura_smc["current_trend"] = "Bearish"
                elif self.estructura_smc["bos"]:
                    if self.estructura_smc["bos"]["tipo"] == "alcista":
                        self.estructura_smc["current_trend"] = "Bullish"
                    else:
                        self.estructura_smc["current_trend"] = "Bearish"

        except Exception as e:
            logging.error(f"Error en determine_current_trend: {e}")
            self.estructura_smc["current_trend"] = None

    def _update_estructura(self):
        """Actualiza la estructura SMC"""
        try:
            current_price = self.data_1m['close'].iloc[-1]
            max_distance = current_price * 0.005  # 0.5% del precio actual
            
            # Actualizar OBs
            self.estructura_smc["ob_bull"] = [
                ob for ob in self.orderblocks 
                if ob["tipo"] == "alcista" and 
                abs(ob["precio"] - current_price) <= max_distance
            ]
            self.estructura_smc["ob_bear"] = [
                ob for ob in self.orderblocks 
                if ob["tipo"] == "bajista" and 
                abs(ob["precio"] - current_price) <= max_distance
            ]
            
            # Actualizar FVGs
            self.estructura_smc["fvg_bull"] = [
                fvg for fvg in self.fair_value_gaps 
                if fvg["tipo"] == "alcista"
            ]
            self.estructura_smc["fvg_bear"] = [
                fvg for fvg in self.fair_value_gaps 
                if fvg["tipo"] == "bajista"
            ]
            
            # Actualizar timestamp
            self.estructura_smc["last_update"] = datetime.now().isoformat()
            
        except Exception as e:
            logging.error(f"Error en update_estructura: {e}")
        
def guardar_diagnostico(señal, informacion_adicional=None, filename="diagnostico_actual.json"):
    """
    Guarda el diagnóstico de la señal en un archivo JSON.

    Args:
        señal (dict): El diccionario que contiene el diagnóstico de la señal.
        informacion_adicional (dict, optional): Información adicional para guardar junto con el diagnóstico. Defaults to None.
        filename (str, optional): El nombre del archivo en el que se guardará el diagnóstico. Defaults to "diagnostico_actual.json".
    """
    try:
        datos_a_guardar = {
            "diagnostico": señal,
            "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S")
        }
        if informacion_adicional:
            datos_a_guardar["info_extra"] = informacion_adicional

        with open(filename, "w", encoding="utf-8") as f:
            json.dump(datos_a_guardar, f, indent=2, ensure_ascii=False)
        print(f" Diagnóstico guardado en {filename}")
        
    except Exception as e:
        print(f" Error al guardar diagnóstico: {e}")

os.environ["LOKY_MAX_CPU_COUNT"] = "6"
# Cargar el modelo
# Cargar modelos y recursos
modelo_signal = joblib.load('modelo_lightgbm.pkl')
modelo_niveles = joblib.load('modelo_niveles.pkl')
modelo_direccion = joblib.load('modelo_direccion_mercado.pkl')  # Cargar el nuevo modelo
scaler_direccion = joblib.load('scaler_direccion.pkl')        # Cargar el scaler
label_encoders_direccion = joblib.load('label_encoders_direccion.pkl')  # Cargar los label encoders

logging.basicConfig(
    level=logging.INFO, # Cambia a logging.DEBUG para más verbosidad
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("trading_bot.log"), # Guarda logs en un archivo
        logging.StreamHandler() # Muestra logs en consola también
    ]
)

# Funciones de carga de modelos (manteniendo la estructura existente)
def cargar_modelo_niveles(path="modelo_niveles.pkl"):
    try:
        modelo = joblib.load(path)
        print("Modelo de niveles cargado correctamente.")
        return modelo
    except Exception as e:
        print(f"Error al cargar el modelo de niveles: {e}")
        return None

def cargar_modelo_lightgbm(path="modelo_lightgbm.pkl"):
    try:
        modelo = joblib.load(path)
        logging.info("Modelo LightGBM cargado correctamente.")
        return modelo
    except Exception as e:
        logging.error(f"Error al cargar el modelo LightGBM: {e}")
        return None


def predecir_direccion_precio(self, data=None):
    """
    Predice la dirección del precio basándose en indicadores técnicos.
    Retorna 'Buy', 'Sell' o None según la predicción.
    
    Parameters:
    -----------
    data : pd.DataFrame, opcional
        DataFrame con datos OHLC. Si es None, se usa self.data_1m
        
    Returns:
    --------
    str
        'Buy', 'Sell' o None según la dirección predicha
    """
    try:
        # Si no se proporcionan datos, usar los datos internos de 1 minuto
        if data is None:
            if self.data_1m is None or len(data) < 100:  # Aumentado a 100 para permitir SMA de 100 períodos
                logging.warning("Datos insuficientes para predecir dirección")
                return None
            data = ()
        
        # Asegurarnos de tener suficientes datos
        if len(data) < 100:  # Aumentado a 100 para permitir SMA de 100 períodos
            logging.warning("Datos insuficientes para predecir dirección")
            return None
            
        # Calcular indicadores técnicos
        # Calcular indicadores técnicos
        # 1. RSI con periodo 10 (según la captura)
        data['rsi'] = self.calcular_rsi(data['close'], periodo=10)
        
        # 2. SMA blanca de 100 y SMA verde fluorescente de 20
        data['sma_100'] = data['close'].rolling(window=100).mean()  # SMA blanca de 100 períodos
        data['sma_20'] = data['close'].rolling(window=20).mean()    # SMA verde fluorescente de 20 períodos
        
        # 3. ADX con periodo 5.5 (según la captura)
        data['adx'] = self.calcular_adx(data, periodo=5)
        
        # 4. Bandas de Bollinger (mantenidas del código original)
        data['sma20'] = data['close'].rolling(window=20).mean()
        data['std20'] = data['close'].rolling(window=20).std()
        data['bband_upper'] = data['sma20'] + (data['std20'] * 2)
        data['bband_lower'] = data['sma20'] - (data['std20'] * 2)
        
        # Obtener los últimos valores para tomar la decisión
        ultimo_indice = len(data) - 1
        rsi = data['rsi'].iloc[ultimo_indice]
        sma_20 = data['sma_20'].iloc[ultimo_indice]
        sma_100 = data['sma_100'].iloc[ultimo_indice]
        adx = data['adx'].iloc[ultimo_indice]
        precio_actual = data['close'].iloc[ultimo_indice]
        bband_upper = data['bband_upper'].iloc[ultimo_indice]
        bband_lower = data['bband_lower'].iloc[ultimo_indice]
        
        # Sistema de puntuación para tomar decisión
        puntuacion = 0
        
        # RSI: Sobrecompra/Sobreventa
        if rsi > 70:
            puntuacion -= 2  # Sobrecompra, posible bajada
        elif rsi < 30:
            puntuacion += 2  # Sobreventa, posible subida
        
        # Media móvil: Cruce alcista/bajista usando SMA
        if sma_20 > sma_100:
            puntuacion += 1  # Cruce alcista
        else:
            puntuacion -= 1  # Cruce bajista
            
        # ADX: Fuerza de la tendencia
        if adx > 25:
            # Si hay fuerte tendencia, reforzar la dirección actual
            if sma_20 > sma_100:
                puntuacion += 1  # Reforzar tendencia alcista
            else:
                puntuacion -= 1  # Reforzar tendencia bajista
            
        # Bandas de Bollinger: Posición del precio
        if precio_actual > bband_upper:
            puntuacion -= 1  # Sobrecompra
        elif precio_actual < bband_lower:
            puntuacion += 1  # Sobreventa
            
        # Determinar dirección según la puntuación
        if puntuacion >= 2:
            return "Buy"
        elif puntuacion <= -2:
            return "Sell"
        else:
            return None  # Sin dirección clara
            
    except Exception as e:
        logging.error(f"Error al predecir dirección del precio: {str(e)}")
        return None
        
def calcular_rsi(serie, periodo=10):
    """Calcula el RSI para una serie de precios."""
    try:
        delta = serie.diff()
        ganancia = delta.clip(lower=0)
        perdida = -delta.clip(upper=0)
        avg_ganancia = ganancia.rolling(window=periodo).mean()
        avg_perdida = perdida.rolling(window=periodo).mean()
        rs = avg_ganancia / avg_perdida
        rsi = 100 - (100 / (1 + rs))
        return rsi
    except Exception as e:
        logging.error(f"Error al calcular RSI: {str(e)}")
        return pd.Series([50] * len(serie))  # Valor neutro

def calcular_adx(data, periodo=5):
    """
    Calcula el ADX (Average Directional Index) con periodo dado.
    data: DataFrame con columnas ['high', 'low', 'close']
    """
    try:
        data = data.copy()
        data['tr1'] = abs(data['high'] - data['low'])
        data['tr2'] = abs(data['high'] - data['close'].shift(1))
        data['tr3'] = abs(data['low'] - data['close'].shift(1))
        data['tr'] = data[['tr1', 'tr2', 'tr3']].max(axis=1)
        data['plus_dm'] = (data['high'] - data['high'].shift(1)).clip(lower=0)
        data['minus_dm'] = (data['low'].shift(1) - data['low']).clip(lower=0)
        data['plus_dm'] = data['plus_dm'].where(data['plus_dm'] > data['minus_dm'], 0.0)
        data['minus_dm'] = data['minus_dm'].where(data['minus_dm'] > data['plus_dm'], 0.0)
        data['atr'] = data['tr'].rolling(window=periodo).mean()
        data['plus_di'] = 100 * (data['plus_dm'].rolling(window=periodo).mean() / data['atr'])
        data['minus_di'] = 100 * (data['minus_dm'].rolling(window=periodo).mean() / data['atr'])
        data['dx'] = 100 * abs(data['plus_di'] - data['minus_di']) / (data['plus_di'] + data['minus_di'])
        adx = data['dx'].rolling(window=periodo).mean()
        return adx
    except Exception as e:
        logging.error(f"Error al calcular ADX: {str(e)}")
        return pd.Series([20] * len(data))  # Valor neutro para ADX

def predecir_direccion_precio(data_1m): 
    """
    Predice la dirección del precio basándose en indicadores técnicos.
    Retorna 'Buy', 'Sell' o None según la predicción.
    """
    try:
        if data_1m is None or len(data_1m) < 100:
            logging.warning("Datos insuficientes para predecir dirección")
            return None
        data = data_1m.copy()
        data['rsi'] = calcular_rsi(data['close'], periodo=10)
        data['sma_100'] = data['close'].rolling(window=100).mean()
        data['sma_20'] = data['close'].rolling(window=20).mean()
        data['adx'] = calcular_adx(data, periodo=5)
        data['sma20'] = data['close'].rolling(window=20).mean()
        data['std20'] = data['close'].rolling(window=20).std()
        data['bband_upper'] = data['sma20'] + (data['std20'] * 2)
        data['bband_lower'] = data['sma20'] - (data['std20'] * 2)
        ultimo = data.iloc[-1]
        puntuacion = 0
        # RSI
        if ultimo['rsi'] > 70:
            puntuacion -= 2
        elif ultimo['rsi'] < 30:
            puntuacion += 2
        # SMA
        if ultimo['sma_20'] > ultimo['sma_100']:
            puntuacion += 1
        else:
            puntuacion -= 1
        # ADX
        if ultimo['adx'] > 25:
            if ultimo['sma_20'] > ultimo['sma_100']:
                puntuacion += 1
            else:
                puntuacion -= 1
        # Bollinger
        if ultimo['close'] > ultimo['bband_upper']:
            puntuacion -= 1
        elif ultimo['close'] < ultimo['bband_lower']:
            puntuacion += 1
        if puntuacion >= 2:
            return "Buy"
        elif puntuacion <= -2:
            return "Sell"
        else:
            return None
    except Exception as e:
        logging.error(f"Error al predecir dirección del precio: {str(e)}")
        return None
def _detectar_bisi(data, current_price, proximidad_relativa, proximidad_absoluta, ignorar_proximidad, max_patrones):
    bisi_signals = []
    for i in range(len(data) - 1, 2, -1):
        if len(bisi_signals) >= max_patrones:
            break
        vela_1 = data.iloc[i - 2]
        vela_2 = data.iloc[i - 1]
        vela_3 = data.iloc[i]
        timestamp_vela_2 = data.index[i - 1]
        if (vela_1['close'] > vela_1['open'] and vela_3['close'] < vela_3['open'] and
            vela_2['low'] > max(vela_1['high'], vela_3['high'])):
            nivel_bisi = vela_2['low']
            if ignorar_proximidad or abs(current_price - nivel_bisi) <= min(proximidad_relativa, proximidad_absoluta):
                bisi_signals.append({
                    'Type': 'Sell', 'Level': nivel_bisi, 'Reason': 'BISI', 'Esquema': 'BISI',
                    'DireccionEstructural': 'bajista', 'TipoEstructura': 'reversion',
                    'Confidence': 'Alta', 'Categoria': 'Imbalance', 'Strategy': 'BISI_M1',
                    'Nombre': 'BISI en 1M', 'OrderBlockRelacionado': False,
                    'Timestamp': timestamp_vela_2, 'DistanciaAlPrecioActual': abs(current_price - nivel_bisi)
                })
    return bisi_signals

def _detectar_sibi(data, current_price, proximidad_relativa, proximidad_absoluta, ignorar_proximidad, max_patrones):
    sibi_signals = []
    for i in range(len(data) - 1, 2, -1):
        if len(sibi_signals) >= max_patrones:
            break
        vela_1 = data.iloc[i - 2]
        vela_2 = data.iloc[i - 1]
        vela_3 = data.iloc[i]
        timestamp_vela_2 = data.index[i - 1]
        if (vela_1['close'] < vela_1['open'] and vela_3['close'] > vela_3['open'] and
            vela_2['high'] < min(vela_1['low'], vela_3['low'])):
            nivel_sibi = min(vela_1['low'], vela_3['low'])
            if ignorar_proximidad or abs(current_price - nivel_sibi) <= min(proximidad_relativa, proximidad_absoluta):
                sibi_signals.append({
                    'Type': 'Buy', 'Level': nivel_sibi, 'Reason': 'SIBI', 'Esquema': 'SIBI',
                    'DireccionEstructural': 'alcista', 'TipoEstructura': 'reversion',
                    'Confidence': 'Alta', 'Categoria': 'Imbalance', 'Strategy': 'SIBI_M1',
                    'Nombre': 'SIBI en 1M', 'OrderBlockRelacionado': False,
                    'Timestamp': timestamp_vela_2, 'DistanciaAlPrecioActual': abs(current_price - nivel_sibi)
                })
    return sibi_signals
def _detectar_fvg_individual(data, current_price, proximidad_relativa, proximidad_absoluta, ignorar_proximidad, max_patrones):
    fvg_signals = []
    for i in range(len(data) - 1, 2, -1):
        if len(fvg_signals) >= max_patrones:
            break
        vela_1 = data.iloc[i - 2]
        vela_2 = data.iloc[i - 1]
        vela_3 = data.iloc[i]
        timestamp_vela_2 = data.index[i - 1]
        if vela_2['low'] > vela_1['high'] and vela_2['low'] > vela_3['high']:
            nivel_fvg = vela_2['low']
            if ignorar_proximidad or abs(current_price - nivel_fvg) <= min(proximidad_relativa, proximidad_absoluta):
                fvg_signals.append({
                    'Type': 'Buy', 'Level': nivel_fvg, 'Reason': 'FVG', 'Esquema': 'FVG',
                    'DireccionEstructural': 'alcista', 'TipoEstructura': 'continuacion',
                    'Confidence': 'Media', 'Categoria': 'Imbalance', 'Strategy': 'FVG_M1',
                    'Nombre': 'FVG alcista en 1M', 'OrderBlockRelacionado': False,
                    'Timestamp': timestamp_vela_2, 'DistanciaAlPrecioActual': abs(current_price - nivel_fvg)
                })
        elif vela_2['high'] < vela_1['low'] and vela_2['high'] < vela_3['low']:
            nivel_fvg = vela_2['high']
            if ignorar_proximidad or abs(current_price - nivel_fvg) <= min(proximidad_relativa, proximidad_absoluta):
                fvg_signals.append({
                    'Type': 'Sell', 'Level': nivel_fvg, 'Reason': 'FVG', 'Esquema': 'FVG',
                    'DireccionEstructural': 'bajista', 'TipoEstructura': 'continuacion',
                    'Confidence': 'Media', 'Categoria': 'Imbalance', 'Strategy': 'FVG_M1',
                    'Nombre': 'FVG bajista en 1M', 'OrderBlockRelacionado': False,
                    'Timestamp': timestamp_vela_2, 'DistanciaAlPrecioActual': abs(current_price - nivel_fvg)
                })
    return fvg_signals

def detectar_fvg(data, max_patrones=5, ignorar_proximidad=True):
    all_signals = []
    if len(data) < 3:
        return all_signals
    current_price_1m = data['close'].iloc[-1]
    proximidad_relativa = current_price_1m * 0.005
    proximidad_absoluta = 0.5
    all_signals.extend(_detectar_fvg_individual(data, current_price_1m, proximidad_relativa, proximidad_absoluta, ignorar_proximidad, max_patrones))
    all_signals.extend(_detectar_bisi(data, current_price_1m, proximidad_relativa, proximidad_absoluta, ignorar_proximidad, max_patrones))
    all_signals.extend(_detectar_sibi(data, current_price_1m, proximidad_relativa, proximidad_absoluta, ignorar_proximidad, max_patrones))
    
    if not ignorar_proximidad:
        all_signals.sort(key=lambda x: x['DistanciaAlPrecioActual'])
    else:
        all_signals.sort(key=lambda x: x['Timestamp'], reverse=True)
    return all_signals[:max_patrones]

def detectar_bos_choch(data, tendencia_actual=None, ventana_estructura=10, confirmacion=True,
                      max_patrones=5, ignorar_proximidad=False):
    """
    Detecta estructuras BOS (Break of Structure) y CHoCH (Change of Character).
    
    Args:
        data (pd.DataFrame): DataFrame con datos OHLCV
        tendencia_actual (str, optional): Tendencia actual ('Alcista', 'Bajista', 'Lateral')
        ventana_estructura (int): Número de velas para identificar swings
        confirmacion (bool): Requiere confirmación de cierre
        max_patrones (int): Número máximo de patrones a detectar
        ignorar_proximidad (bool): Si es True, no filtra por proximidad al precio actual
    
    Returns:
        dict: Resultados de la detección con señales y resumen
    """
    try:
        resultados = {
            "señales": [],
            "bos": [],
            "choch": [],
            "resumen": "",
            "ultima_actualizacion": datetime.now().isoformat()
        }

        if data is None or len(data) < max(ventana_estructura * 2 + 1, 5):
            return resultados

        df = data.copy()
        current_price = df['close'].iloc[-1]
        
        # 1. Inferir tendencia si no se proporciona
        if tendencia_actual is None:
            tendencia_actual = _inferir_tendencia(df)

        # 2. Identificar Swings
        df = _identificar_swings(df, ventana_estructura)

        # 3. Detectar patrones
        patrones_encontrados = 0
        max_distance = float('inf') if ignorar_proximidad else current_price * 0.005

        for i in range(len(df) - 1, ventana_estructura, -1):
            if patrones_encontrados >= max_patrones:
                break

            señal = _analizar_patron(df, i, tendencia_actual, confirmacion, 
                                   max_distance, current_price)
            
            if señal:
                if señal["Reason"] == "BOS":
                    resultados["bos"].append(señal)
                else:
                    resultados["choch"].append(señal)
                    
                resultados["señales"].append(señal)
                patrones_encontrados += 1

        # 4. Ordenar y generar resumen
        resultados["señales"].sort(key=lambda x: x['Timestamp'], reverse=True)
        resultados["resumen"] = _generar_resumen(resultados["señales"])

        return resultados

    except Exception as e:
        logging.error(f"Error en detectar_bos_choch: {e}")
        return {
            "señales": [],
            "bos": [],
            "choch": [],
            "resumen": f"Error: {str(e)}",
            "ultima_actualizacion": datetime.now().isoformat()
        }

def _inferir_tendencia(df):
    """Infiere la tendencia actual del mercado"""
    ventana_tendencia = min(20, len(df) // 4)
    if ventana_tendencia < 5:
        return "Lateral"
        
    primeras_high = df['high'].iloc[-ventana_tendencia*2:-ventana_tendencia].max()
    ultimas_high = df['high'].iloc[-ventana_tendencia:].max()
    primeras_low = df['low'].iloc[-ventana_tendencia*2:-ventana_tendencia].min()
    ultimas_low = df['low'].iloc[-ventana_tendencia:].min()

    if ultimas_high > primeras_high and ultimas_low > primeras_low:
        return "Alcista"
    elif ultimas_high < primeras_high and ultimas_low < primeras_low:
        return "Bajista"
    return "Lateral"

def _identificar_swings(df, ventana):
    """Identifica los swing points en el DataFrame"""
    df['swing_high'] = False
    df['swing_low'] = False
    ventana_efectiva = max(1, min(ventana, (len(df) - 1) // 2))

    for i in range(ventana_efectiva, len(df) - ventana_efectiva):
        # Swing high
        if all(df['high'].iloc[i] > df['high'].iloc[i-j] for j in range(1, ventana_efectiva + 1)) and \
           all(df['high'].iloc[i] > df['high'].iloc[i+j] for j in range(1, ventana_efectiva + 1)):
            df.loc[df.index[i], 'swing_high'] = True

        # Swing low
        if all(df['low'].iloc[i] < df['low'].iloc[i-j] for j in range(1, ventana_efectiva + 1)) and \
           all(df['low'].iloc[i] < df['low'].iloc[i+j] for j in range(1, ventana_efectiva + 1)):
            df.loc[df.index[i], 'swing_low'] = True

    return df

def _analizar_patron(df, i, tendencia_actual, confirmacion, max_distance, current_price):
    """Analiza y detecta patrones BOS/CHoCH en una posición específica"""
    try:
        # Encontrar swings previos
        swing_high_indices = df.index[(df.index < df.index[i]) & df['swing_high']].tolist()
        swing_low_indices = df.index[(df.index < df.index[i]) & df['swing_low']].tolist()

        if not swing_high_indices or not swing_low_indices:
            return None

        ultimo_swing_high_idx = swing_high_indices[-1]
        ultimo_swing_low_idx = swing_low_indices[-1]
        ultimo_swing_high = df['high'].loc[ultimo_swing_high_idx]
        ultimo_swing_low = df['low'].loc[ultimo_swing_low_idx]

        current_high = df['high'].iloc[i]
        current_low = df['low'].iloc[i]
        current_close = df['close'].iloc[i]
        timestamp = df.index[i]

        rango_significativo = current_close * 0.002

        # Verificar patrones
        señal = None
        
        # BOS y CHoCH alcistas
        if current_high > ultimo_swing_high and abs(current_high - current_price) <= max_distance:
            if (current_high - ultimo_swing_high) > rango_significativo:
                if not confirmacion or current_close > ultimo_swing_high:
                    patron_tipo = "CHoCH" if tendencia_actual == "Bajista" else "BOS"
                    señal = _crear_señal(
                        tipo="Buy",
                        nivel=ultimo_swing_high,
                        patron=patron_tipo,
                        direccion="alcista",
                        tipo_estructura="reversion" if patron_tipo == "CHoCH" else "continuacion",
                        timestamp=timestamp,
                        distancia=(current_high - ultimo_swing_high) / ultimo_swing_high * 100,
                        precio_break=current_close
                    )

        # BOS y CHoCH bajistas
        elif current_low < ultimo_swing_low and abs(current_low - current_price) <= max_distance:
            if (ultimo_swing_low - current_low) > rango_significativo:
                if not confirmacion or current_close < ultimo_swing_low:
                    patron_tipo = "CHoCH" if tendencia_actual == "Alcista" else "BOS"
                    señal = _crear_señal(
                        tipo="Sell",
                        nivel=ultimo_swing_low,
                        patron=patron_tipo,
                        direccion="bajista",
                        tipo_estructura="reversion" if patron_tipo == "CHoCH" else "continuacion",
                        timestamp=timestamp,
                        distancia=(ultimo_swing_low - current_low) / ultimo_swing_low * 100,
                        precio_break=current_close
                    )

        return señal

    except Exception as e:
        logging.error(f"Error en _analizar_patron: {e}")
        return None

def _crear_señal(tipo, nivel, patron, direccion, tipo_estructura, timestamp, distancia, precio_break):
    """Crea una señal estructurada"""
    return {
        "Type": tipo,
        "Level": nivel,
        "Reason": patron,
        "Esquema": patron,
        "DireccionEstructural": direccion,
        "TipoEstructura": tipo_estructura,
        "Confidence": "Alta",
        "Categoria": "Estructura",
        "Strategy": "BOS_CHOCH_M1",
        "OrderBlockRelacionado": False,
        "Nombre": f"{patron} {direccion} en 1M",
        "Timestamp": timestamp,
        "DistanciaBreakout": f"{distancia:.2f}%",
        "PrecioActualEnBreak": precio_break
    }

def _generar_resumen(señales):
    """Genera un resumen de las señales detectadas"""
    if not señales:
        return "Sin patrones detectados"
        
    ultima_señal = señales[0]
    return f"{ultima_señal['Reason']} {ultima_señal['DireccionEstructural']} en {ultima_señal['Level']:.2f}"
def generar_resumen_estructura(bos_choch):
    """
    Resume la estructura detectada en un formato BOS/CHoCH para mostrar.
    """
    resumen = {"bos": "none", "choch": "none"}
    for evento in bos_choch:
        if evento.get("Reason") == "BOS" and resumen["bos"] == "none":
            resumen["bos"] = evento.get("DireccionEstructural", "none")
        elif evento.get("Reason") == "CHoCH" and resumen["choch"] == "none":
            resumen["choch"] = evento.get("DireccionEstructural", "none")
    return resumen


def ejecutar_deteccion_completa(data, max_patrones=5, ignorar_proximidad=False):
    """
    Ejecuta la detección completa de patrones de estructura.
    
    Args:
        data (pd.DataFrame): DataFrame con datos OHLCV
        max_patrones (int): Número máximo de patrones por tipo
        ignorar_proximidad (bool): Si es True, no filtra por proximidad
    
    Returns:
        dict: Resultados de la detección
    """
    try:
        resultados = {
            "bos_choch": detectar_bos_choch(data, 
                                          max_patrones=max_patrones,
                                          ignorar_proximidad=ignorar_proximidad),
            "timestamp": datetime.now().isoformat()
        }
        
        return resultados

    except Exception as e:
        logging.error(f"Error en ejecutar_deteccion_completa: {e}")
        return {
            "bos_choch": {
                "bos": [],
                "choch": [],
                "resumen": f"Error: {str(e)}",
                "ultima_actualizacion": datetime.now().isoformat()
            },
            "timestamp": datetime.now().isoformat()
        }



def normalize_text(text: str) -> str:
    """Normaliza el texto para eliminar caracteres extraños y asegurar que esté en UTF-8."""
    if not isinstance(text, str):
        return text  # Si no es un string, devolverlo sin cambios
    return unicodedata.normalize("NFKD", text)
# Decorador para reintentos automáticos
def retry(max_retries=3, delay=5):
    def decorator(func):
        async def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    logging.error(f"Error en {func.__name__}: {e}. Reintento {attempt + 1}/{max_retries}")
                    if attempt < max_retries - 1:
                        await asyncio.sleep(delay)
                        continue
                    raise e
        return wrapper
    return decorator
# Clase para analizar datos en 30 minutos
class M30Analyzer:
    def __init__(self):
        self.lookback = 48  # Velas a analizar para 30 minutos
        self.trend_threshold = 5  # Nuevo umbral para confirmar la tendencia

    def get_trend(self, data):
        if len(data) < self.lookback:
            return 'Rango'

        highs = data['high'].tail(self.lookback).values
        lows = data['low'].tail(self.lookback).values

        higher_highs = 0
        higher_lows = 0
        lower_highs = 0
        lower_lows = 0

        for i in range(1, len(highs)):
            if highs[i] > highs[i-1]:
                higher_highs += 1
            if lows[i] > lows[i-1]:
                higher_lows += 1
            if highs[i] < highs[i-1]:
                lower_highs += 1
            if lows[i] < lows[i-1]:
                lower_lows += 1

        if higher_highs >= self.trend_threshold and higher_lows >= self.trend_threshold:
            return 'Alcista'
        elif lower_highs >= self.trend_threshold and lower_lows >= self.trend_threshold:
            return 'Bajista'
        else:
            return 'Rango'
    def identify_significant_levels(self, data):
        if len(data) < self.lookback:
            logging.warning(f"Datos insuficientes para analizar niveles en 30M. Velas disponibles: {len(data)}")
            return {'highs': [], 'lows': []}

        lookback = min(48, len(data))  # Analizar hasta 48 velas, o menos si no hay suficientes

        # Reemplaza el llamado a _calculate_levels por lógica válida
        highs = data['high'].tail(lookback).unique().tolist()
        lows = data['low'].tail(lookback).unique().tolist()
       
        def group_levels(levels, tolerance=0.0005):
            if not levels:
                logging.info("No hay niveles para agrupar.")
                return []
            levels.sort()
            grouped = [[levels[0]]]
            for i in range(1, len(levels)):
                if abs(levels[i] - grouped[-1][0]) <= tolerance:
                    grouped[-1].append(levels[i])
                else:
                    grouped.append([levels[i]])
            return [sum(group) / len(group) for group in grouped]

        significant_highs = group_levels(highs)
        significant_lows = group_levels(lows)

        if not significant_highs:
            recent_high = data['high'].tail(3).max()
            significant_highs = [recent_high]
            logging.info(f"Usando nivel alto reciente como respaldo: {recent_high}")
        if not significant_lows:
            recent_low = data['low'].tail(3).min()
            significant_lows = [recent_low]
            logging.info(f"Usando nivel bajo reciente como respaldo: {recent_low}")

        return {'highs': sorted(significant_highs, reverse=True)[:5], 'lows': sorted(significant_lows)[:5]}
# Clase para analizar datos en 5 minutos
class M5Analyzer:
    def __init__(self):
        self.lookback = 48  # Velas disponibles a analizar
        self.trend_lookback = 30  # Velas recientes a analizar para la tendencia
        self.trend_threshold = 5  # Umbral para confirmar la tendencia

    def get_trend(self, data):
        if len(data) < self.lookback:
            return 'Rango'

        highs = data['high'].tail(self.lookback).values
        lows = data['low'].tail(self.lookback).values

        higher_highs = 0
        higher_lows = 0
        lower_highs = 0
        lower_lows = 0

        # Analizar una ventana más reciente para la tendencia de 5M (ajustado)
        recent_highs = highs[-self.trend_lookback:]
        recent_lows = lows[-self.trend_lookback:]

        for i in range(1, len(recent_highs)):
            if recent_highs[i] > recent_highs[i-1]:
                higher_highs += 1
            if recent_lows[i] > recent_lows[i-1]:
                higher_lows += 1
            if recent_highs[i] < recent_highs[i-1]:
                lower_highs += 1
            if recent_lows[i] < recent_lows[i-1]:
                lower_lows += 1

        if higher_highs >= self.trend_threshold and higher_lows >= self.trend_threshold:
            return 'Alcista'
        elif lower_highs >= self.trend_threshold and lower_lows >= self.trend_threshold:
            return 'Bajista'
        else:
            return 'Rango'

    def validate_concepts(self, data, tested_levels, trend):
        """ 
        Valida múltiples señales en 5M: rebotes, rompimientos y falsos rompimientos.
        Devuelve una lista de todas las señales encontradas.
        """
        señales_validas = []

        if len(data) < 3 or not tested_levels:
            logging.warning("Datos insuficientes para analizar conceptos en 5M.")
            return []

        previous_candle = data.iloc[-2]
        last_candle = data.iloc[-1]
        tolerance = abs(data['high'].max() - data['low'].min()) * 0.01

        logging.info(f"Evaluando señales en 5M. Niveles testeados: {tested_levels}, Tendencia actual: {trend}")

        for level in tested_levels:
            close_price = last_candle['close']
            high_price = last_candle['high']
            low_price = last_candle['low']

            # Rebote Alcista
            if trend == 'Alcista' and low_price <= level + tolerance and close_price > level and close_price > last_candle['open']:
                logging.info(f"Rebote Alcista detectado en nivel {level}")
                señales_validas.append({'Type': 'Buy', 'Level': level, 'Reason': 'Rebote 5M', 'Confidence': 'Alta'})

            # Rebote Bajista
            if trend == 'Bajista' and high_price >= level - tolerance and close_price < level and close_price < last_candle['open']:
                logging.info(f"Rebote Bajista detectado en nivel {level}")
                señales_validas.append({'Type': 'Sell', 'Level': level, 'Reason': 'Rebote 5M', 'Confidence': 'Alta'})

            # Rompimiento Alcista
            if trend == 'Alcista' and close_price > level and previous_candle['close'] <= level and close_price > last_candle['open']:
                logging.info(f"Rompimiento Alcista confirmado en nivel {level}")
                señales_validas.append({'Type': 'Buy', 'Level': level, 'Reason': 'Rompimiento 5M', 'Confidence': 'Alta'})

            # Rompimiento Bajista
            if trend == 'Bajista' and close_price < level and previous_candle['close'] >= level and close_price < last_candle['open']:
                logging.info(f"Rompimiento Bajista confirmado en nivel {level}")
                señales_validas.append({'Type': 'Sell', 'Level': level, 'Reason': 'Rompimiento 5M', 'Confidence': 'Alta'})

            # Falso Rompimiento Alcista
            if trend == 'Bajista' and previous_candle['close'] > level and high_price > level and close_price < level and close_price < last_candle['open']:
                logging.info(f"Falso Rompimiento Alcista detectado en nivel {level}")
                señales_validas.append({'Type': 'Sell', 'Level': level, 'Reason': 'Falso Rompimiento Alcista 5M', 'Confidence': 'Media'})

            # Falso Rompimiento Bajista
            if trend == 'Alcista' and previous_candle['close'] < level and low_price < level and close_price > level and close_price > last_candle['open']:
                logging.info(f"Falso Rompimiento Bajista detectado en nivel {level}")
                señales_validas.append({'Type': 'Buy', 'Level': level, 'Reason': 'Falso Rompimiento Bajista 5M', 'Confidence': 'Media'})

        if not señales_validas:
            logging.info("No se detectaron señales válidas en 5M.")

        return señales_validas
    def find_tested_levels(self, data):
        """Identifica niveles frecuentemente testeados con margen dinámico."""
        if len(data) < self.lookback:
            return []

        closes = data['close'].tail(self.lookback)
        high = data['high'].tail(self.lookback).max()
        low = data['low'].tail(self.lookback).min()
        margin = (high - low) * 0.01  # MEJORA 3: Margen dinámico para detectar niveles testeados

        tested_levels = []
        for level in set(closes):
            interactions = sum(abs(closes - level) < margin)
            if interactions >= 3:
                tested_levels.append(level)
    
        # Fallback: Si no se encuentran niveles testeados
        if not tested_levels:
            tested_levels.append(high)
            tested_levels.append(low)
        
        return sorted(tested_levels)
    
# Clase para analizar datos en 1 minuto
class M1Analyzer:
    def __init__(self):
        self.lookback = 60  # Velas a analizar para 1 minuto
        self.trend_lookback = 20  # Velas para tendencia 1M

    def get_trend(self, data):
        if len(data) < self.trend_lookback:
            return 'Rango'

        highs = data['high'].tail(self.trend_lookback).values
        lows = data['low'].tail(self.trend_lookback).values

        higher_highs = 0
        higher_lows = 0
        lower_highs = 0
        lower_lows = 0

        for i in range(1, len(highs)):
            if highs[i] > highs[i - 1]:
                higher_highs += 1
            if lows[i] > lows[i - 1]:
                higher_lows += 1
            if highs[i] < highs[i - 1]:
                lower_highs += 1
            if lows[i] < lows[i - 1]:
                lower_lows += 1

        if higher_highs >= 3 and higher_lows >= 3:
            return 'Alcista'
        elif lower_highs >= 3 and lower_lows >= 3:
            return 'Bajista'
        else:
            return 'Rango'

   
    def analyze_price_action(self, data, level, trend, validated_levels_5m=None, is_flexible=False):
        """
        Analiza la acción del precio en 1M para generar señales basadas en rebotes, rompimientos,
        flips, o testeos frecuentes. Priorizando el primer concepto encontrado.
        """
        if len(data) < 3:
            logging.warning("Datos insuficientes para analizar el precio en 1M.")
            return None

        last_candle = data.iloc[-1]
        previous_candle = data.iloc[-2]
        tolerance = 0.0005  # Incrementar tolerancia para detectar interacciones

        if is_flexible or not validated_levels_5m:
            logging.info("Modo flexible activado: Analizando solo en 1M.")

            # Confirmación de continuación alcista
            if trend == 'Alcista' and last_candle['close'] > level and last_candle['open'] < level:
                logging.info("Confirmación de continuación alcista: Rompimiento en 1M.")
                return {'Type': 'Buy', 'Level': level, 'Reason': 'Rompimiento Alcista en 1M'}

            # Confirmación de continuación bajista
            if trend == 'Bajista' and last_candle['close'] < level and last_candle['open'] > level:
                logging.info("Confirmación de continuación bajista: Rompimiento en 1M.")
                return {'Type': 'Sell', 'Level': level, 'Reason': 'Rompimiento Bajista en 1M'}

            # Rebote alcista
            if trend == 'Alcista' and abs(last_candle['low'] - level) <= tolerance and last_candle['close'] > last_candle['open']:
                logging.info("Confirmación de rebote alcista en 1M.")
                return {'Type': 'Buy', 'Level': level, 'Reason': 'Rebote Alcista en 1M'}

            # Rebote bajista
            if trend == 'Bajista' and abs(last_candle['high'] - level) <= tolerance and last_candle['close'] < last_candle['open']:
                logging.info("Confirmación de rebote bajista en 1M.")
                return {'Type': 'Sell', 'Level': level, 'Reason': 'Rebote Bajista en 1M'}

        else:
            # Validar si el nivel actual está dentro de los niveles validados en 5M
            if level not in validated_levels_5m:
                logging.info("Nivel no validado por 5M, se descarta en análisis 1M.")
                return None

            # Confirmación del rompimiento con validación previa
            if trend == 'Alcista' and previous_candle['close'] < level and last_candle['close'] > level:
                return {'Type': 'Buy', 'Level': level, 'Reason': 'Rompimiento Alcista Validado'}

            if trend == 'Bajista' and previous_candle['close'] > level and last_candle['close'] < level:
                return {'Type': 'Sell', 'Level': level, 'Reason': 'Rompimiento Bajista Validado'}

        
           
            # **Detectar flips (resistencia a soporte o viceversa)**
            if last_candle['close'] > level and previous_candle['close'] < level:
                logging.info("Confirmación de Flip Zone: Resistencia rota en 1M.")
                return {'Type': 'Buy', 'Level': level, 'Reason': 'Flip Zone - Resistencia Rota', 'Confidence': 'Media'}

            elif last_candle['close'] < level and previous_candle['close'] > level:
                logging.info("Confirmación de Flip Zone: Soporte roto en 1M.")
                return {'Type': 'Sell', 'Level': level, 'Reason': 'Flip Zone - Soporte Roto', 'Confidence': 'Media'}

        # **Validaciones cruzadas con 5M**
        if validated_levels_5m:
            logging.info("Validaciones en 5M detectadas: Analizando en base a niveles validados.")
            if last_candle['close'] > level and last_candle['low'] <= level + tolerance:
                logging.info("Confirmación de Rebote Alcista en 1M.")
                return {'Type': 'Buy', 'Level': level, 'Reason': 'Rebote Alcista', 'Confidence': 'Alta'}

            elif last_candle['close'] < level and last_candle['high'] >= level - tolerance:
                logging.info("Confirmación de Rebote Bajista en 1M.")
                return {'Type': 'Sell', 'Level': level, 'Reason': 'Rebote Bajista', 'Confidence': 'Alta'}

        # Entrada por Testeo Frecuente (si no se validó nada en 5M o se está en modo flexible)
        if not validated_levels_5m or is_flexible:
            interactions = sum(abs(data['close'].tail(self.lookback) - level) < tolerance)
            if interactions >= 3:  # Si el nivel ha sido testeado al menos 3 veces
                logging.info(f"Nivel testeado encontrado con {interactions} interacciones. Nivel: {level}")
                if trend == 'Alcista' and last_candle['close'] > level:
                    logging.info("Señal por Testeo Frecuente Alcista en 1M.")
                    return {'Type': 'Buy', 'Level': level, 'Reason': 'Testeo Frecuente', 'Confidence': 'Baja'}
                elif trend == 'Bajista' and last_candle['close'] < level:
                    logging.info("Señal por Testeo Frecuente Bajista en 1M.")
                    return {'Type': 'Sell', 'Level': level, 'Reason': 'Testeo Frecuente', 'Confidence': 'Baja'}
        return None
    def find_tested_levels(self, data, current_price):
        """
        Identifica niveles testeados cercanos al precio actual en 1M.
        """
        if len(data) < self.lookback:
            return []

        closes = data['close'].tail(self.lookback)  # Últimos cierres de las velas
        tested_levels = []

        # Buscar niveles frecuentemente testeados
        for level in set(closes):
            interactions = sum(abs(closes - level) < 0.0001)  # Considera un margen para identificar testeos
            if interactions >= 3:  # Si ha sido testeado al menos 3 veces
                tested_levels.append(level)
            
        # Ordenar los niveles en función de la cercanía al precio actual
        tested_levels = sorted(tested_levels, key=lambda x: abs(x - current_price))

        return tested_levels
    def analyze_price_action(self, data, level, trend, validated_levels_5m=None, is_flexible=False):
        if len(data) < 3:
            logging.warning("Datos insuficientes para analizar el precio en 1M.")
            return None
    
class FlexibleM5Analyzer:
    """
    Clase para el análisis de niveles de soporte/resistencia y su comportamiento
    en el timeframe de 5 minutos, incluyendo identificación de niveles,
    polaridad, rompimientos y retesteos.
    """
    def __init__(self):
        self.levels_df = pd.DataFrame()
        
        # Parámetros definidos directamente en la clase, sin usar 'config'
        self.min_break_percentage = 0.001 # 0.1% del precio del nivel
        self.min_body_ratio_breakout = 0.7 # Porcentaje mínimo del cuerpo de la vela para un rompimiento fuerte
        self.max_wick_ratio_breakout = 0.3 # Porcentaje máximo de mecha contraria al rompimiento
        self.breakout_lookback_candles = 20 # Cuántas velas hacia atrás buscar rompimientos
        self.polarity_check_candles = 5  # Cuántas velas después del breakout revisar para cambio de polaridad
        self.strong_breakout_lookback_candles = 20 # Cuántas velas hacia atrás buscar rompimientos fuertes
        self.retest_lookback_candles = 10 # Cuántas velas después del breakout buscar retests
        self.retest_tolerance = 0.0002 # Tolerancia de proximidad al nivel para un retest (ej: 0.02%)
        self.continuation_check_candles = 3 # Cuántas velas después del retest buscar continuación
        

    def identify_key_levels(self, data: pd.DataFrame):
        """
        Identifica niveles clave (pivotes, flips, S/R tradicionales) en los datos de velas.
        Asegura el uso consistente de .iloc para acceso posicional y maneja el índice de tiempo.
        """
        levels = []

        if data.empty or len(data) < 5:
            logging.warning("FlexibleM5Analyzer: Datos insuficientes para identificar niveles clave. Se requieren al menos 5 velas.")
            self.levels_df = pd.DataFrame(columns=['Date', 'Level', 'Type', 'Trend'])
            return self.levels_df

        highs = data['high'].rolling(window=3, center=True).max()
        lows = data['low'].rolling(window=3, center=True).min()

        start_index = 2
        end_index = len(data) - 2 

        if start_index >= end_index:
            logging.warning("FlexibleM5Analyzer: Rango de bucle no válido para la identificación de niveles clave. Datos demasiado cortos.")
            self.levels_df = pd.DataFrame(columns=['Date', 'Level', 'Type', 'Trend'])
            return self.levels_df

        for i in range(start_index, end_index):
            # Pivotes Highs/Lows
            # Se ha añadido np.isnan check para robustez
            if not np.isnan(highs.iloc[i]) and data['high'].iloc[i] == highs.iloc[i]:
                levels.append({'Date': data.index[i], 'Level': highs.iloc[i], 'Type': 'High (A)', 'Trend': 'N/A'})
            elif not np.isnan(lows.iloc[i]) and data['low'].iloc[i] == lows.iloc[i]:
                levels.append({'Date': data.index[i], 'Level': lows.iloc[i], 'Type': 'Low (B)', 'Trend': 'N/A'})

            # Flips
            if (data['close'].iloc[i] > data['close'].iloc[i - 1] and
                data['close'].iloc[i] > data['close'].iloc[i + 1]):
                if data['close'].iloc[i - 1] > data['close'].iloc[i - 2]:
                    levels.append({'Date': data.index[i], 'Level': data['close'].iloc[i], 'Type': 'Flip AA+', 'Trend': 'Bullish'})
                else:
                    levels.append({'Date': data.index[i], 'Level': data['close'].iloc[i], 'Type': 'Flip BA+', 'Trend': 'Bullish'})
            elif (data['close'].iloc[i] < data['close'].iloc[i - 1] and
                  data['close'].iloc[i] < data['close'].iloc[i + 1]):
                if data['close'].iloc[i - 1] < data['close'].iloc[i - 2]:
                    levels.append({'Date': data.index[i], 'Level': data['close'].iloc[i], 'Type': 'Flip BB+', 'Trend': 'Bearish'})
                else:
                    levels.append({'Date': data.index[i], 'Level': data['close'].iloc[i], 'Type': 'Flip AB+', 'Trend': 'Bearish'})

            # AB-/BA-
            if (data['high'].iloc[i] > data['high'].iloc[i - 1] and data['high'].iloc[i] > data['high'].iloc[i + 1] and
                data['close'].iloc[i] < data['close'].iloc[i - 1] and data['close'].iloc[i] < data['close'].iloc[i + 1]):
                levels.append({'Date': data.index[i], 'Level': data['high'].iloc[i], 'Type': 'AB-', 'Trend': 'Bearish'})

            if (data['low'].iloc[i] < data['low'].iloc[i - 1] and data['low'].iloc[i] < data['low'].iloc[i + 1] and
                data['close'].iloc[i] > data['close'].iloc[i - 1] and data['close'].iloc[i] > data['close'].iloc[i + 1]):
                levels.append({'Date': data.index[i], 'Level': data['low'].iloc[i], 'Type': 'BA-', 'Trend': 'Bullish'})

            # S/R tradicionales
            if not np.isnan(highs.iloc[i]) and data['high'].iloc[i] == highs.iloc[i]:
                levels.append({'Date': data.index[i], 'Level': highs.iloc[i], 'Type': 'Resistance', 'Trend': 'N/A'})
            elif not np.isnan(lows.iloc[i]) and data['low'].iloc[i] == lows.iloc[i]:
                levels.append({'Date': data.index[i], 'Level': lows.iloc[i], 'Type': 'Support', 'Trend': 'N/A'})
        
        if levels:
            self.levels_df = pd.DataFrame(levels).drop_duplicates(subset=['Date', 'Level', 'Type']).sort_values(by='Date').reset_index(drop=True)
            logging.info(f"FlexibleM5Analyzer: Identificados {len(self.levels_df)} niveles clave.")
        else:
            self.levels_df = pd.DataFrame(columns=['Date', 'Level', 'Type', 'Trend'])
            logging.warning("FlexibleM5Analyzer: No se identificaron niveles clave.")
        
        return self.levels_df

    def _is_strong_breakout(self, candle: pd.Series, level: float, direction: str) -> bool:
        """
        Verifica si una vela representa un rompimiento "fuerte" de un nivel.
        """
        body_size = abs(candle['close'] - candle['open'])
        
        # Usar self.min_break_percentage directamente
        min_break_percentage = self.min_break_percentage 
        
        total_range = (candle['high'] - candle['low'])
        if total_range == 0:
            return False

        if direction == 'up':
            if candle['close'] > level and (candle['close'] - level) > level * min_break_percentage:
                # Usar self.min_body_ratio_breakout y self.max_wick_ratio_breakout directamente
                if body_size / total_range > self.min_body_ratio_breakout:
                    if (candle['high'] - candle['close']) / body_size < self.max_wick_ratio_breakout:
                        return True
        elif direction == 'down':
            if candle['close'] < level and (level - candle['close']) > level * min_break_percentage:
                # Usar self.min_body_ratio_breakout y self.max_wick_ratio_breakout directamente
                if body_size / total_range > self.min_body_ratio_breakout:
                    if (candle['open'] - candle['low']) / body_size < self.max_wick_ratio_breakout:
                        return True
        return False

    def _find_breakouts(self, data: pd.DataFrame, level_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Encuentra rompimientos de un nivel dado.
        """
        level = level_info['Level']
        level_type = level_info['Type']
        breakouts = []
        
        # Usar self.breakout_lookback_candles directamente
        lookback_period = self.breakout_lookback_candles 
        start_idx = max(0, len(data) - lookback_period)

        for i in range(start_idx, len(data)):
            candle = data.iloc[i]
            
            is_break = False
            direction = 'none'

            if level_type == 'Support':
                if candle['close'] < level:
                    is_break = True
                    direction = 'down'
            elif level_type == 'Resistance':
                if candle['close'] > level:
                    is_break = True
                    direction = 'up'
            
            if is_break and self._is_strong_breakout(candle, level, direction):
                breakouts.append({
                    'index': i,
                    'close_price': candle['close'],
                    'direction': direction,
                    'timestamp': data.index[i]
                })
        logging.debug(f"FlexibleM5Analyzer: Encontrados {len(breakouts)} rompimientos para nivel {level}.")
        return breakouts
    
    def _check_polarity_change(self, data: pd.DataFrame, level_info: Dict[str, Any], breakout: Dict[str, Any]) -> Optional[str]:
        """
        Verifica si un nivel cambia su polaridad después de un rompimiento.
        """
        level = level_info['Level']
        original_type = level_info['Type']
        breakout_index = breakout['index']
        
        # Usar self.polarity_check_candles directamente
        post_breakout_lookforward = self.polarity_check_candles 
        
        start_check_idx = breakout_index + 1
        end_check_idx = min(len(data), breakout_index + 1 + post_breakout_lookforward)

        if start_check_idx >= end_check_idx:
            return None

        if breakout['direction'] == 'down' and original_type == 'Support':
            for i in range(start_check_idx, end_check_idx):
                candle = data.iloc[i]
                is_retest_and_rejection = candle['high'] >= level and candle['close'] < level
                no_significant_close_above = not any(data.iloc[j]['close'] > level for j in range(breakout_index + 1, i + 1))
                
                if is_retest_and_rejection and no_significant_close_above:
                    logging.debug(f"FlexibleM5Analyzer: Polaridad cambiada de Soporte a Resistencia en {level}.")
                    return 'SupportToResistance'
        
        elif breakout['direction'] == 'up' and original_type == 'Resistance':
            for i in range(start_check_idx, end_check_idx):
                candle = data.iloc[i]
                is_retest_and_rejection = candle['low'] <= level and candle['close'] > level
                no_significant_close_below = not any(data.iloc[j]['close'] < level for j in range(breakout_index + 1, i + 1))
                
                if is_retest_and_rejection and no_significant_close_below:
                    logging.debug(f"FlexibleM5Analyzer: Polaridad cambiada de Resistencia a Soporte en {level}.")
                    return 'ResistanceToSupport'
                            
        return None

    def _identify_scheme(self, data: pd.DataFrame, level_info: Dict[str, Any], breakout: Dict[str, Any], polarity_change_type: Optional[str]) -> str:
        """
        Identifica un esquema basado en el rompimiento y cambio de polaridad o continuación.
        """
        level_type = level_info['Type']
        
        if polarity_change_type == 'SupportToResistance':
            return "Soporte_Roto_a_Resistencia"
        elif polarity_change_type == 'ResistanceToSupport':
            return "Resistencia_Rota_a_Soporte"
        
        if breakout['direction'] == 'down' and level_type == 'Support':
            return "Rompimiento_Bajista_Soporte"
        elif breakout['direction'] == 'up' and level_type == 'Resistance':
            return "Rompimiento_Alcista_Resistencia"
            
        return "Esquema_Desconocido"

    def _find_strong_breakouts(self, data: pd.DataFrame, level_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Encuentra rompimientos fuertes, que son el primer paso para una continuación.
        """
        level = level_info['Level']
        level_type = level_info['Type']
        strong_breakouts = []
        
        # Usar self.strong_breakout_lookback_candles directamente
        lookback_period = self.strong_breakout_lookback_candles 
        start_idx = max(0, len(data) - lookback_period)

        for i in range(start_idx, len(data)):
            candle = data.iloc[i]
            
            is_break = False
            direction = 'none'

            if level_type == 'Support' and candle['close'] < level:
                is_break = True
                direction = 'down'
            elif level_type == 'Resistance' and candle['close'] > level:
                is_break = True
                direction = 'up'
            
            if is_break and self._is_strong_breakout(candle, level, direction):
                strong_breakouts.append({
                    'index': i,
                    'close_price': candle['close'],
                    'direction': direction,
                    'timestamp': data.index[i]
                })
        logging.debug(f"FlexibleM5Analyzer: Encontrados {len(strong_breakouts)} rompimientos fuertes para nivel {level}.")
        return strong_breakouts

    def _find_retests(self, data: pd.DataFrame, level_info: Dict[str, Any], breakout: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Encuentra retesteos del nivel después de un rompimiento fuerte.
        """
        level = level_info['Level']
        breakout_index = breakout['index']
        retests = []
        
        # Usar self.retest_lookback_candles y self.retest_tolerance directamente
        retest_lookback_candles = self.retest_lookback_candles 
        retest_tolerance = self.retest_tolerance 
        
        start_retest_idx = breakout_index + 1
        end_retest_idx = min(len(data), breakout_index + 1 + retest_lookback_candles)

        if start_retest_idx >= end_retest_idx:
            return retests

        for i in range(start_retest_idx, end_retest_idx):
            candle = data.iloc[i]
            
            if breakout['direction'] == 'down':
                if candle['high'] >= level and abs(candle['high'] - level) <= level * retest_tolerance:
                    if candle['close'] < level:
                        retests.append({
                            'index': i,
                            'close_price': candle['close'],
                            'direction': 'retest_down',
                            'timestamp': data.index[i]
                        })
            elif breakout['direction'] == 'up':
                if candle['low'] <= level and abs(candle['low'] - level) <= level * retest_tolerance:
                    if candle['close'] > level:
                        retests.append({
                            'index': i,
                            'close_price': candle['close'],
                            'direction': 'retest_up',
                            'timestamp': data.index[i]
                        })
        logging.debug(f"FlexibleM5Analyzer: Encontrados {len(retests)} retests para nivel {level} y breakout en {data.index[breakout_index]}.")
        return retests

    def _check_continuation(self, data: pd.DataFrame, level_info: Dict[str, Any], breakout: Dict[str, Any], retest: Dict[str, Any]) -> bool:
        """
        Verifica si hay una continuación de la tendencia después de un retest.
        """
        retest_index = retest['index']
        breakout_direction = breakout['direction']
        level = level_info['Level']
        
        # Usar self.continuation_check_candles directamente
        continuation_candles = self.continuation_check_candles 
        
        start_check_idx = retest_index + 1
        end_check_idx = min(len(data), retest_index + 1 + continuation_candles)
        
        if start_check_idx >= end_check_idx:
            return False

        has_continued = False
        if breakout_direction == 'down':
            for i in range(start_check_idx, end_check_idx):
                if data.iloc[i]['close'] < level:
                    has_continued = True
                    break
        elif breakout_direction == 'up':
            for i in range(start_check_idx, end_check_idx):
                if data.iloc[i]['close'] > level:
                    has_continued = True
                    break
        
        logging.debug(f"FlexibleM5Analyzer: Continuación {has_continued} para retest en {data.index[retest_index]}.")
        return has_continued
    
    def analyze_polarity(self, data: pd.DataFrame, levels: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Analiza el cambio de polaridad de los niveles (resistencia a soporte, o viceversa)
        después de un rompimiento.
        """
        polarities = []
        if data.empty or not levels:
            logging.warning("FlexibleM5Analyzer: Datos o niveles vacíos para analyze_polarity.")
            return polarities

        for level in levels:
            breakouts = self._find_breakouts(data, level)
            for breakout in breakouts:
                polarity_change_type = self._check_polarity_change(data, level, breakout)
                if polarity_change_type:
                    scheme = self._identify_scheme(data, level, breakout, polarity_change_type)
                    polarities.append({
                        'Level': level['Level'],
                        'original_type': level['Type'],
                        'new_type': 'Resistance' if level['Type'] == 'Support' else 'Support',
                        'breakout_index': breakout['index'],
                        'direction': 'Sell' if level['Type'] == 'Support' else 'Buy',
                        'scheme': scheme,
                        'timestamp': data.index[breakout['index']]
                    })
        logging.info(f"FlexibleM5Analyzer: {len(polarities)} cambios de polaridad detectados.")
        return polarities

    def analyze_breakout_support(self, data: pd.DataFrame, levels: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Analiza los rompimientos y retesteos de niveles de soporte/resistencia
        para identificar continuaciones.
        """
        continuation_signals = []
        if data.empty or not levels:
            logging.warning("FlexibleM5Analyzer: Datos o niveles vacíos para analyze_breakout_support.")
            return continuation_signals

        for level in levels:
            strong_breakouts = self._find_strong_breakouts(data, level)
            for breakout in strong_breakouts:
                retests = self._find_retests(data, level, breakout)
                for retest in retests:
                    if self._check_continuation(data, level, breakout, retest):
                        scheme = self._identify_scheme(data, level, breakout, None)
                        continuation_signals.append({
                            'Level': level['Level'],
                            'original_type': level['Type'],
                            'breakout_index': breakout['index'],
                            'retest_index': retest['index'],
                            'direction': 'Buy' if level['Type'] == 'Resistance' else 'Sell',
                            'scheme': scheme,
                            'timestamp': data.index[retest['index']]
                        })
        logging.info(f"FlexibleM5Analyzer: {len(continuation_signals)} señales de continuación (rompimiento/retest) detectadas.")
        return continuation_signals

    def detect_polarity_change(self, row: dict, previous_level: Optional[dict]) -> bool:
        """
        Detecta si hay un cambio de polaridad entre el nivel actual y el anterior.
        """
        if previous_level is None:
            return False
        
        return (row['Type'] == 'Resistance' and previous_level['Type'] == 'Support') or \
               (row['Type'] == 'Support' and previous_level['Type'] == 'Resistance')

    def identify_scheme_falso_rompimiento(self, current_row: dict, next_candle: Optional[pd.Series], previous_level: Optional[dict]) -> Optional[str]:
        """
        Identifica el esquema de "Falso Rompimiento" (FR) o "Continuación"
        basado en la vela siguiente y el cambio de polaridad.
        """
        if next_candle is None:
            return None
        
        close = next_candle['close'] 
        level_price = current_row['Level']
        level_type = current_row['Type']
        
        polarity_change_detected = self.detect_polarity_change(current_row, previous_level)
        
        if polarity_change_detected:
            if level_type == 'Resistance' and close < level_price:
                return 'FR_Alcista_Fallido'
            elif level_type == 'Support' and close > level_price:
                return 'FR_Bajista_Fallido'
        
        return 'Nivel_Relevante'

    def analyze_5m_levels(self, candles_df: pd.DataFrame) -> pd.DataFrame:
        """
        Analiza los niveles de 5M y los enriquece con información de esquema
        de falso rompimiento/continuación.
        """
        enriched_levels = []
        if self.levels_df.empty:
            logging.warning("FlexibleM5Analyzer: No hay niveles identificados para analizar en 5M.")
            return pd.DataFrame(columns=['Date', 'Level', 'Type', 'polarityChange', 'scheme', 'timestamp'])

        for i, row in self.levels_df.iterrows():
            level_time = row['Date']
            
            next_candle_candidates = candles_df[candles_df.index > level_time]
            next_row = next_candle_candidates.iloc[0] if not next_candle_candidates.empty else None
            
            previous_level = self.levels_df.iloc[i-1].to_dict() if i > 0 else None
            
            polarity_change_for_level = self.detect_polarity_change(row.to_dict(), previous_level)
            
            scheme = self.identify_scheme_falso_rompimiento(row.to_dict(), next_row, previous_level)
            
            enriched_levels.append({
                'Date': row['Date'],
                'Level': row['Level'],
                'Type': row['Type'],
                'polarityChange': polarity_change_for_level,
                'scheme': scheme,
                'timestamp': row['Date']
            })
        logging.info(f"FlexibleM5Analyzer: Enriquecidos {len(enriched_levels)} niveles con esquemas de falso rompimiento.")
        return pd.DataFrame(enriched_levels)

    def analyze(self, data: pd.DataFrame) -> List[Dict[str, Any]]:
        """Análisis completo en 5M con salida unificada de señales/esquemas."""
        
        
        self.identify_key_levels(data)
        
        if self.levels_df.empty:
            logging.warning("FlexibleM5Analyzer: No hay niveles clave identificados. Saltando análisis de polaridad y breakout.")
            return []

        levels_as_list = self.levels_df.to_dict('records')
        
        polarity_analysis = self.analyze_polarity(data, levels_as_list)
        
        breakout_analysis = self.analyze_breakout_support(data, levels_as_list)
        
        enriched_levels_df = self.analyze_5m_levels(data)
        false_breakout_analysis = enriched_levels_df.to_dict('records')

        esquemas_unificados: List[Dict[str, Any]] = []

        for item in polarity_analysis:
            esquemas_unificados.append({
                'Level': item['Level'],
                'scheme': item['scheme'],
                'direction': item['direction'],
                'source': 'Polarity_5m',
                'timestamp': item['timestamp']
            })

        for item in breakout_analysis:
            esquemas_unificados.append({
                'Level': item['Level'],
                'scheme': item['scheme'],
                'direction': item['direction'],
                'source': 'BreakoutRetest_5m',
                'timestamp': item['timestamp']
            })
        
        for item in false_breakout_analysis:
            esquemas_unificados.append({
                'Level': item['Level'],
                'scheme': item['scheme'],
                'direction': item.get('Type', 'N/A'),
                'source': 'FalseBreakout_5m',
                'timestamp': item['timestamp']
            })
            
        
        return esquemas_unificados

class FlexibleM1Analyzer:
    """
    Clase para el análisis de niveles clave y patrones específicos en el timeframe de 1 minuto,
    combinando con esquemas de timeframes mayores.
    """
    def __init__(self):
        self.levels_df = pd.DataFrame()
        # Parámetros definidos directamente en la clase, sin usar 'config'
        self.proximity_threshold_5m = 0.0006 # Umbral de proximidad para confirmar esquemas de 5M en 1M
        

    def identify_key_levels(self, data: pd.DataFrame) -> List[Dict[str, Any]]:
        """
        Identifica niveles clave (Flips, Altos/Bajos, AB-/BA-, soportes y resistencias) en 1M.
        Asegura el uso consistente de .iloc para acceso posicional y maneja el índice de tiempo.
        """
        levels = []

        # Necesitamos al menos 3 velas para rolling(window=3) y 5 para i-2 y i+2 de forma segura
        if data.empty or len(data) < 5:
            logging.warning("FlexibleM1Analyzer: Datos insuficientes para identificar niveles clave (1M). Se requieren al menos 5 velas.")
            self.levels_df = pd.DataFrame(columns=['Date', 'Level', 'Type', 'Trend'])
            return self.levels_df.to_dict('records')

        highs = data['high'].rolling(window=3, center=True).max()
        lows = data['low'].rolling(window=3, center=True).min()

        # El rango del bucle debe asegurar que los accesos como i-2 y i+2 sean válidos.
        # i-2 requiere i >= 2. i+2 requiere i <= len(data) - 3.
        start_index = 2
        end_index = len(data) - 2 # Exclusivo, así que el último índice procesado es len(data) - 3

        if start_index >= end_index:
            logging.warning("FlexibleM1Analyzer: Rango de bucle no válido para la identificación de niveles clave (1M). Datos demasiado cortos.")
            self.levels_df = pd.DataFrame(columns=['Date', 'Level', 'Type', 'Trend'])
            return self.levels_df.to_dict('records')

        for i in range(start_index, end_index):
            # Pivotes Highs/Lows
            if data['high'].iloc[i] == highs.iloc[i]:
                levels.append({'Date': data.index[i], 'Level': highs.iloc[i], 'Type': 'High (A)', 'Trend': 'N/A'})
            elif data['low'].iloc[i] == lows.iloc[i]:
                levels.append({'Date': data.index[i], 'Level': lows.iloc[i], 'Type': 'Low (B)', 'Trend': 'N/A'})

            # Flips
            if (data['close'].iloc[i] > data['close'].iloc[i - 1] and
                data['close'].iloc[i] > data['close'].iloc[i + 1]):
                if data['close'].iloc[i - 1] > data['close'].iloc[i - 2]:
                    levels.append({'Date': data.index[i], 'Level': data['close'].iloc[i], 'Type': 'Flip AA+', 'Trend': 'Bullish'})
                else:
                    levels.append({'Date': data.index[i], 'Level': data['close'].iloc[i], 'Type': 'Flip BA+', 'Trend': 'Bullish'})
            elif (data['close'].iloc[i] < data['close'].iloc[i - 1] and
                  data['close'].iloc[i] < data['close'].iloc[i + 1]):
                if data['close'].iloc[i - 1] < data['close'].iloc[i - 2]:
                    levels.append({'Date': data.index[i], 'Level': data['close'].iloc[i], 'Type': 'Flip BB+', 'Trend': 'Bearish'})
                else:
                    levels.append({'Date': data.index[i], 'Level': data['close'].iloc[i], 'Type': 'Flip AB+', 'Trend': 'Bearish'})

            # AB- y BA-
            if (data['high'].iloc[i] > data['high'].iloc[i - 1] and data['high'].iloc[i] > data['high'].iloc[i + 1] and
                data['close'].iloc[i] < data['close'].iloc[i - 1] and data['close'].iloc[i] < data['close'].iloc[i + 1]):
                levels.append({'Date': data.index[i], 'Level': data['high'].iloc[i], 'Type': 'AB-', 'Trend': 'Bearish'})
            if (data['low'].iloc[i] < data['low'].iloc[i - 1] and data['low'].iloc[i] < data['low'].iloc[i + 1] and
                data['close'].iloc[i] > data['close'].iloc[i - 1] and data['close'].iloc[i] > data['close'].iloc[i + 1]):
                levels.append({'Date': data.index[i], 'Level': data['low'].iloc[i], 'Type': 'BA-', 'Trend': 'Bullish'})

            # S/R tradicionales (usando los mismos criterios de highs/lows)
            if data['high'].iloc[i] == highs.iloc[i]:
                levels.append({'Date': data.index[i], 'Level': highs.iloc[i], 'Type': 'Resistance', 'Trend': 'N/A'})
            elif data['low'].iloc[i] == lows.iloc[i]:
                levels.append({'Date': data.index[i], 'Level': lows.iloc[i], 'Type': 'Support', 'Trend': 'N/A'})

        # Eliminar duplicados y ordenar por fecha
        if levels:
            self.levels_df = pd.DataFrame(levels).drop_duplicates(subset=['Date', 'Level', 'Type']).sort_values(by='Date').reset_index(drop=True)
            logging.info(f"FlexibleM1Analyzer: Identificados {len(self.levels_df)} niveles clave en 1M.")
        else:
            self.levels_df = pd.DataFrame(columns=['Date', 'Level', 'Type', 'Trend'])
            logging.warning("FlexibleM1Analyzer: No se identificaron niveles clave en 1M.")

        return self.levels_df.to_dict('records') # Devuelve como lista de diccionarios

    def analyze_pullbacks(self, data: pd.DataFrame, levels: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Detecta 'Pullbacks'."""
        pullbacks = []
        if data.empty or not levels or len(data) < 2:
            return pullbacks

        for level in levels:
            for i in range(len(data) - 1): # Bucle hasta la penúltima vela para acceder a i+1
                if data['close'].iloc[i] < level['Level'] and data['close'].iloc[i + 1] > level['Level']:
                    pullbacks.append({
                        'Date': data.index[i],
                        'Level': level['Level'],
                        'Type': 'Pullback',
                        'Trend': 'Bullish' if level['Level'] > data['close'].iloc[i] else 'Bearish'
                    })
        logging.debug(f"FlexibleM1Analyzer: Detectados {len(pullbacks)} pullbacks.")
        return pullbacks

    def analyze_ranks(self, data: pd.DataFrame, levels: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Detecta 'Ranks'."""
        ranks = []
        if data.empty or not levels or len(data) < 2:
            return ranks

        for level in levels:
            for i in range(len(data) - 1): # Bucle hasta la penúltima vela para acceder a i+1
                if data['close'].iloc[i] > level['Level'] and data['close'].iloc[i + 1] < level['Level']:
                    ranks.append({
                        'Date': data.index[i],
                        'Level': level['Level'],
                        'Type': 'Rank',
                        'Trend': 'Bearish' if level['Level'] < data['close'].iloc[i] else 'Bullish'
                    })
        logging.debug(f"FlexibleM1Analyzer: Detectados {len(ranks)} ranks.")
        return ranks

    def analyze_baston_c(self, data: pd.DataFrame, levels: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Detecta patrones 'Baston C' (continuación alcista)."""
        baston_c = []
        if data.empty or not levels or len(data) < 2:
            return baston_c

        added_levels_for_baston = set() 

        for level in levels:
            for i in range(len(data) - 1):
                # Si el cierre actual y el siguiente están por encima del nivel
                if data['close'].iloc[i] > level['Level'] and data['close'].iloc[i + 1] > level['Level']:
                    # Usar una tupla (Level, Type) para identificar el nivel de forma única
                    level_key = (level['Level'], level['Type'])
                    if level_key not in added_levels_for_baston:
                        baston_c.append({
                            'Date': data.index[i],
                            'Level': level['Level'],
                            'Type': 'Baston C',
                            'Trend': 'Bullish'
                        })
                        added_levels_for_baston.add(level_key)
        logging.debug(f"FlexibleM1Analyzer: Detectados {len(baston_c)} baston_c.")
        return baston_c

    def analyze_baston_r(self, data: pd.DataFrame, levels: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Detecta patrones 'Baston R' (continuación bajista)."""
        baston_r = []
        if data.empty or not levels or len(data) < 2:
            return baston_r
        
        added_levels_for_baston = set()

        for level in levels:
            for i in range(len(data) - 1):
                # Si el cierre actual y el siguiente están por debajo del nivel
                if data['close'].iloc[i] < level['Level'] and data['close'].iloc[i + 1] < level['Level']:
                    level_key = (level['Level'], level['Type'])
                    if level_key not in added_levels_for_baston:
                        baston_r.append({
                            'Date': data.index[i],
                            'Level': level['Level'],
                            'Type': 'Baston R',
                            'Trend': 'Bearish'
                        })
                        added_levels_for_baston.add(level_key)
        logging.debug(f"FlexibleM1Analyzer: Detectados {len(baston_r)} baston_r.")
        return baston_r
    
    def analyze_concepts(self, data: pd.DataFrame, esquemas_5m: Optional[List[Dict[str, Any]]] = None) -> List[Dict[str, Any]]:
        """
        Análisis flexible en 1M. Combina esquemas de 5M con patrones locales en 1M.
        Este método es el que `TradingBot.analyze_flexible_strategy` llamará.
        """
        señales_1m_finales = []
        niveles_agregados = set() # Para evitar duplicados de señales

        if data.empty:
            logging.warning("FlexibleM1Analyzer.analyze_concepts: Datos de 1M vacíos.")
            return señales_1m_finales

        # 1. Identificar niveles clave locales en 1M
        levels_1m = self.identify_key_levels(data) # Esto devuelve una lista de dicts

        # 2. Análisis de patrones locales en 1M
        pullbacks = self.analyze_pullbacks(data, levels_1m)
        ranks = self.analyze_ranks(data, levels_1m)
        baston_c = self.analyze_baston_c(data, levels_1m)
        baston_r = self.analyze_baston_r(data, levels_1m)

        # === Señales desde ESQUEMAS DE 5M (confirmación en 1M) ===
        if esquemas_5m:
            current_price = data['close'].iloc[-1]
            # Umbral de proximidad para confirmar esquemas de 5M en 1M
            proximity_threshold_5m = self.proximity_threshold_5m # Acceso directo al atributo

            for esquema in esquemas_5m:
                # Asegúrate de que 'Level' exista y no sea NaN
                esquema_level = esquema.get('Level')
                if esquema_level is None or np.isnan(esquema_level):
                    continue

                if abs(current_price - esquema_level) < proximity_threshold_5m:
                    key = (esquema_level, esquema.get('scheme', 'Scheme_5M'))
                    if key not in niveles_agregados:
                        señales_1m_finales.append({
                            'Type': esquema.get('direction'), # Usar la dirección del esquema 5M
                            'Level': esquema_level,
                            'Reason': f"Confirmación esquema 5M: {esquema.get('scheme', 'N/A')}",
                            'Confidence': 'Alta',
                            'Categoria': 'Flexible_5M', # Nueva categoría para distinguir
                            'Strategy': 'FlexibleStrategy',
                            'Nombre': f"{esquema.get('scheme', 'N/A')} confirmado en 1M",
                            'Esquema': esquema.get('scheme', 'N/A'),
                            'OrderBlockRelacionado': "OrderBlock" in esquema.get('scheme', '') # Asumiendo que el esquema 5M podría indicar OB
                        })
                        niveles_agregados.add(key)
        
        # === Señales locales por patrones en 1M ===
        def agregar_patron(signals_list: List[Dict[str, Any]], name: str, force_type: Optional[str] = None):
            for señal in signals_list:
                # Asegúrate de que 'Level' exista y no sea NaN
                señal_level = señal.get('Level')
                if señal_level is None or np.isnan(señal_level):
                    continue

                tipo = 'Buy' if señal.get('Trend') == 'Bullish' else 'Sell'
                if force_type:
                    tipo = force_type
                
                key = (señal_level, name)
                if key not in niveles_agregados:
                    señales_1m_finales.append({
                        'Type': tipo,
                        'Level': señal_level,
                        'Reason': name,
                        'Confidence': 'Media',
                        'Categoria': 'Flexible_1M', # Nueva categoría
                        'Strategy': 'FlexibleStrategy',
                        'Nombre': f"Patrón {name} en 1M",
                        'Esquema': name, # El patrón mismo es el esquema
                        'OrderBlockRelacionado': False # Por defecto, a menos que tu patrón lo indique
                    })
                    niveles_agregados.add(key)

        agregar_patron(pullbacks, 'Pullback')
        agregar_patron(ranks, 'Rank')
        agregar_patron(baston_c, 'Baston C', force_type='Buy')
        agregar_patron(baston_r, 'Baston R', force_type='Sell')

        
        return señales_1m_finales
    
class MarketStructureManager:
    """
    Gestiona y consolida los niveles de estructura de mercado identificados por los analizadores
    y niveles adicionales.
    """
    def __init__(self, m1_analyzer: FlexibleM1Analyzer = None,
                 m5_analyzer: FlexibleM5Analyzer = None,
                 additional_levels: Optional[List[Dict[str, Any]]] = None):
        self.m1_analyzer = m1_analyzer
        self.m5_analyzer = m5_analyzer
        self.additional_levels = additional_levels if additional_levels is not None else []
        logging.info("MarketStructureManager inicializado.")

    def update_analyzers(self, m1_analyzer: FlexibleM1Analyzer, m5_analyzer: FlexibleM5Analyzer,
                         additional_levels: Optional[List[Dict[str, Any]]] = None):
        self.m1_analyzer = m1_analyzer
        self.m5_analyzer = m5_analyzer
        self.additional_levels = additional_levels if additional_levels is not None else []
        logging.info("MarketStructureManager: Analizadores y niveles adicionales actualizados.")

    def get_all_levels(self, level_types: Optional[List[str]] = None) -> List[Dict[str, Any]]:
        """
        Extrae todos los niveles de los DataFrames de los analizadores y los niveles adicionales.
        """
        all_levels_dfs = []

        if self.m1_analyzer and not self.m1_analyzer.levels_df.empty:
            df1 = self.m1_analyzer.levels_df.copy()
            df1['Timeframe'] = 'M1'
            all_levels_dfs.append(df1)
            logging.debug(f"MarketStructureManager: Añadidos {len(df1)} niveles de M1.")

        if self.m5_analyzer and not self.m5_analyzer.levels_df.empty:
            df5 = self.m5_analyzer.levels_df.copy()
            df5['Timeframe'] = 'M5'
            all_levels_dfs.append(df5)
            logging.debug(f"MarketStructureManager: Añadidos {len(df5)} niveles de M5.")

        if self.additional_levels:
            df_additional = pd.DataFrame(self.additional_levels)
            if 'Timeframe' not in df_additional.columns:
                df_additional['Timeframe'] = 'ATR_Filtered' # Un timeframe para los niveles filtrados por ATR
            all_levels_dfs.append(df_additional)
            logging.debug(f"MarketStructureManager: Añadidos {len(df_additional)} niveles adicionales (ATR filtrados).")

        if not all_levels_dfs:
            logging.warning("MarketStructureManager: No se encontraron DataFrames de niveles en los analizadores ni niveles adicionales.")
            return []

        combined_df = pd.concat(all_levels_dfs, ignore_index=True)
        combined_df = combined_df.drop_duplicates(subset=['Date', 'Level', 'Type'])
        logging.debug(f"MarketStructureManager: Total de {len(combined_df)} niveles combinados.")

        if level_types:
            filtered_df = combined_df[
                combined_df['Type'].apply(lambda x: any(lt in x for lt in level_types))
            ]
            logging.debug(f"MarketStructureManager: Filtrados a {len(filtered_df)} niveles por tipo: {level_types}.")
            return filtered_df.to_dict('records')
        
        return combined_df.to_dict('records')

    def get_closest_level(self, current_price: float, level_types: Optional[List[str]] = None,
                          tendencia: Optional[str] = None, max_dist_percent: float = 0.0006) -> Optional[Dict[str, Any]]:
        levels_to_consider = self.get_all_levels(level_types=level_types)
        if not levels_to_consider:
            return None
        filtrados = []
        for level_info in levels_to_consider:
            level_price = level_info['Level']
            distancia_absoluta = abs(level_price - current_price)
            distancia_porcentual = distancia_absoluta / current_price
            if distancia_porcentual <= max_dist_percent:
                if tendencia and level_info.get('Trend') != tendencia:
                    continue
                filtrados.append((distancia_absoluta, level_info))
        filtrados.sort(key=lambda x: x[0])
        return filtrados[0][1] if filtrados else None

    def get_all_flips(self) -> List[Dict[str, Any]]:
        return self.get_all_levels(level_types=['Flip'])

import pandas as pd
import numpy as np
from typing import List, Dict, Tuple, Optional, Any
from dataclasses import dataclass
from datetime import datetime, timedelta
import logging

@dataclass
class LiquidityZone:
    """Clase unificada para representar zonas de liquidez"""
    price: float
    timestamp: datetime
    zone_type: str  # 'Equal_Highs', 'Equal_Lows', 'psychological', 'swing_high', 'swing_low'
    strength: float  # 0-100 (combinando ambos sistemas)
    num_touches: int
    volume_profile: float
    confidence: str  # 'Alta', 'Media', 'Baja'
    volume_ratio: float
    age_minutes: float = 0
    decay_factor: float = 1.0
    last_update: str = ""

@dataclass
class LiquiditySweep:
    """Representa un barrido de liquidez detectado"""
    zone: LiquidityZone
    sweep_price: float
    sweep_time: datetime
    volume_spike: float
    price_rejection: float
    confidence: float
    sweep_direction: str  # 'bullish_sweep', 'bearish_sweep'
    confirmation_score: float

class UnifiedLiquidityDetector:
    """
    Sistema unificado que combina detección de zonas y barridos de liquidez
    """
    
    def __init__(self, lookback_periods: int = 100, ventana_deteccion: int = 10):
        self.lookback_periods = lookback_periods
        self.ventana_deteccion = ventana_deteccion
        self.liquidity_zones: List[LiquidityZone] = []
        self.detected_sweeps: List[LiquiditySweep] = []
        self.trend_5m = 'Rango'  # Se actualiza externamente
        
    def detect_all_liquidity(self, data_1m: pd.DataFrame) -> Dict[str, Any]:
        """
        Método principal que detecta tanto zonas como barridos
        """
        try:
            if data_1m.empty:
                logging.warning("Data de 1 minuto vacía en detect_all_liquidity.")
                return {'zones': [], 'sweeps': [], 'signals': []}
            
            # Crear índice temporal si no existe
            if not isinstance(data_1m.index, pd.DatetimeIndex):
                data_1m = data_1m.copy()
                data_1m.index = pd.date_range(
                    start=pd.Timestamp.utcnow() - pd.Timedelta(minutes=len(data_1m)-1),
                    periods=len(data_1m),
                    freq='1min'
                )
            
            # Detectar zonas y barridos
            zones = self._detect_liquidity_zones(data_1m)
            sweeps = self._detect_liquidity_sweeps(data_1m)
            signals = self._generate_combined_signals(data_1m, zones, sweeps)
            
            # Actualizar estado interno
            self._update_internal_state(zones, sweeps)
            
            return {
                'zones': zones,
                'sweeps': sweeps,
                'signals': signals,
                'stats': self._get_detection_stats()
            }
            
        except Exception as e:
            logging.error(f"Error en detect_all_liquidity: {str(e)}")
            return {'zones': [], 'sweeps': [], 'signals': []}
    
    def _detect_liquidity_zones(self, data_1m: pd.DataFrame) -> List[Dict[str, Any]]:
        """
        Detección mejorada de zonas de liquidez combinando ambos enfoques
        """
        zones_signals = []
        current_price = data_1m['close'].iloc[-1]
        volume_threshold = data_1m['volume'].rolling(window=20).mean().iloc[-1] * 1.5
        
        # Parámetros refinados
        proximidad_relativa = current_price * 0.0015  # 0.015%
        proximidad_absoluta = 0.0015
        
        # Obtener el nombre correcto de la columna de tiempo
        time_column = 'timestamp' if 'timestamp' in data_1m.columns else data_1m.index

        # DETECCIÓN DE EQUAL HIGHS/LOWS
        for i in range(self.ventana_deteccion, len(data_1m)):
            ventana_velas = data_1m.iloc[i - self.ventana_deteccion : i]
            vela_actual = data_1m.iloc[i]
            
            # Equal Highs
            maximos = ventana_velas['high']
            if len(maximos) >= 2:
                max_val = maximos.max()
                tolerancia = max_val * 0.0001
                count_equal_highs = sum(abs(m - max_val) <= tolerancia for m in maximos)
                
                if count_equal_highs >= 2:
                    if abs(current_price - max_val) <= min(proximidad_relativa, proximidad_absoluta):
                        # Usar el índice temporal correcto
                        timestamp = vela_actual[time_column] if isinstance(time_column, str) else time_column[i]
                        
                        zone = self._create_liquidity_zone(
                            price=max_val,
                            timestamp=timestamp,
                            zone_type='Equal_Highs',
                            num_touches=count_equal_highs,
                            volume=vela_actual['volume'],
                            volume_threshold=volume_threshold
                        )
                        zones_signals.append(self._zone_to_signal(zone, 'Sell'))
            
            # Equal Lows
            minimos = ventana_velas['low']
            if len(minimos) >= 2:
                min_val = minimos.min()
                tolerancia = min_val * 0.0001
                count_equal_lows = sum(abs(m - min_val) <= tolerancia for m in minimos)
                
                if count_equal_lows >= 2:
                    if abs(current_price - min_val) <= min(proximidad_relativa, proximidad_absoluta):
                        # Usar el índice temporal correcto
                        timestamp = vela_actual[time_column] if isinstance(time_column, str) else time_column[i]
                        
                        zone = self._create_liquidity_zone(
                            price=min_val,
                            timestamp=timestamp,
                            zone_type='Equal_Lows',
                            num_touches=count_equal_lows,
                            volume=vela_actual['volume'],
                            volume_threshold=volume_threshold
                        )
                        zones_signals.append(self._zone_to_signal(zone, 'Buy'))
        
        return zones_signals
    
    def _detect_liquidity_sweeps(self, data_1m: pd.DataFrame) -> List[Dict[str, Any]]:
        """
        Detección avanzada de barridos de liquidez
        """
        sweep_signals = []
        
        if len(data_1m) < 20:
            return sweep_signals
        
        current_idx = len(data_1m) - 1
        current_price = data_1m['close'].iloc[current_idx]
        
        # Buscar zonas cercanas para posibles barridos
        nearby_zones = self._get_nearby_zones(current_price)
        
        for zone in nearby_zones:
            sweep = self._check_zone_sweep_advanced(data_1m, zone, current_idx)
            if sweep and sweep.confidence >= 0.6:
                sweep_signal = self._sweep_to_signal(sweep)
                sweep_signals.append(sweep_signal)
                
        return sweep_signals
    
    def _detect_psychological_levels(self, data_1m: pd.DataFrame, current_price: float) -> List[Dict[str, Any]]:
        """
        Detecta niveles psicológicos importantes
        """
        psych_signals = []
        
        # Generar niveles psicológicos cercanos
        base_level = self._round_to_psychological(current_price)
        levels_to_check = [
            base_level - 0.0100,  # 100 pips abajo
            base_level - 0.0050,  # 50 pips abajo
            base_level,           # Nivel actual
            base_level + 0.0050,  # 50 pips arriba
            base_level + 0.0100   # 100 pips arriba
        ]
        
        for level in levels_to_check:
            if abs(level - current_price) / current_price <= 0.02:  # Solo niveles cercanos (2%)
                # Calcular cuántas veces fue tocado este nivel
                touches = self._count_level_touches(data_1m, level)
                
                if touches >= 2:
                    zone = self._create_liquidity_zone(
                        price=level,
                        timestamp=data_1m['time'].iloc[-1],
                        zone_type='psychological',
                        num_touches=touches,
                        volume=data_1m['volume'].iloc[-20:].mean(),
                        volume_threshold=data_1m['volume'].iloc[-20:].mean()
                    )
                    
                    signal_type = 'Sell' if level > current_price else 'Buy'
                    psych_signals.append(self._zone_to_signal(zone, signal_type))
        
        return psych_signals
    
    def _detect_swing_levels(self, data_1m: pd.DataFrame) -> List[Dict[str, Any]]:
        """
        Detecta máximos y mínimos swing importantes
        """
        swing_signals = []
        window = 5
        
        # Swing Highs
        swing_highs = self._find_swing_highs(data_1m, window)
        for high_idx in swing_highs[-10:]:  # Solo últimos 10
            if high_idx < len(data_1m):
                zone = self._create_liquidity_zone(
                    price=data_1m['high'].iloc[high_idx],
                    timestamp=data_1m['time'].iloc[high_idx],
                    zone_type='swing_high',
                    num_touches=self._count_level_touches(data_1m, data_1m['high'].iloc[high_idx]),
                    volume=data_1m['volume'].iloc[high_idx],
                    volume_threshold=data_1m['volume'].iloc[max(0, high_idx-10):high_idx+10].mean()
                )
                swing_signals.append(self._zone_to_signal(zone, 'Sell'))
        
        # Swing Lows
        swing_lows = self._find_swing_lows(data_1m, window)
        for low_idx in swing_lows[-10:]:  # Solo últimos 10
            if low_idx < len(data_1m):
                zone = self._create_liquidity_zone(
                    price=data_1m['low'].iloc[low_idx],
                    timestamp=data_1m['time'].iloc[low_idx],
                    zone_type='swing_low',
                    num_touches=self._count_level_touches(data_1m, data_1m['low'].iloc[low_idx]),
                    volume=data_1m['volume'].iloc[low_idx],
                    volume_threshold=data_1m['volume'].iloc[max(0, low_idx-10):low_idx+10].mean()
                )
                swing_signals.append(self._zone_to_signal(zone, 'Buy'))
        
        return swing_signals
    
    def _check_zone_sweep_advanced(self, data_1m: pd.DataFrame, zone: LiquidityZone, current_idx: int) -> Optional[LiquiditySweep]:
        """
        Verificación avanzada de barridos con múltiples criterios
        """
        lookback = min(10, current_idx)
        
        for i in range(current_idx - lookback, current_idx + 1):
            if i < 0:
                continue
            
            high = data_1m['high'].iloc[i]
            low = data_1m['low'].iloc[i]
            close = data_1m['close'].iloc[i]
            volume = data_1m['volume'].iloc[i]
            
            # Detección de barrido según tipo de zona
            swept = False
            sweep_price = 0
            sweep_direction = ""
            
            if zone.zone_type in ['Equal_Highs', 'psychological', 'swing_high']:
                # Barrida alcista: rompe resistencia pero revierte
                if high >= zone.price and close < zone.price * 0.9995:  # Buffer más estricto
                    swept = True
                    sweep_price = high
                    sweep_direction = 'bearish_sweep'  # Barrida alcista que genera señal bajista
                    
            elif zone.zone_type in ['Equal_Lows', 'swing_low']:
                # Barrida bajista: rompe soporte pero revierte
                if low <= zone.price and close > zone.price * 1.0005:
                    swept = True
                    sweep_price = low
                    sweep_direction = 'bullish_sweep'  # Barrida bajista que genera señal alcista
            
            if swept:
                # Validaciones adicionales
                avg_volume = data_1m['volume'].iloc[max(0, i-20):i].mean()
                volume_spike = volume / avg_volume if avg_volume > 0 else 1
                
                # Cálculo de rechazo (wick ratio)
                if sweep_direction == 'bearish_sweep':
                    total_range = high - low
                    rejection = (high - close) / total_range if total_range > 0 else 0
                else:
                    total_range = high - low
                    rejection = (close - low) / total_range if total_range > 0 else 0
                
                # Confirmación en velas siguientes
                confirmation = self._check_sweep_confirmation_advanced(data_1m, i, zone, current_idx)
                
                # Confianza combinada
                confidence = self._calculate_sweep_confidence_advanced(
                    volume_spike, rejection, confirmation, zone.strength, zone.num_touches
                )
                
                if confidence >= 0.6:
                    return LiquiditySweep(
                        zone=zone,
                        sweep_price=sweep_price,
                        sweep_time=data_1m['time'].iloc[i],
                        volume_spike=volume_spike,
                        price_rejection=rejection,
                        confidence=confidence,
                        sweep_direction=sweep_direction,
                        confirmation_score=confirmation
                    )
        
        return None
    
    def _generate_combined_signals(self, data_1m: pd.DataFrame, zones: List[Dict], sweeps: List[Dict]) -> List[Dict[str, Any]]:
        """
        Genera señales combinando zonas y barridos
        """
        combined_signals = []
        
        # Añadir señales de zonas
        for zone_signal in zones:
            zone_signal['source'] = 'zone_detection'
            combined_signals.append(zone_signal)
        
        # Añadir señales de barridos
        for sweep_signal in sweeps:
            sweep_signal['source'] = 'sweep_detection'
            sweep_signal['priority'] = 'high'
            combined_signals.append(sweep_signal)
        
        # Filtrar señales conflictivas
        filtered_signals = self._filter_conflicting_signals(combined_signals)
        
        # Función de conversión de confianza a valor numérico
        def get_confidence_value(signal):
            confidence = signal.get('Confidence', signal.get('confidence', 'Baja'))
            if isinstance(confidence, (int, float)):
                return float(confidence)
            # Mapear valores de texto a números
            confidence_map = {
                'Alta': 0.9,
                'Media': 0.6,
                'Baja': 0.3
            }
            return confidence_map.get(confidence, 0.0)

        # Ordenar señales
        filtered_signals.sort(key=lambda x: (
            x.get('priority') == 'high',
            get_confidence_value(x)
        ), reverse=True)
        
        return filtered_signals[:5]
    
    # MÉTODOS AUXILIARES
    def _create_liquidity_zone(self, price: float, timestamp: Any, zone_type: str, 
                         num_touches: int, volume: float, volume_threshold: float) -> LiquidityZone:
        """Crea una zona de liquidez unificada"""
        try:
            confidence = self._calculate_zone_confidence(volume, volume_threshold, num_touches)
            strength = self._calculate_zone_strength_unified(num_touches, volume, volume_threshold)
            
            # Si no hay timestamp, usar la fecha actual
            if timestamp is None:
                timestamp = datetime.utcnow()
            
            # Crear el objeto LiquidityZone
            return LiquidityZone(
                price=float(price),
                timestamp=pd.to_datetime(timestamp),
                zone_type=str(zone_type),
                strength=float(strength),
                num_touches=int(num_touches),
                volume_profile=float(volume),
                confidence=str(confidence),
                volume_ratio=float(volume / volume_threshold if volume_threshold > 0 else 1.0)
            )
        except Exception as e:
            logging.error(f"Error creando zona de liquidez: {e}")
            # Retornar una zona con valores por defecto
            return LiquidityZone(
                price=float(price),
                timestamp=datetime.utcnow(),
                zone_type=str(zone_type),
                strength=50.0,
                num_touches=1,
                volume_profile=1.0,
                confidence="Baja",
                volume_ratio=1.0
            )
        
    def _calculate_zone_confidence(self, volume: float, volume_threshold: float, num_touches: int) -> str:
        """Calcula confianza de zona"""
        volume_ratio = volume / volume_threshold if volume_threshold > 0 else 1.0
        
        if volume_ratio > 2.0 and num_touches >= 3:
            return "Alta"
        elif volume_ratio > 1.5 or num_touches >= 2:
            return "Media"
        return "Baja"
    
    def _calculate_zone_strength_unified(self, num_touches: int, volume: float, volume_threshold: float) -> float:
        """Calcula fuerza unificada (0-100)"""
        base_strength = min(num_touches * 20, 60)  # Máximo 60 puntos por toques
        volume_bonus = min((volume / volume_threshold - 1) * 20, 40) if volume_threshold > 0 else 0
        return max(0, min(100, base_strength + volume_bonus))
    
    def _zone_to_signal(self, zone: LiquidityZone, signal_type: str) -> Dict[str, Any]:
        """Convierte zona a señal de trading"""
        return {
            'Categoria': 'Liquidez',
            'Type': signal_type,
            'Level': zone.price,
            'Timestamp': zone.timestamp,
            'Esquema': 'Fuerte' if zone.num_touches >= 3 else 'Normal',
            'Confidence': zone.confidence,
            'Trend': self.trend_5m,
            'price_action': -1 if signal_type == 'Sell' else 1,
            'descripcion': f'Zona {zone.zone_type}: {zone.num_touches} toques en {zone.price:.5f}',
            'zona_liquidez_tipo': zone.zone_type,
            'volume_ratio': zone.volume_ratio,
            'num_toques': zone.num_touches,
            'strength': zone.strength
        }
    
    def _sweep_to_signal(self, sweep: LiquiditySweep) -> Dict[str, Any]:
        """Convierte barrido a señal de trading"""
        signal_type = 'Buy' if sweep.sweep_direction == 'bullish_sweep' else 'Sell'
        
        return {
            'Categoria': 'Liquidez',
            'Type': signal_type,
            'Level': sweep.sweep_price,
            'Timestamp': sweep.sweep_time,
            'Esquema': 'Sweep',
            'Confidence': 'Alta' if sweep.confidence > 0.8 else 'Media',
            'Trend': self.trend_5m,
            'price_action': 1 if signal_type == 'Buy' else -1,
            'descripcion': f'Barrido {sweep.zone.zone_type} en {sweep.sweep_price:.5f} (conf: {sweep.confidence:.2f})',
            'zona_liquidez_tipo': f'Sweep_{sweep.zone.zone_type}',
            'volume_spike': sweep.volume_spike,
            'price_rejection': sweep.price_rejection,
            'confidence_numeric': sweep.confidence,
            'sweep_direction': sweep.sweep_direction
        }
    
    def _is_psychological_level(self, price: float) -> bool:
        """Detecta niveles psicológicos"""
        rounded = round(price, 4)
        return rounded % 0.0050 == 0 or rounded % 0.0100 == 0
    
    def _round_to_psychological(self, price: float) -> float:
        """Redondea al nivel psicológico más cercano"""
        return round(price / 0.0050) * 0.0050
    
    def _count_level_touches(self, data_1m: pd.DataFrame, level: float) -> int:
        """Cuenta cuántas veces un nivel fue tocado"""
        tolerance = level * 0.0005  # 0.05% tolerance
        touches = 0
        
        for i in range(len(data_1m)):
            if (abs(data_1m['high'].iloc[i] - level) <= tolerance or 
                abs(data_1m['low'].iloc[i] - level) <= tolerance):
                touches += 1
        
        return touches
    
    def _find_swing_highs(self, df: pd.DataFrame, window: int = 5) -> List[int]:
        """Encuentra máximos swing"""
        highs = []
        for i in range(window, len(df) - window):
            if all(df['high'].iloc[i] >= df['high'].iloc[j] 
                  for j in range(i-window, i+window+1) if j != i):
                highs.append(i)
        return highs
    
    def _find_swing_lows(self, df: pd.DataFrame, window: int = 5) -> List[int]:
        """Encuentra mínimos swing"""
        lows = []
        for i in range(window, len(df) - window):
            if all(df['low'].iloc[i] <= df['low'].iloc[j] 
                  for j in range(i-window, i+window+1) if j != i):
                lows.append(i)
        return lows
    
    def _get_nearby_zones(self, current_price: float) -> List[LiquidityZone]:
        """Obtiene zonas cercanas al precio actual"""
        nearby = []
        for zone in self.liquidity_zones:
            if abs(zone.price - current_price) / current_price <= 0.02:  # 2%
                nearby.append(zone)
        return nearby
    
    def _check_sweep_confirmation_advanced(self, data_1m: pd.DataFrame, sweep_idx: int, 
                                         zone: LiquidityZone, current_idx: int) -> float:
        """Confirmación avanzada de barridos"""
        if current_idx <= sweep_idx:
            return 0.5
            
        confirmations = 0
        total_checks = min(5, current_idx - sweep_idx)
        
        for i in range(sweep_idx + 1, sweep_idx + total_checks + 1):
            if i >= len(data_1m):
                break
                
            close = data_1m['close'].iloc[i]
            
            if zone.zone_type in ['Equal_Highs', 'psychological', 'swing_high']:
                if close < zone.price * 0.995:  # Confirmación bajista
                    confirmations += 1
            else:
                if close > zone.price * 1.005:  # Confirmación alcista
                    confirmations += 1
        
        return confirmations / total_checks if total_checks > 0 else 0.5
    
    def _calculate_sweep_confidence_advanced(self, volume_spike: float, rejection: float,
                                           confirmation: float, zone_strength: float, 
                                           num_touches: int) -> float:
        """Cálculo avanzado de confianza en barridos"""
        # Pesos ajustados
        volume_score = min(volume_spike / 2.0, 1.0) * 0.25  # 25%
        rejection_score = rejection * 0.25  # 25%
        confirmation_score = confirmation * 0.20  # 20%
        strength_score = (zone_strength / 100) * 0.15  # 15%
        touches_score = min(num_touches / 5.0, 1.0) * 0.15  # 15%
        
        return volume_score + rejection_score + confirmation_score + strength_score + touches_score
    
    def _filter_conflicting_signals(self, signals: List[Dict]) -> List[Dict]:
        """Filtra señales conflictivas"""
        filtered = []
        seen_levels = set()
        
        for signal in signals:
            level = round(signal.get('Level', 0), 4)
            key = (level, signal.get('Type'))
            
            if key not in seen_levels:
                seen_levels.add(key)
                filtered.append(signal)
        
        return filtered
    
    def _update_internal_state(self, zones: List[Dict], sweeps: List[Dict]) -> None:
        """Actualiza estado interno del detector"""
        # Convertir señales de zonas a objetos LiquidityZone
        current_zones = []
        for zone_signal in zones:
            if 'Level' in zone_signal:
                zone = LiquidityZone(
                    price=zone_signal['Level'],
                    timestamp=pd.to_datetime(zone_signal['Timestamp']),
                    zone_type=zone_signal.get('zona_liquidez_tipo'),
                    strength=zone_signal.get('strength', 50),
                    num_touches=zone_signal.get('num_toques', 1),
                    volume_profile=zone_signal.get('volume_ratio', 1.0),
                    confidence=zone_signal.get('Confidence', 'Media'),
                    volume_ratio=zone_signal.get('volume_ratio', 1.0)
                )
                current_zones.append(zone)
        
        self.liquidity_zones = current_zones
        
        # Actualizar sweeps detectados
        # (Los sweeps ya están procesados en el formato correcto)
        
    def _get_detection_stats(self) -> Dict[str, Any]:
        """Obtiene estadísticas de detección"""
        return {
            'total_zones': len(self.liquidity_zones),
            'total_sweeps': len(self.detected_sweeps),
            'zones_by_type': {
                zone_type: len([z for z in self.liquidity_zones if z.zone_type == zone_type])
                for zone_type in set([z.zone_type for z in self.liquidity_zones])
            },
            'avg_zone_strength': np.mean([z.strength for z in self.liquidity_zones]) if self.liquidity_zones else 0,
            'high_confidence_zones': len([z for z in self.liquidity_zones if z.confidence == 'Alta'])
        }
    def _validate_liquidity_signal(self, zone: Dict) -> bool:
        """Validación mejorada de señales de liquidez"""
        try:
            if not isinstance(zone, dict):
                return False
                
            # Validar fuerza mínima
            strength = float(zone.get('strength', 0))
            if strength < 40:  # Reducir umbral de fuerza
                return False
                
            # Validar número de toques
            num_touches = int(zone.get('num_touches', 0))
            if num_touches < 2:  # Reducir requisito de toques
                return False
                
            # Validar ratio de volumen
            volume_ratio = float(zone.get('volume_ratio', 0))
            if volume_ratio < 0.8:  # Hacer más flexible
                return False
                
            return True
            
        except Exception as e:
            logging.error(f"Error validando zona de liquidez: {e}")
            return False



class TradingBot:
    def __init__(self, api):
        """
        Inicializa el TradingBot con configuraciones y estructuras necesarias.
        
        Args:
            api: API de trading
        """
        # Configuración básica
        self.api = api
        self.total_profit = 0
        self.current_amount = 10
        self.target_profit = 10
        self.asset = None
        self.otc = False
        self.todas_las_senales = []
        
        # Fecha y usuario actual
        self.current_date = datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S")
        self.current_user = "gonzalo00123"
        
        # Obtener información del activo
        self.get_asset_info()

        # Inicializar analizadores
        try:
            self.m30_analyzer = M30Analyzer()
            self.m5_analyzer = M5Analyzer() 
            self.m1_analyzer = M1Analyzer()
            self.flexible_m5_analyzer = FlexibleM5Analyzer()
            self.flexible_m1_analyzer = FlexibleM1Analyzer()
            logging.info("Analizadores inicializados correctamente")
        except Exception as e:
            logging.error(f"Error inicializando analizadores: {e}")
            raise

        # Cargar modelos de IA
        try:
            self.modelo_niveles = joblib.load("modelo_niveles.pkl")
            self.modelo_signal = joblib.load("modelo_lightgbm.pkl")  # Renombrado para consistencia
            self.modelo_direccion = modelo_direccion
            self.scaler_direccion = scaler_direccion
            self.label_encoders_direccion = label_encoders_direccion
            logging.info("Modelos de IA cargados correctamente")
        except Exception as e:
            logging.error(f"Error cargando modelos de IA: {e}")
            raise

        # Control de tiempo y datos
        self.last_trade_time = None
        self.data_30m = pd.DataFrame()
        self.data_5m = pd.DataFrame()
        self.data_1m = pd.DataFrame()
        self.señales_activas = []
        self.último_resultado = None
        self.última_actualización = None
        self.current_user = "gonzalo00123"
        self.symbol = None 
        # Estructuras para señales y análisis
        self._init_signal_structures()
        
        # Estructuras de mercado
        self._init_market_structures()
        
        # Añadir métodos auxiliares
        self._add_structure_methods()
        
        logging.info(f"Bot configurado para operar con {self.asset}")
    
    def get_current_market_structure(self, data_1m):
        """
        Obtiene la estructura actual del mercado basado en los datos de 1 minuto.
        
        Args:
            data_1m (pd.DataFrame): DataFrame con los datos de 1 minuto
            
        Returns:
            dict: Diccionario con la estructura actual del mercado
        """
        try:
            if data_1m is None or data_1m.empty:
                return {
                    "current_trend": None,
                    "last_bos_choch": None,
                    "bos_choch_events": []
                }

            # Detectar tendencia
            ventana_sma = 20
            sma = data_1m['close'].rolling(window=ventana_sma).mean()
            current_price = data_1m['close'].iloc[-1]
            
            tendencia_base = "Bullish" if current_price > sma.iloc[-1] else "Bearish"

            # Eventos BOS/CHoCH
            bos_choch_events = []
            ultima_estructura = None

            if hasattr(self, 'estructura_smc') and self.estructura_smc:
                if self.estructura_smc.get("bos"):
                    bos_choch_events.append({
                        "tipo": "BOS",
                        "direccion": self.estructura_smc["bos"].get("tipo"),
                        "nivel": self.estructura_smc["bos"].get("nivel"),
                        "tiempo": self.estructura_smc["bos"].get("tiempo")
                    })
                    ultima_estructura = "BOS"

                if self.estructura_smc.get("choch"):
                    bos_choch_events.append({
                        "tipo": "CHoCH",
                        "direccion": self.estructura_smc["choch"].get("tipo"),
                        "nivel": self.estructura_smc["choch"].get("nivel"),
                        "tiempo": self.estructura_smc["choch"].get("tiempo")
                    })
                    ultima_estructura = "CHoCH"

            # Determinar tendencia final
            tendencia_final = tendencia_base
            if bos_choch_events:
                ultimo_evento = bos_choch_events[-1]
                if ultimo_evento["direccion"] == "alcista":
                    tendencia_final = "Bullish"
                elif ultimo_evento["direccion"] == "bajista":
                    tendencia_final = "Bearish"

            return {
                "current_trend": tendencia_final,
                "last_bos_choch": ultima_estructura,
                "bos_choch_events": bos_choch_events,
                "timestamp": datetime.now().isoformat(),
                "price": current_price,
                "sma20": sma.iloc[-1]
            }

        except Exception as e:
            logging.error(f"Error en get_current_market_structure: {e}")
            return {
                "current_trend": None,
                "last_bos_choch": None,
                "bos_choch_events": []
            }

    def _init_signal_structures(self):
        """Inicializa las estructuras relacionadas con señales"""
        # Señales actuales
        self.current_signal = None
        
        # Estructuras de flips
        self.relevant_flips = []
        self.recent_flips_1m = []
        self.flip_1m_recientes = []
        
        # Parámetros y señales FVG
        self.fvg_max_patterns = 5
        self.fvg_ignore_proximity = True
        self.fvg_signals = []

        # Otras estructuras de señales
        self.orderblocks = []
        self.sibi_bisi = []
        self.bos_choch = []
        self.todas_las_senales = []

    def _init_market_structures(self):
        """Inicializa las estructuras del mercado"""
        try:
            # Estructura unificada del mercado
            self.estructura_mercado = {
                # Información general
                "current_trend": "Lateral",
                "last_update": self.current_date,
                "user": self.current_user,
                
                # Estructura SMC
                "smc": {
                    "current_trend": "Lateral",
                    "bos": None,
                    "choch": None,
                    "ob_bull": [],
                    "ob_bear": [],
                    "fvg_bull": [],
                    "fvg_bear": []
                },
                
                # Estructura tradicional
                "tradicional": {
                    "current_trend": "Lateral",
                    "sibi": "none",
                    "bisi": "none",
                    "bos": "none",
                    "choch": "none",
                    "last_bos_choch": None,
                    "bos_choch_events": []
                },
                
                # Flips y otros elementos
                "flips": {
                    "recientes": 0,
                    "influence_active": False,
                    "lista": []
                }
            }
            
            # Inicializar listas de señales
            self.todas_las_senales = []
            self.orderblocks = []
            self.bos_choch = []
            self.sibi_bisi = []
            
            logging.info("Estructuras de mercado inicializadas correctamente")
            
        except Exception as e:
            logging.error(f"Error inicializando estructuras de mercado: {e}")
            self.estructura_mercado = {
                "current_trend": "Lateral",
                "smc": {"current_trend": "Lateral"},
                "tradicional": {"current_trend": "Lateral"}
            }
            self.todas_las_senales = []
        
        # Lista unificada de señales
        self.todas_las_senales = []
    def filtrar_por_estructura(self, señales):
        """
        Filtra las señales basándose en la estructura actual del mercado.
        
        Args:
            señales (list): Lista de señales a filtrar
            
        Returns:
            list: Señales filtradas que coinciden con la estructura actual
        """
        try:
            if not señales:
                logging.debug("No hay señales para filtrar")
                return []
                
            if not self.estructura_mercado:
                logging.debug("No hay estructura de mercado, retornando todas las señales")
                return señales

            # Obtener tendencia actual
            current_trend = self.estructura_mercado.get("current_trend", "Lateral")
            
            # Verificar BOS y CHOCH activos
            bos_activo = self.estructura_mercado.get("bos") != "none"
            choch_activo = self.estructura_mercado.get("choch") != "none"
            flip_influence = self.estructura_mercado.get("flip_influence_active", False)

            # Filtrar señales
            señales_filtradas = []
            for señal in señales:
                if not isinstance(señal, dict):
                    continue

                tipo_señal = señal.get("Type")
                if not tipo_señal:
                    continue

                # Verificar coherencia con estructura
                coherente_con_estructura = (
                    (tipo_señal == "Buy" and current_trend == "Bullish") or
                    (tipo_señal == "Sell" and current_trend == "Bearish") or
                    (señal.get("Esquema") == "CHoCH" and choch_activo) or
                    current_trend == "Lateral" or
                    (señal.get("Esquema") == "BOS" and bos_activo) or
                    (señal.get("Categoria") == "Flip" and 
                     señal.get("is_recent_flip", False) and 
                     flip_influence)
                )

                if coherente_con_estructura:
                    señales_filtradas.append(señal)

            logging.info(f"Filtrado por estructura: {len(señales)} -> {len(señales_filtradas)} señales")
            logging.info(f"Tendencia: {current_trend}, BOS: {'activo' if bos_activo else 'inactivo'}, " +
                        f"CHoCH: {'activo' if choch_activo else 'inactivo'}, " +
                        f"Flip Influence: {'activo' if flip_influence else 'inactivo'}")
            return señales_filtradas

        except Exception as e:
            logging.error(f"Error en filtrar_por_estructura: {e}")
            traceback.print_exc()
            return señales
    def _add_structure_methods(self):
        """
        Añade métodos auxiliares para el manejo de estructura.
        Incluye conversión de BOS y CHoCH a señales estandarizadas.
        """
        def _convertir_bos_a_señales(self, bos_list):
            """
            Convierte eventos BOS a señales estandarizadas.
            
            Args:
                bos_list (list): Lista de eventos BOS
                
            Returns:
                list: Lista de señales estandarizadas
            """
            señales = []
            if not bos_list:
                return señales

            for bos in bos_list:
                if not isinstance(bos, dict):
                    continue

                señal = {
                    "Type": "Buy" if bos.get("tipo") == "alcista" else "Sell",
                    "Level": bos.get("nivel", 0),
                    "timestamp": bos.get("tiempo", datetime.now().isoformat()),
                    "Categoria": "Estructura",
                    "Strategy": "BOS_Strategy",
                    "Confidence": "Alta",
                    "Reason": "Break of Structure",
                    "OrderBlockRelacionado": False,
                    "Esquema": "BOS",
                    "Nombre": f"BOS {'alcista' if bos.get('tipo') == 'alcista' else 'bajista'}",
                    "DireccionEstructural": bos.get("tipo", "indefinida")
                }
                señales.append(señal)
            return señales

        def _convertir_choch_a_señales(self, choch_list):
            """
            Convierte eventos CHoCH a señales estandarizadas.
            
            Args:
                choch_list (list): Lista de eventos CHoCH
                
            Returns:
                list: Lista de señales estandarizadas
            """
            señales = []
            if not choch_list:
                return señales

            for choch in choch_list:
                if not isinstance(choch, dict):
                    continue

                señal = {
                    "Type": "Buy" if choch.get("tipo") == "alcista" else "Sell",
                    "Level": choch.get("nivel", 0),
                    "timestamp": choch.get("tiempo", datetime.now().isoformat()),
                    "Categoria": "Estructura",
                    "Strategy": "CHoCH_Strategy",
                    "Confidence": "Alta",
                    "Reason": "Change of Character",
                    "OrderBlockRelacionado": False,
                    "Esquema": "CHoCH",
                    "Nombre": f"CHoCH {'alcista' if choch.get('tipo') == 'alcista' else 'bajista'}",
                    "DireccionEstructural": choch.get("tipo", "indefinida")
                }
                señales.append(señal)
            return señales

        # Asignar métodos a la instancia
        self._convertir_bos_a_señales = types.MethodType(_convertir_bos_a_señales, self)
        self._convertir_choch_a_señales = types.MethodType(_convertir_choch_a_señales, self)
    
    def actualizar_estructura_con_resumen(self):
        try:
            # Ejecutar detección completa
            resultados_estructura = ejecutar_deteccion_completa(
                self.data_1m,
                max_patrones=5,
                ignorar_proximidad=True
            )
            
            # Actualizar estructura del mercado
            self.estructura_mercado.update({
                "bos_choch": resultados_estructura["bos_choch"],
                "ultima_actualizacion": resultados_estructura["timestamp"]
            })
            
            # Actualizar señales si es necesario
            if resultados_estructura["bos_choch"]["bos"]:
                self.todas_las_senales.extend(self._convertir_bos_a_señales(
                    resultados_estructura["bos_choch"]["bos"]
                ))
                
            if resultados_estructura["bos_choch"]["choch"]:
                self.todas_las_senales.extend(self._convertir_choch_a_señales(
                    resultados_estructura["bos_choch"]["choch"]
                ))
                
        except Exception as e:
            logging.error(f"Error en actualizar_estructura_con_resumen: {e}")
    def analizar_con_smc(self, data_1m, data_5m):
        """
        Analiza el mercado usando Smart Money Concepts.
        Combina análisis de ambos timeframes.

        Args:
            data_1m (pd.DataFrame): Datos del timeframe de 1 minuto
            data_5m (pd.DataFrame): Datos del timeframe de 5 minutos

        Returns:
            list: Lista de señales detectadas
        """
        try:
            # Inicializar SMC
            self.smc = SmartMoneyConcepts(data_1m, data_5m)
            
            # Análisis inicial SMC
            resultado_smc = self.smc.analyze(ignorar_proximidad=True)
            señales_combinadas = []

            if resultado_smc:
                señales_combinadas.extend(resultado_smc["señales"])
                self.estructura_smc = resultado_smc["estructura"]

            # Análisis tradicional BOS/CHoCH
            resultados_bos_choch = self.smc.detect_bos_choch(
                data=data_1m,
                tendencia_actual=self.estructura_smc.get("current_trend"),
                ventana_estructura=10,
                confirmacion=True,
                max_patrones=5,
                ignorar_proximidad=True
            )

            if resultados_bos_choch and "señales" in resultados_bos_choch:
                señales_combinadas.extend(resultados_bos_choch["señales"])

            # Eliminar duplicados basados en Timestamp y Type
            señales_unicas = []
            timestamps_tipos_vistos = set()

            for señal in señales_combinadas:
                timestamp_tipo = (señal['Timestamp'], señal['Type'])
                if timestamp_tipo not in timestamps_tipos_vistos:
                    timestamps_tipos_vistos.add(timestamp_tipo)
                    señales_unicas.append(señal)

            # Ordenar por timestamp más reciente
            señales_unicas.sort(key=lambda x: x['Timestamp'], reverse=True)

            # Actualizar estructuras internas
            self._actualizar_estructuras_internas(señales_unicas)

            return señales_unicas

        except Exception as e:
            logging.error(f"Error en analizar_con_smc: {e}")
            return []

    def _actualizar_estructuras_internas(self, señales):
        """
        Actualiza las estructuras internas basadas en las señales detectadas.
        
        Args:
            señales (list): Lista de señales a procesar
        """
        try:
            # Categorizar señales
            for señal in señales:
                categoria = señal.get('Categoria', '')
                if categoria == 'OrderBlock':
                    self.orderblocks.append(señal)
                elif categoria == 'Estructura':
                    self.bos_choch.append(señal)
                
                # Actualizar FVG/SIBI/BISI si corresponde
                if señal.get('Reason') in ['FVG', 'SIBI', 'BISI']:
                    self.sibi_bisi.append(señal)

        except Exception as e:
            logging.error(f"Error en _actualizar_estructuras_internas: {e}")  

    def validate_structures_consistency(self):
        smc_trend = self.estructura_mercado["smc"]["current_trend"]
        trad_trend = self.estructura_mercado["tradicional"]["current_trend"]
        if smc_trend != trad_trend:
            logging.warning(f"Inconsistency detected: SMC trend: {smc_trend}, Traditional trend: {trad_trend}") 

    def sync_structure_trends(self):
        current_trend = self.estructura_mercado["current_trend"]
        self.estructura_mercado["smc"]["current_trend"] = current_trend
        self.estructura_mercado["tradicional"]["current_trend"] = current_trend          
                    
    # Método evaluar_signal movido a la implementación anterior
    
    def _ensure_volume_column(self, df, timeframe):
        if df is not None and not df.empty and 'volume' not in df.columns:
            # Volumen sintético basado en rango (más realista)
            df['volume'] = (df['high'] - df['low']) * 1000
            logging.info(f"Volumen sintético generado para {timeframe}")
            
        # Asegurar que sea numérico
        if 'volume' in df.columns:
            df['volume'] = pd.to_numeric(df['volume'], errors='coerce').fillna(1.0)
    def evaluar_niveles(self, señal):
        # Evaluar el nivel con el Modelo de Niveles
        X_nivel = pd.DataFrame([self.convertir_a_features_niveles(señal)])
        prob_nivel = self.modelo_niveles.predict_prob(X_nivel)
        print(f"Probabilidad de nivel: {prob_nivel}")
        return prob_nivel[0][1] >= self.umbral_niveles
                  
    def elegir_mejor_senal(self):
        """
        Elige la mejor señal basada en múltiples criterios y con mejor manejo de errores.
        """
        try:
            # Get current timestamp and user
            current_timestamp = datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S")
            current_user = "gonzalo00123"

            if not self.todas_las_senales:
                logging.info("No hay señales para evaluar")
                return None

            # Filtrar señales inválidas y logging de diagnóstico
            señales_validas = []
            for señal in self.todas_las_senales:
                if not isinstance(señal, dict):
                    logging.warning(f"Señal inválida (no es diccionario): {señal}")
                    continue
                    
                if 'Level' not in señal:
                    logging.warning(f"Señal sin nivel: {señal.get('Nombre', 'Desconocida')}")
                    continue
                    
                try:
                    nivel = float(señal['Level'])
                    señal['Level'] = nivel
                    
                    # Initialize or update basic metadata
                    señal.update({
                        "timestamp": current_timestamp,
                        "last_updated_by": current_user
                    })
                except (ValueError, TypeError):
                    logging.warning(f"Nivel inválido en señal: {señal.get('Level')}")
                    continue
                    
                señales_validas.append(señal)
                
            if not señales_validas:
                logging.info("No hay señales válidas después del filtrado inicial")
                return None
                
            # Obtener precio actual
            current_price = self.data_1m['close'].iloc[-1] if not self.data_1m.empty else None
            if current_price is None:
                logging.error("No se pudo obtener el precio actual")
                return None
                
            # Calcular distancias y filtrar por proximidad
            UMBRAL_MAXIMO = current_price * 0.003  # 0.3% máximo de distancia
            señales_por_distancia = []
            
            for señal in señales_validas:
                try:
                    distancia = abs(señal['Level'] - current_price)
                    distancia_porcentual = (distancia / current_price) * 100
                    
                    # Update signal with distance metrics
                    señal.update({
                        'distancia_precio_actual': distancia,
                        'distancia_porcentual': distancia_porcentual,
                        'distancia_relativa': distancia / current_price
                    })
                    
                    if distancia <= UMBRAL_MAXIMO:
                        señales_por_distancia.append(señal)
                        logging.debug(f"Señal {señal.get('Nombre', 'Desconocida')} a {distancia_porcentual:.3f}% del precio")
                except Exception as e:
                    logging.warning(f"Error calculando distancia para señal: {str(e)}")
                    continue
                    
            if not señales_por_distancia:
                logging.info(f"No hay señales dentro del umbral de distancia ({UMBRAL_MAXIMO})")
                return None
                
            # Evaluar señales con IA y filtrar
            señales_evaluadas = []
            for señal in señales_por_distancia:
                try:
                    self.evaluar_con_modelos_ia(señal)
                    
                    # Update IA evaluation timestamp
                    señal['ia_evaluation_timestamp'] = current_timestamp
                    
                    if señal.get('ia_decision') == 'buena' and señal.get('probabilidad_win', 0) >= 0.5:
                        señales_evaluadas.append(señal)
                        logging.info(f"Señal aprobada por IA: {señal.get('Nombre')} (Prob: {señal.get('probabilidad_win', 0):.2f})")
                except Exception as e:
                    logging.warning(f"Error al evaluar señal con IA: {e}")
                    continue
                    
            if not señales_evaluadas:
                logging.info("No hay señales que pasen la evaluación de IA")
                return None
                
            # Seleccionar la mejor señal
            mejor_señal = max(señales_evaluadas, 
                            key=lambda x: (x.get('probabilidad_win', 0),
                                        -x.get('distancia_precio_actual', float('inf'))))
            
            # Update final selection metadata
            mejor_señal.update({
                "selected_at": current_timestamp,
                "selected_by": current_user,
                "selection_criteria": {
                    "probabilidad_win": mejor_señal.get('probabilidad_win', 0),
                    "distancia_precio_actual": mejor_señal.get('distancia_precio_actual', 0),
                    "ia_decision": mejor_señal.get('ia_decision', ''),
                    "timestamp": current_timestamp
                }
            })
                                        
            logging.info(f"""Mejor señal seleccionada:
            - Nombre: {mejor_señal.get('Nombre', 'Desconocida')}
            - Nivel: {mejor_señal.get('Level')}
            - Distancia: {mejor_señal.get('distancia_porcentual', 0):.3f}%
            - Probabilidad: {mejor_señal.get('probabilidad_win', 0):.2f}
            - Seleccionada en: {current_timestamp}
            """)
            
            return mejor_señal
            
        except Exception as e:
            logging.error(f"Error al elegir mejor señal: {e}")
            traceback.print_exc()  # Add stack trace for better debugging
            return None

    def preparar_caracteristicas_direccion(self, señal):
        """
        Extrae y prepara las características de la señal para el modelo de dirección del mercado.
        Devuelve None si faltan características.
        """
        try:
            # Asegúrate de que los nombres de las claves en 'señal' coincidan con los nombres de las columnas que espera el modelo.
            features_direccion = {
                'price_action': señal['price_action'],
                'trend': señal['trend'],
                'body_size': señal['body_size'],
                'mecha_superior_pct': señal['mecha_superior_pct'],
                'mecha_inferior_pct': señal['mecha_inferior_pct'],
                'prev_body_size': señal['prev_body_size'],  # Asegúrate de tener esto en 'señal'
                'ob_body_size': señal['ob_body_size']     # Asegúrate de tener esto en 'señal'
            }
            # Verifica si alguna característica falta en la señal.
            if not all(key in señal for key in features_direccion):
                logging.warning(f"Faltan características para el modelo de dirección del mercado en la señal: {señal}")
                return None
            return pd.Series(features_direccion)
        except KeyError as e:
            logging.error(f"Error al extraer características para el modelo de dirección: {e}")
            return None
        except Exception as e:
            logging.error(f"Error inesperado al preparar características de dirección: {e}")
            return None

    def convertir_a_features_niveles(self, señal):
        """
        Convierte una señal en un diccionario de características para el modelo de niveles.
        """
        features = {
            'body_size': señal.get('body_size', 0),
            'mecha_superior_pct': señal.get('mecha_superior_pct', 0),
            'mecha_inferior_pct': señal.get('mecha_inferior_pct', 0),
            'prev_body_size': señal.get('prev_body_size', 0),
            'ob_body_size': señal.get('ob_body_size', 0),
            'price_action': 1 if señal['price_action'] == 'alcista' else 0,
            'trend': 1 if señal['trend'] == 'alcista' else 0,
            'time': señal['time'].timestamp()
        }
        return features

    def analizar_mercado(self, data_1m, data_5m, data_30m):
        """
        Integra todos los análisis y devuelve una lista de señales filtradas.
        """
        try:
            # Update market structure
            self.actualizar_estructura_mercado(data_1m, data_5m, data_30m)
            
            # Get all signals
            all_signals = []
            
            # Your existing signal collection code
            niveles_filtrados = self.detectar_niveles_relevantes(data_5m)
            
            analysis_methods = [
                lambda: self.detectar_orderblocks(data_5m, data_1m, niveles_filtrados),
                lambda: self.detectar_consolidaciones(data_5m, niveles_filtrados),
                lambda: self._detect_fvg(data_5m),
                lambda: self._detectar_bos_choch(data_1m),
                lambda: self.get_flip_info(self.flexible_m1_analyzer, self.flexible_m5_analyzer),
                lambda: self.detectar_liquidez(data_1m),
                lambda: self.smc.detect_orderblocks(data_1m),
                lambda: self.smc.detect_fair_value_gaps(data_1m),
                lambda: self.smc.detect_bos_choch(data_1m)
            ]
            
            for method in analysis_methods:
                try:
                    signals = method()
                    if signals:
                        all_signals.extend(signals)
                except Exception as e:
                    logging.error(f"Error en método de análisis: {e}")
            
            # Filter signals based on structure
            filtered_signals = self.filtrar_senales_estructura(all_signals)
            
            return filtered_signals
            
        except Exception as e:
            logging.error(f"Error en analizar_mercado: {e}")
            return []

    def detectar_niveles_relevantes(self, analyzer_flexible) -> List[Dict[str, Any]]:
        """
        Detecta niveles relevantes usando el analizador flexible proporcionado.
        Se enfoca especialmente en los flips y niveles clave.
        
        Args:
            analyzer_flexible: Instancia del analizador flexible (puede ser flexible_m1_analyzer o flexible_m5_analyzer)
            
        Returns:
            list: Lista de niveles relevantes detectados
        """
        try:
            relevant_levels = []
            
            # Verificar que el analizador tenga los datos necesarios
            if not hasattr(analyzer_flexible, 'levels_df') or analyzer_flexible.levels_df is None:
                logging.warning("Analizador flexible no tiene levels_df inicializado")
                return []

            # Obtener el precio actual para referencias
            current_price = self.data_1m['close'].iloc[-1] if not self.data_1m.empty else None
            if current_price is None:
                logging.warning("No se puede obtener el precio actual")
                return []

            # Obtener los niveles del analizador flexible
            df_levels = analyzer_flexible.levels_df
            
            if df_levels.empty:
                logging.debug("No hay niveles detectados en el analizador flexible")
                return []

            # Filtrar niveles relevantes
            for _, level in df_levels.iterrows():
                try:
                    level_price = float(level.get('Level', 0))
                    level_type = level.get('Type', '')
                    level_trend = level.get('Trend', '')
                    
                    # Calcular distancia al precio actual
                    distance_to_price = abs(level_price - current_price)
                    proximity_score = 1 - (distance_to_price / (current_price * 0.002))  # 0.2% como máxima distancia
                    
                    # Solo considerar niveles cercanos al precio actual
                    if proximity_score <= 0:
                        continue
                    
                    # Determinar la dirección y confianza basado en el tipo de nivel
                    signal_type = "Buy"
                    confidence = "Media"
                    
                    if "Bearish" in level_trend or "Resistance" in level_type:
                        signal_type = "Sell"
                    elif "Bullish" in level_trend or "Support" in level_type:
                        signal_type = "Buy"

                    if "Flip" in level_type:
                        confidence = "Alta"
                    
                    # Crear señal con el formato estándar
                    señal = {
                        "Type": signal_type,
                        "Level": level_price,
                        "timestamp": level.get('timestamp', datetime.now().isoformat()),
                        "Confidence": confidence,
                        "Categoria": "NivelRelevante",
                        "Reason": f"Nivel {level_type} detectado",
                        "Strategy": "Niveles_Flexibles",
                        "OrderBlockRelacionado": False,
                        "Esquema": level_type,
                        "Nombre": f"Nivel {level_type} {'Alcista' if signal_type == 'Buy' else 'Bajista'}",
                        "proximity_score": round(proximity_score, 3)
                    }
                    
                    # Añadir información adicional si es un flip
                    if "Flip" in level_type:
                        señal.update({
                            "is_recent_flip": True,
                            "Categoria": "Flip",
                            "Strategy": "Flip_Detection",
                            "proximity_to_current_price": proximity_score
                        })
                    
                    relevant_levels.append(señal)

                except Exception as e:
                    logging.error(f"Error procesando nivel individual: {e}")
                    continue
                    
            # Ordenar por proximidad al precio actual
            relevant_levels.sort(key=lambda x: x.get('proximity_score', 0), reverse=True)
            
            # Mantener solo los niveles más relevantes (top 5)
            relevant_levels = relevant_levels[:5]
            
            logging.info(f"Detectados {len(relevant_levels)} niveles relevantes del analizador flexible")
            return relevant_levels

        except Exception as e:
            logging.error(f"Error en detectar_niveles_relevantes: {e}")
            return []

    def calcular_atr(self, data, ventana):
        """
        Calcula el Average True Range (ATR).

        Args:
            data (pd.DataFrame): DataFrame con columnas 'high', 'low', 'close'.
            ventana (int): Ventana para el cálculo del ATR.

        Returns:
            pd.Series: Serie con los valores del ATR.
        """
        data['TR'] = np.maximum(data['high'] - data['low'],
                              np.maximum(np.abs(data['high'] - data['close'].shift(1)),
                                         np.abs(data['low'] - data['close'].shift(1))))
        atr = data['TR'].rolling(window=ventana).mean()
        return atr

    
    def detectar_order_blocks(self, data_1m, data_5m=None, tested_levels=None):
        """
        Detecta Order Blocks en el mercado.
        
        Args:
            data_1m (pd.DataFrame): Datos de timeframe 1M
            data_5m (pd.DataFrame, opcional): Datos de timeframe 5M
            tested_levels (list, opcional): Niveles testeados previamente
        
        Returns:
            list: Lista de Order Blocks detectados
        """
        try:
            order_blocks = []
            
            if data_1m is None or data_1m.empty:
                logging.warning("No hay datos 1M para detectar Order Blocks")
                return order_blocks

            # Convertir índice a datetime si no lo está
            if not isinstance(data_1m.index, pd.DatetimeIndex):
                data_1m = data_1m.copy()
                data_1m.index = pd.to_datetime(data_1m.index)

            # Obtener últimas N velas para el análisis
            lookback = min(100, len(data_1m))
            recent_data = data_1m.tail(lookback)

            # Detectar swing highs y lows
            for i in range(3, len(recent_data)-1):
                current_candle = recent_data.iloc[i]
                prev_candles = recent_data.iloc[i-3:i]
                next_candle = recent_data.iloc[i+1]

                # Verificar Order Block alcista
                if (current_candle['low'] < prev_candles['low'].min() and 
                    next_candle['close'] > current_candle['high']):
                    
                    ob_level = current_candle['low']
                    distance_to_current = abs(ob_level - recent_data.iloc[-1]['close'])
                    
                    # Calcular fuerza del OB
                    price_movement = (next_candle['high'] - current_candle['low']) / current_candle['low']
                    strength = min(1.0, price_movement * 100)  # Normalizar a máximo 1.0
                    
                    order_blocks.append({
                        "tipo": "compra",
                        "nivel_ob": ob_level,
                        "Level": ob_level,  # Para compatibilidad con el sistema de señales
                        "Type": "Buy",
                        "timestamp": recent_data.index[i].isoformat(),
                        "Confidence": "Alta" if strength > 0.7 else "Media",
                        "Categoria": "OrderBlock",
                        "Reason": "OrderBlock alcista detectado",
                        "Strategy": "OB_Detection",
                        "OrderBlockRelacionado": True,
                        "Esquema": "OB_Bullish",
                        "strength": strength,
                        "distance_to_current": distance_to_current
                    })

                # Verificar Order Block bajista
                if (current_candle['high'] > prev_candles['high'].max() and 
                    next_candle['close'] < current_candle['low']):
                    
                    ob_level = current_candle['high']
                    distance_to_current = abs(ob_level - recent_data.iloc[-1]['close'])
                    
                    # Calcular fuerza del OB
                    price_movement = (current_candle['high'] - next_candle['low']) / current_candle['high']
                    strength = min(1.0, price_movement * 100)  # Normalizar a máximo 1.0
                    
                    order_blocks.append({
                        "tipo": "venta",
                        "nivel_ob": ob_level,
                        "Level": ob_level,  # Para compatibilidad con el sistema de señales
                        "Type": "Sell",
                        "timestamp": recent_data.index[i].isoformat(),
                        "Confidence": "Alta" if strength > 0.7 else "Media",
                        "Categoria": "OrderBlock",
                        "Reason": "OrderBlock bajista detectado",
                        "Strategy": "OB_Detection",
                        "OrderBlockRelacionado": True,
                        "Esquema": "OB_Bearish",
                        "strength": strength,
                        "distance_to_current": distance_to_current
                    })

            # Filtrar OBs por proximidad al precio actual
            if order_blocks:
                current_price = recent_data.iloc[-1]['close']
                max_distance = current_price * 0.002  # 0.2% del precio actual
                
                order_blocks = [
                    ob for ob in order_blocks 
                    if ob["distance_to_current"] <= max_distance
                ]
                
                # Ordenar por fuerza y proximidad
                order_blocks.sort(key=lambda x: (x["strength"], -x["distance_to_current"]), reverse=True)
                
                # Limitar a los mejores 5 OBs
                order_blocks = order_blocks[:5]

            return order_blocks

        except Exception as e:
            logging.error(f"Error en detectar_order_blocks: {e}")
            return []
    def detectar_bos_choch(self):
        """
        Detecta patrones BOS (Break of Structure) y CHoCH (Change of Character)
        en los datos de mercado y actualiza self.bos_choch internamente.
        
        Returns:
            list: Lista de eventos BOS/CHoCH detectados
        """
        try:
            if self.data_1m is None or self.data_1m.empty:
                logging.warning("No hay datos 1M para detectar BOS/CHoCH")
                return []

            # Convertir índice a datetime si no lo está
            if not isinstance(self.data_1m.index, pd.DatetimeIndex):
                data_1m = self.data_1m.copy()
                data_1m.index = pd.to_datetime(data_1m.index)
            else:
                data_1m = self.data_1m

            # Inicializar lista de eventos
            eventos_bos_choch = []
            
            # Obtener últimas N velas para el análisis
            lookback = min(100, len(data_1m))
            recent_data = data_1m.tail(lookback)
            
            # Detectar swing highs y lows
            swing_points = []
            for i in range(2, len(recent_data)-2):
                current_high = recent_data.iloc[i]['high']
                current_low = recent_data.iloc[i]['low']
                prev_2_high = recent_data.iloc[i-2:i]['high'].max()
                prev_2_low = recent_data.iloc[i-2:i]['low'].min()
                next_2_high = recent_data.iloc[i+1:i+3]['high'].max()
                next_2_low = recent_data.iloc[i+1:i+3]['low'].min()
                
                # Detectar swing high
                if current_high > prev_2_high and current_high > next_2_high:
                    swing_points.append({
                        'type': 'high',
                        'price': current_high,
                        'index': i,
                        'time': recent_data.index[i]
                    })
                
                # Detectar swing low
                if current_low < prev_2_low and current_low < next_2_low:
                    swing_points.append({
                        'type': 'low',
                        'price': current_low,
                        'index': i,
                        'time': recent_data.index[i]
                    })

            # Detectar BOS y CHoCH
            for i in range(1, len(swing_points)-1):
                current = swing_points[i]
                prev = swing_points[i-1]
                
                # Detectar BOS
                if current['type'] == 'high' and prev['type'] == 'high':
                    if current['price'] > prev['price']:
                        eventos_bos_choch.append({
                            "Type": "Buy",
                            "Level": current['price'],
                            "timestamp": current['time'].isoformat(),
                            "Confidence": "Alta",
                            "Categoria": "Estructura",
                            "Reason": "BOS Alcista",
                            "Strategy": "BOS_Detection",
                            "OrderBlockRelacionado": False,
                            "Esquema": "BOS",
                            "Nombre": "Break of Structure Alcista"
                        })
                
                elif current['type'] == 'low' and prev['type'] == 'low':
                    if current['price'] < prev['price']:
                        eventos_bos_choch.append({
                            "Type": "Sell",
                            "Level": current['price'],
                            "timestamp": current['time'].isoformat(),
                            "Confidence": "Alta",
                            "Categoria": "Estructura",
                            "Reason": "BOS Bajista",
                            "Strategy": "BOS_Detection",
                            "OrderBlockRelacionado": False,
                            "Esquema": "BOS",
                            "Nombre": "Break of Structure Bajista"
                        })
                
                # Detectar CHoCH si hay suficientes puntos
                if i < len(swing_points)-2:
                    next = swing_points[i+1]
                    
                    # CHoCH Alcista
                    if (current['type'] == 'low' and 
                        prev['type'] == 'low' and 
                        next['type'] == 'low' and
                        current['price'] < prev['price'] and 
                        next['price'] > current['price']):
                        
                        eventos_bos_choch.append({
                            "Type": "Buy",
                            "Level": next['price'],
                            "timestamp": next['time'].isoformat(),
                            "Confidence": "Alta",
                            "Categoria": "Estructura",
                            "Reason": "CHoCH Alcista",
                            "Strategy": "CHoCH_Detection",
                            "OrderBlockRelacionado": False,
                            "Esquema": "CHoCH",
                            "Nombre": "Change of Character Alcista"
                        })
                    
                    # CHoCH Bajista
                    if (current['type'] == 'high' and 
                        prev['type'] == 'high' and 
                        next['type'] == 'high' and
                        current['price'] > prev['price'] and 
                        next['price'] < current['price']):
                        
                        eventos_bos_choch.append({
                            "Type": "Sell",
                            "Level": next['price'],
                            "timestamp": next['time'].isoformat(),
                            "Confidence": "Alta",
                            "Categoria": "Estructura",
                            "Reason": "CHoCH Bajista",
                            "Strategy": "CHoCH_Detection",
                            "OrderBlockRelacionado": False,
                            "Esquema": "CHoCH",
                            "Nombre": "Change of Character Bajista"
                        })

            # Filtrar y ordenar eventos por tiempo
            if eventos_bos_choch:
                # Ordenar por tiempo, más recientes primero
                eventos_bos_choch.sort(key=lambda x: x["timestamp"], reverse=True)
                
                # Mantener solo los eventos más recientes (últimos 5)
                eventos_bos_choch = eventos_bos_choch[:5]
            
            # Actualizar la variable de instancia
            self.bos_choch = eventos_bos_choch
            
            return eventos_bos_choch

        except Exception as e:
            logging
    
    def _sync_trends(self):
        """
        Sincroniza las tendencias entre las estructuras SMC y tradicional
        """
        try:
            # Get the unified trend
            unified_trend = self._determinar_tendencia_unificada()
            
            # Update all trend references
            self.estructura_mercado["current_trend"] = unified_trend
            self.estructura_mercado["smc"]["current_trend"] = unified_trend
            self.estructura_mercado["tradicional"]["current_trend"] = unified_trend
            
            logging.info(f"Tendencias sincronizadas: {unified_trend}")
            
        except Exception as e:
            logging.error(f"Error sincronizando tendencias: {e}")

    def _validate_structure_consistency(self):
        """
        Valida la consistencia entre las estructuras SMC y tradicional
        """
        try:
            smc = self.estructura_mercado.get("smc", {})
            trad = self.estructura_mercado.get("tradicional", {})
            
            # Validate BOS/CHoCH consistency
            if smc.get("bos") != trad.get("bos"):
                logging.warning("Inconsistencia detectada en BOS entre SMC y tradicional")
                
            if smc.get("choch") != trad.get("choch"):
                logging.warning("Inconsistencia detectada en CHoCH entre SMC y tradicional")
                
            # Validate trends
            if smc.get("current_trend") != trad.get("current_trend"):
                logging.warning(f"Inconsistencia en tendencias: SMC={smc.get('current_trend')}, "
                            f"Tradicional={trad.get('current_trend')}")
                
        except Exception as e:
            logging.error(f"Error validando consistencia de estructuras: {e}")

    def filtrar_senales_estructura(self, signals):
        """
        Filtra señales basándose en ambas estructuras de mercado
        """
        try:
            filtered_signals = []
            
            for signal in signals:
                if self._validate_signal_consistency(signal):
                    filtered_signals.append(signal)
                    
            logging.info(f"Señales filtradas: {len(signals)} -> {len(filtered_signals)}")
            return filtered_signals
            
        except Exception as e:
            logging.error(f"Error filtrando señales: {e}")
            return signals

    def _validate_signal_consistency(self, signal):
        """
        Valida que una señal sea consistente con la estructura actual del mercado
        """
        try:
            if not isinstance(signal, dict):
                return False
                
            signal_type = signal.get("Type")
            current_trend = self.estructura_mercado.get("current_trend")
            
            # Validar consistencia con tendencia
            if current_trend == "Lateral":
                return True
                
            if current_trend == "Bullish" and signal_type == "Buy":
                return True
                
            if current_trend == "Bearish" and signal_type == "Sell":
                return True
                
            # Validar señales estructurales
            if signal.get("Categoria") == "Estructura":
                return self._validate_structural_signal(signal)
                
            return False
            
        except Exception as e:
            logging.error(f"Error validando consistencia de señal: {e}")
            return False

    def _validate_structural_signal(self, signal):
        """
        Valida señales estructurales específicas
        """
        try:
            esquema = signal.get("Esquema")
            
            if esquema == "BOS":
                return self.estructura_mercado["tradicional"]["bos"] != "none"
                
            if esquema == "CHoCH":
                return self.estructura_mercado["tradicional"]["choch"] != "none"
                
            return True
            
        except Exception as e:
            logging.error(f"Error validando señal estructural: {e}")
            return False


    def actualizar_estructura_mercado(self, data_1m, data_5m, data_30m):
        """
        Actualiza la estructura del mercado unificando análisis SMC y tradicional.
        """
        try:
            logging.info("Actualizando estructura de mercado...")
            
            # Validar datos de entrada
            if data_1m.empty or data_5m.empty or data_30m.empty:
                logging.warning("Datos insuficientes para actualizar estructura.")
                return
                
            # Asignar datos a variables de instancia
            self.data_1m = data_1m
            self.data_5m = data_5m
            self.data_30m = data_30m
            
            # Reset de señales
            self.todas_las_senales = []
            
            # 1. Análisis SMC
            self.smc = SmartMoneyConcepts(data_1m, data_5m)
            resultado_smc = self.smc.analyze(ignorar_proximidad=True)
            
            # Asegurarnos de que la estructura SMC existe
            if "smc" not in self.estructura_mercado:
                self.estructura_mercado["smc"] = {
                    "current_trend": "Lateral",
                    "bos": None,
                    "choch": None,
                    "ob_bull": [],
                    "ob_bear": [],
                    "fvg_bull": [],
                    "fvg_bear": []
                }
            
            if resultado_smc:
                self.estructura_mercado["smc"].update(resultado_smc["estructura"])
                self.todas_las_senales.extend(resultado_smc["señales"])
                
            # 2. Análisis tradicional
            sibi_summary, bisi_summary, bos_summary, choch_summary = \
                self._calculate_sibi_bisi_and_bos_choch(data_30m, data_5m)
                
            # Asegurarnos de que la estructura tradicional existe
            if "tradicional" not in self.estructura_mercado:
                self.estructura_mercado["tradicional"] = {
                    "current_trend": "Lateral",
                    "sibi": "none",
                    "bisi": "none",
                    "bos": "none",
                    "choch": "none",
                    "last_bos_choch": None,
                    "bos_choch_events": []
                }
                
            # Actualizar con los nuevos valores
            self.estructura_mercado["tradicional"].update({
                "sibi": sibi_summary,
                "bisi": bisi_summary,
                "bos": bos_summary,
                "choch": choch_summary
            })
            
            # 3. Actualizar tendencia general
            self.estructura_mercado["current_trend"] = self._determinar_tendencia_unificada()
            
            # 4. Actualizar timestamp
            self.estructura_mercado["last_update"] = datetime.now().isoformat()
            
            # Add these new calls at the end of the try block:
            self._sync_trends()
            self._validate_structure_consistency()
            
            # Update user and timestamp
            self.estructura_mercado.update({
                "last_update": "2025-06-17 20:02:19",  # From your current timestamp
                "user": "gonzalo00123"  # From your current user
            })
            
            logging.info("Estructura de mercado actualizada exitosamente.")
             # Actualizar la estructura con la nueva información de liquidez
            if hasattr(self, 'estructura_mercado') and isinstance(self.estructura_mercado, dict):
                liquidity_data = self.estructura_mercado.get('liquidez', {})
                
                # Añadir estadísticas de liquidez al resumen
                self.estructura_mercado['resumen']['liquidez'] = {
                    'zonas_activas': len(liquidity_data.get('zones', [])),
                    'sweeps_recientes': len(liquidity_data.get('sweeps', [])),
                    'stats': liquidity_data.get('stats', {})
                }

        except Exception as e:
            logging.error(f"Error actualizando estructura de mercado: {e}")
            self.estructura_mercado = {}
            self.todas_las_senales = []

    def _reset_estructuras(self):
        """Reset de todas las estructuras y listas"""
        self.orderblocks = []
        self.sibi_bisi = []
        self.bos_choch = []
        self.todas_las_senales = []
        self.relevant_flips = []
        self.flip_1m_recientes = []

    def _procesar_senales_smc(self, smc_signals):
        """Procesa y categoriza las señales SMC"""
        for señal in smc_signals:
            # Agregar origen SMC a todas las señales
            señal["origen"] = "smc"
            
            # Modificar categorías para diferenciar
            if señal.get("Categoria") == "OrderBlock":
                señal["Esquema"] = "OB_SMC"
                self.orderblocks.append(señal)
            elif señal.get("Categoria") == "FVG":
                señal["Esquema"] = "FVG_SMC"
            elif señal.get("Categoria") == "Estructura":
                señal["Categoria"] = "Estructura_SMC"
                señal["Esquema"] = f"{señal.get('Esquema', 'BOS')}_SMC"
                self.bos_choch.append(señal)
        
        # Agregar todas las señales procesadas
        self.todas_las_senales.extend(smc_signals)

    def _determinar_tendencia_unificada(self):
        """
        Determina la tendencia unificando información de SMC y análisis tradicional
        """
        try:
            tendencia_smc = self.estructura_mercado.get("smc", {}).get("current_trend", "Lateral")
            tendencia_tradicional = self.estructura_mercado.get("tradicional", {}).get("bos", "Lateral")
            
            if tendencia_smc == tendencia_tradicional:
                return tendencia_smc
            
            # Si hay discrepancia, dar prioridad a SMC
            return tendencia_smc if tendencia_smc != "Lateral" else tendencia_tradicional
        except Exception as e:
            logging.error(f"Error determinando tendencia unificada: {e}")
            return "Lateral"

    def _procesar_resultados_bos_choch(self, resultados):
        """Procesa los resultados de la detección BOS/CHoCH tradicional"""
        if resultados["señales"]:
            for señal in resultados["señales"]:
                # Agregar origen tradicional
                señal["origen"] = "tradicional"
                señal["Categoria"] = "Estructura_Tradicional"
                señal["Esquema"] = f"{señal.get('Esquema', 'BOS')}_TRADICIONAL"
                self.bos_choch.append(señal)
            
            # Agregar todas las señales procesadas
            self.todas_las_senales.extend(resultados["señales"])

    def _detectar_elementos_estructurales(self):
        """Detecta elementos estructurales adicionales"""
        # Niveles relevantes
        self.relevant_levels = self.detectar_niveles_relevantes(self.flexible_m1_analyzer)
        self.todas_las_senales.extend(self.relevant_levels)

        # Flips
        self.relevant_flips = self.get_flip_info()
        self.todas_las_senales.extend(self.relevant_flips)

        # SIBI/BISI
        self.detectar_sibi_bisi()
        self.todas_las_senales.extend(self.sibi_bisi)

        # Liquidez
        self.liquidez = self.detectar_liquidez(self.data_1m)
        self.todas_las_senales.extend(self.liquidez)

    def _construir_estructura_mercado(self, sibi_summary, bisi_summary, bos_summary, choch_summary):
        """Construye la estructura de mercado final"""
        return {
            # Estructura SMC
            "smc": self.estructura_smc,
            
            # Order Blocks y eventos estructurales
            "order_blocks": self.orderblocks,
            "bos_choch_events": self.bos_choch,
            
            # SIBI/BISI y FVG
            "sibi_bisi": {
                "summary": {
                    "sibi": sibi_summary,
                    "bisi": bisi_summary
                },
                "signals": self.sibi_bisi,
                "fvg_signals": [s for s in self.sibi_bisi if s.get('Reason') == 'FVG']
            },
            
            # BOS/CHoCH resumen
            "estructura": {
                "bos": bos_summary,
                "choch": choch_summary
            },
            
            # Otros elementos estructurales
            "flips": self.relevant_flips,
            "niveles_relevantes": self.relevant_levels,
            "liquidez": self.liquidez,
            
            # Resúmenes de estado
            "estados": {
                "niveles": self.relevant_levels_state.__dict__ if hasattr(self, 'relevant_levels_state') else {},
                "alertas": self.alert_manager.__dict__ if hasattr(self, 'alert_manager') else {},
                "extremos": self.trailing_extremes.__dict__ if hasattr(self, 'trailing_extremes') else {}
            },
            
            # Timestamp de actualización
            "last_update": datetime.now().isoformat()
        }

    async def analizar_mercado_v2(self, price_data=None):
        """
        Analiza el mercado utilizando todos los métodos de detección disponibles.
        Version 2 con integración SMC y tradicional mejorada.
        """
        CURRENT_TIMESTAMP = "2025-06-17 20:09:16"
        CURRENT_USER = "gonzalo00123"
        
        try:
            logging.info("Iniciando análisis de mercado v2...")

            # 1. Validar datos
            if not self._validate_input_data():
                return self._create_error_response("Datos insuficientes para el análisis.")

            # 2. Preparar datos
            data_1m, data_5m, data_30m = self._prepare_data()

            # 3. Actualizar estructura de mercado
            self.actualizar_estructura_mercado(data_1m, data_5m, data_30m)
            
            # 4. Análisis SMC y señales
            señales_smc = self.analizar_con_smc(data_1m, data_5m)
            
            # 5. Filtrar y validar señales
            señales_filtradas = self.filtrar_senales_estructura(señales_smc)
            self.todas_las_senales.extend(señales_filtradas)

            # 6. Combinar y validar estructuras
            self._sync_trends()
            self._validate_structure_consistency()

            # 7. Actualizar estructura unificada
            estructura_unificada = {
                "order_blocks": self.estructura_mercado.get("order_blocks", []),
                "fvg": self.estructura_mercado.get("fvg", []),
                "bisi": self.estructura_mercado.get("bisi", []),
                "sibi": self.estructura_mercado.get("sibi", []),
                "bos_choch": self.estructura_mercado.get("bos_choch", []),
                "flips": self.estructura_mercado.get("flips", []),
                "liquidez": self.estructura_mercado.get("liquidez", []),
                "current_trend": self.estructura_mercado.get("current_trend", "Lateral"),
                "last_update": CURRENT_TIMESTAMP,
                "user": CURRENT_USER
            }

            # 8. Preparar resultado
            resultado = {
                "timestamp": CURRENT_TIMESTAMP,
                "user": CURRENT_USER,
                "precio_actual": price_data.get("final_price_used") if price_data else None,
                "info_precios": price_data or {},
                "estructura_mercado": estructura_unificada,
                "estructura_smc": self.estructura_smc,
                "señales_analizadas": len(self.todas_las_senales),
                "mejores_señales": self._get_best_signals(),
                "estado": "exito",
                "mensaje": "Análisis completado"
            }

            # 9. Guardar resultados
            self._save_analysis_results(resultado)

            return resultado

        except Exception as e:
            logging.error(f"Error durante el análisis del mercado: {e}")
            traceback.print_exc()
            return self._create_error_response(str(e))

    def _validate_input_data(self):
        """
        Valida que los datos necesarios estén disponibles
        """
        return not (self.data_1m.empty or self.data_5m.empty or self.data_30m.empty)

    def _prepare_data(self):
        """
        Prepara y limpia los datos para el análisis
        """
        data_1m = self.data_1m.copy()
        data_5m = self.data_5m.copy()
        data_30m = self.data_30m.copy()

        for df in [data_1m, data_5m, data_30m]:
            if 'time' in df:
                df['time'] = pd.to_datetime(df['time'], unit='s')
            if 'volume' in df:
                df.drop(columns=['volume'], inplace=True, errors='ignore')

        return data_1m, data_5m, data_30m

    def _get_best_signals(self):
        """
        Selecciona las mejores señales basadas en criterios definidos
        """
        try:
            if not self.todas_las_senales:
                return []
                
            # Ordenar señales por confianza y tiempo
            señales_ordenadas = sorted(
                self.todas_las_senales,
                key=lambda x: (x.get('Confidence', 0), x.get('timestamp', '')),
                reverse=True
            )
            
            # Retornar las mejores señales (top 5 por ejemplo)
            return señales_ordenadas[:5]
            
        except Exception as e:
            logging.error(f"Error obteniendo mejores señales: {e}")
            return []

    def _save_analysis_results(self, resultado):
        """
        Guarda los resultados del análisis en archivos
        """
        try:
            # Guardar estructura SMC
            with open("estructura_smc.json", "w", encoding="utf-8") as f:
                json.dump(self.estructura_smc, f, indent=2, ensure_ascii=False)

            # Guardar análisis completo
            filename = f"analisis_mercado_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(filename, "w", encoding="utf-8") as f:
                json.dump(resultado, f, indent=2, ensure_ascii=False)

            logging.info(f"Análisis del mercado guardado en {filename}")
            
        except Exception as e:
            logging.error(f"Error guardando resultados: {e}")

    def _create_error_response(self, error_message):
        """
        Crea una respuesta de error estandarizada
        """
        return {
            "timestamp": "2025-06-17 20:09:16",
            "user": "gonzalo00123",
            "estado": "error",
            "mensaje": error_message,
            "señales_analizadas": 0,
            "mejores_señales": [],
            "estructura_mercado": {},
            "estructura_smc": {}
        }
    
    def _clean_for_json(self, data):
        """
        Limpia un objeto (diccionario o lista) para asegurar que sea serializable a JSON.
        Convierte objetos no serializables como datetime, NaN, Infinity y funciones a strings.
        """
        if isinstance(data, dict):
            return {k: self._clean_for_json(v) for k, v in data.items()}
        elif isinstance(data, list):
            return [self._clean_for_json(elem) for elem in data]
        elif isinstance(data, datetime):
            return data.isoformat()
        elif isinstance(data, (np.float32, np.float64, np.int32, np.int64)):
            # Convertir tipos numéricos de NumPy a tipos nativos de Python
            return float(data)
        elif isinstance(data, float) and (np.isnan(data) or np.isinf(data)):
            return None # O 'NaN' o 'Infinity' como string
        elif callable(data):
            logging.warning(f"Objeto de tipo función encontrado durante la limpieza JSON: {data}. Convirtiendo a string.")
            return str(data)
       
        # --- FIN NUEVA ADICIÓN ---
        else:
            return data
    def _clean_for_json(self, obj):
        """Limpia un objeto para ser serializado a JSON"""
        if isinstance(obj, dict):
            return {k: self._clean_for_json(v) for k, v in obj.items() if v is not None}
        elif isinstance(obj, list):
            return [self._clean_for_json(item) for item in obj]
        elif isinstance(obj, (float, int)):
            return obj
        elif isinstance(obj, np.float64):
            return float(obj)
        elif isinstance(obj, np.int64):
            return int(obj)
        elif isinstance(obj, pd.Timestamp):
            return obj.strftime("%Y-%m-%d %H:%M:%S")
        elif obj is None:
            return None
        else:
            return str(obj)
    def _convertir_a_serie(self, vela, nombre_funcion):
        """
        Función auxiliar para convertir diferentes tipos de entrada a pd.Series
        
        Args:
            vela: Entrada que podría ser pd.Series, pd.DataFrame o diccionario
            nombre_funcion: Nombre de la función que llama para mejor logging
            
        Returns:
            pd.Series o None si hay error
        """
        try:
            # Si es un número o un tipo primitivo, este no es un valor válido
            if isinstance(vela, (int, float, str, bool)) or vela is None:
                stack_trace = traceback.format_stack()
                caller_info = stack_trace[-3] if len(stack_trace) > 2 else "Desconocido"
                logging.warning(f"Valor no válido para 'vela' en {nombre_funcion}: {vela}. Se esperaba un pd.Series o diccionario.")
                logging.warning(f"Llamado desde: {caller_info}")
                return None
                
            # Si es un DataFrame, tomamos la última fila
            if isinstance(vela, pd.DataFrame):
                if vela.empty:
                    logging.warning(f"DataFrame vacío pasado a {nombre_funcion}")
                    return None
                return vela.iloc[-1]  # Tomamos la última fila como Series
                
            # Si ya es una Series, lo devolvemos tal cual
            if isinstance(vela, pd.Series):
                return vela
                
            # Intentamos convertir a Series si es un diccionario
            try:
                return pd.Series(vela)
            except Exception as e:
                logging.error(f"Error al convertir a Series en {nombre_funcion}: {str(e)}, tipo: {type(vela)}")
                return None
                
        except Exception as e:
            logging.error(f"Error en _convertir_a_serie: {str(e)}")
            return None

    def calcular_body_size(self, vela):
        """
        Calcula el tamaño del cuerpo de una vela.

        Args:
            vela (pd.Series, pd.DataFrame o dict-like): Datos de la vela
                                         debe contener 'close' y 'open'.

        Returns:
            float: El tamaño del cuerpo de la vela.
        """
        try:
            # Convertir a Series si es necesario
            vela_serie = self._convertir_a_serie(vela, "calcular_body_size")
            if vela_serie is None:
                return 0
            
            if 'close' not in vela_serie or 'open' not in vela_serie:
                logging.error("Error: La serie 'vela' debe contener las columnas 'close' y 'open'.")
                return 0
            
            return abs(vela_serie['close'] - vela_serie['open'])
        except Exception as e:
            stack_trace = traceback.format_stack()
            caller_info = stack_trace[-2] if len(stack_trace) > 1 else "Desconocido"
            logging.error(f"Error en calcular_body_size: {str(e)}, tipo de vela: {type(vela)}")
            logging.error(f"Llamado desde: {caller_info}")
            return 0

    def calcular_price_action(self, data):
        """
        Calcula el price action de la última vela.

        Args:
            data (pd.DataFrame): DataFrame con los datos OHLC de 1 minuto.

        Returns:
            str: El tipo de price action detectado ('alcista', 'bajista' o 'neutro').
        """
        try:
            if data is None or not isinstance(data, pd.DataFrame):
                logging.error("Error: El argumento 'data' debe ser un pd.DataFrame.")
                return 'neutro'
                
            if data.empty or len(data) < 1:
                return 'neutro'  # No hay suficientes datos

            last_candle = data.iloc[-1]

            if last_candle['close'] > last_candle['open']:
                return 'alcista'
            elif last_candle['close'] < last_candle['open']:
                return 'bajista'
            else:
                return 'neutro'
        except Exception as e:
            logging.error(f"Error en calcular_price_action: {str(e)}")
            return 'neutro'

    def obtener_tendencia(self, data):
        """
        Determina la tendencia basada en los cierres de las velas.
        Considera un período de 5 velas.
        Args:
            data (pd.DataFrame): DataFrame con datos de velas (close).
        Returns:
            str: "ALCISTA", "BAJISTA" o "RANGO".
        """
        try:
            if data is None or not isinstance(data, pd.DataFrame):
                logging.error("Error: El argumento 'data' debe ser un pd.DataFrame.")
                return "RANGO"
                
            if len(data) < 5:
                logging.warning("No hay datos suficientes para determinar la tendencia.")
                return "RANGO"
                
            closes = data['close'].values[-5:]
            if all(closes[i] < closes[i + 1] for i in range(len(closes)-1)):
                tendencia = "ALCISTA"
            elif all(closes[i] > closes[i + 1] for i in range(len(closes)-1)):
                tendencia = "BAJISTA"
            else:
                tendencia = "RANGO"
                
            return tendencia
        except Exception as e:
            logging.error(f"Error en obtener_tendencia: {str(e)}")
            return "RANGO"

    def calcular_mecha_superior_pct(self, vela):
        """
        Calcula el porcentaje de la mecha superior con respecto al rango de la vela.
        Args:
            vela (pd.Series, pd.DataFrame o dict-like): Datos de la vela,
                                         debe contener 'high', 'open', 'close', 'low'.
        Returns:
            float: Porcentaje de la mecha superior.
        """
        try:
            # Convertir a Series si es necesario
            vela_serie = self._convertir_a_serie(vela, "calcular_mecha_superior_pct")
            if vela_serie is None:
                return 0
                
            if not all(col in vela_serie for col in ['high', 'low', 'close', 'open']):
                logging.error(
                    "Error: La serie 'vela' debe contener las columnas 'high', 'low', 'close' y 'open'.")
                return 0
                
            candle_range = vela_serie['high'] - vela_serie['low']
            if candle_range == 0:
                return 0
                
            if vela_serie['close'] > vela_serie['open']:
                mecha_superior = vela_serie['high'] - vela_serie['close']
            else:
                mecha_superior = vela_serie['high'] - vela_serie['open']
                
            mecha_superior_pct = (mecha_superior / candle_range) * 100
            return mecha_superior_pct
        except Exception as e:
            stack_trace = traceback.format_stack()
            caller_info = stack_trace[-2] if len(stack_trace) > 1 else "Desconocido"
            logging.error(f"Error en calcular_mecha_superior_pct: {str(e)}, tipo de vela: {type(vela)}")
            logging.error(f"Llamado desde: {caller_info}")
            return 0

    def calcular_mecha_inferior_pct(self, vela):
        """
        Calcula el porcentaje de la mecha inferior con respecto al rango de la vela.
        Args:
            vela (pd.Series, pd.DataFrame o dict-like): Datos de la vela,
                                         debe contener 'low', 'open', 'close', 'high'.
        Returns:
            float: Porcentaje de la mecha inferior.
        """
        try:
            # Convertir a Series si es necesario
            vela_serie = self._convertir_a_serie(vela, "calcular_mecha_inferior_pct")
            if vela_serie is None:
                return 0
                
            if not all(col in vela_serie for col in ['high', 'low', 'close', 'open']):
                logging.error(
                    "Error: La serie 'vela' debe contener las columnas 'high', 'low', 'close' y 'open'.")
                return 0
                
            candle_range = vela_serie['high'] - vela_serie['low']
            if candle_range == 0:
                return 0
                
            if vela_serie['close'] > vela_serie['open']:
                mecha_inferior = vela_serie['open'] - vela_serie['low']
            else:
                mecha_inferior = vela_serie['close'] - vela_serie['low']
                
            mecha_inferior_pct = (mecha_inferior / candle_range) * 100
            return mecha_inferior_pct
        except Exception as e:
            stack_trace = traceback.format_stack()
            caller_info = stack_trace[-2] if len(stack_trace) > 1 else "Desconocido"
            logging.error(f"Error en calcular_mecha_inferior_pct: {str(e)}, tipo de vela: {type(vela)}")
            logging.error(f"Llamado desde: {caller_info}")
            return 0

    def calcular_prev_body_size(self, vela):
        """
        Calcula el tamaño del cuerpo de la vela anterior a la última.
        Args:
            vela (pd.Series, pd.DataFrame o dict-like): Datos de la vela,
                                         debe contener 'open' y 'close'.
        Returns:
            float: Tamaño del cuerpo de la vela anterior.
        """
        try:
            # Convertir a Series si es necesario
            vela_serie = self._convertir_a_serie(vela, "calcular_prev_body_size")
            if vela_serie is None:
                return 0
                
            if 'close' not in vela_serie or 'open' not in vela_serie:
                logging.error("Error: La serie 'vela' debe contener las columnas 'close' y 'open'.")
                return 0
                
            return abs(vela_serie['close'] - vela_serie['open'])
        except Exception as e:
            stack_trace = traceback.format_stack()
            caller_info = stack_trace[-2] if len(stack_trace) > 1 else "Desconocido"
            logging.error(f"Error en calcular_prev_body_size: {str(e)}, tipo de vela: {type(vela)}")
            logging.error(f"Llamado desde: {caller_info}")
            return 0

    def calcular_ob_body_size(self, vela):
        """
        Calcula el tamaño del cuerpo de la vela del order block.
        Args:
            vela (pd.Series, pd.DataFrame o dict-like): Datos de la vela,
                                         debe contener 'open' y 'close'.
        Returns:
            float: Tamaño del cuerpo de la vela del order block.
        """
        try:
            # Convertir a Series si es necesario
            vela_serie = self._convertir_a_serie(vela, "calcular_ob_body_size")
            if vela_serie is None:
                return 0
                
            if 'close' not in vela_serie or 'open' not in vela_serie:
                logging.error("Error: La serie 'vela' debe contener las columnas 'close' y 'open'.")
                return 0
                
            return abs(vela_serie['close'] - vela_serie['open'])
        except Exception as e:
            stack_trace = traceback.format_stack()
            caller_info = stack_trace[-2] if len(stack_trace) > 1 else "Desconocido"
            logging.error(f"Error en calcular_ob_body_size: {str(e)}, tipo de vela: {type(vela)}")
            logging.error(f"Llamado desde: {caller_info}")
            return 0
    def evaluar_con_modelos_ia(self, señal):
        try:
            # === Modelo 1: Basado en datos de la señal (niveles, OB, etc.) ===
            try:
                # Normalizar el trend a un valor numérico
                trend_valor = 0  # Valor predeterminado para "Rango"
                trend_str = str(señal.get("Trend", "Rango")).lower()  # Asegurar que sea string y en minúsculas
                if trend_str == "alcista":
                    trend_valor = 1
                elif trend_str == "bajista":
                    trend_valor = -1
                
                # Asegurar que price_action sea numérico
                try:
                    price_action = float(señal.get("price_action", 0))
                except (ValueError, TypeError):
                    price_action = 0
                    
                # Asegurar que confidence sea numérico (1 por defecto)
                try:
                    confidence = float(señal.get("confidence", 1))
                except (ValueError, TypeError):
                    confidence = 1
                    
                # Asegurar que score sea numérico
                try:
                    score = float(señal.get("score", 0))
                except (ValueError, TypeError):
                    score = 0
                    
                # Asegurar que todos los valores sean numéricos
                features_1 = [
                    price_action,
                    trend_valor,
                    confidence,
                    score,
                    float(señal.get("flip_distance", 0)),
                    float(señal.get("body_size", 0)),
                    float(señal.get("mecha_superior_pct", 0)),
                    float(señal.get("mecha_inferior_pct", 0)),
                ]
                
                df_1 = pd.DataFrame([features_1], columns=[
                    'price_action', 'trend', 'confidence', 'score', 'flip_distance', 'body_size',
                    'mecha_superior_pct', 'mecha_inferior_pct'
                ])
                
                if self.modelo_niveles is not None:
                    proba_niveles = self.modelo_niveles.predict_proba(df_1)
                    if proba_niveles.shape[1] > 1:
                        prob1 = proba_niveles[0][1]
                    elif proba_niveles.shape[1] == 1:
                        prob1 = proba_niveles[0][0]
                    else:
                        prob1 = 0.5
                else:
                    prob1 = 0.0  # Si el modelo no está cargado, no puede predecir
                    
            except Exception as e:
                logging.error(f"Error en Modelo 1: {str(e)}")
                prob1 = 0.0
                
            # === Modelo 2: Basado en contexto/vela actual (probabilidad de win) ===
            try:
                # Obtener el diccionario de vela actual
                vela_dict = self.get_current_candle()
                
                # Verificar que vela_dict sea un diccionario
                if not isinstance(vela_dict, dict):
                    logging.warning("get_current_candle() no devolvió un diccionario. Creando uno nuevo.")
                    vela_dict = {}
                
                # Asegurar que todos los valores estén presentes y sean del tipo correcto
                vela_dict['score'] = float(señal.get('score', 0))
                vela_dict['Level'] = float(señal.get('Level', 0)) 
                
                # Normalizar Trend como string
                trend_str = str(señal.get('Trend', 'Rango'))
                vela_dict['Trend'] = trend_str
                
                # Normalizar Confidence como string
                confidence_str = str(señal.get('Confidence', 'Media'))
                vela_dict['Confidence'] = confidence_str
                
                # Determinar Type basado en price_action numérico
                try:
                    price_action_val = float(señal.get('price_action', 0))
                    vela_dict['Type'] = 'Buy' if price_action_val > 0 else 'Sell'
                except (ValueError, TypeError):
                    vela_dict['Type'] = 'Sell'  # Valor por defecto
                
                # Asegurar que los demás valores sean numéricos
                vela_dict['flip_distance'] = float(señal.get('flip_distance', 0))
                vela_dict['body_size'] = float(señal.get('body_size', 0))
                vela_dict['mecha_superior_pct'] = float(señal.get('mecha_superior_pct', 0))
                vela_dict['mecha_inferior_pct'] = float(señal.get('mecha_inferior_pct', 0))
                
                # Asegurarse de que todas las columnas OHLC estén presentes
                for col in ['open', 'high', 'low', 'close', 'volume']:
                    if col not in vela_dict:
                        vela_dict[col] = 0.0
                
                # Convertir a Series para evitar el error
                vela = pd.Series(vela_dict)
                
                # Verificar que vela sea una Series antes de continuar
                if not isinstance(vela, pd.Series):
                    logging.error("No se pudo convertir vela_dict a pd.Series")
                    prob2 = 0.0
                else:
                    flips = self.relevant_flips if hasattr(self, 'relevant_flips') else []
                    logging.info(f"Relevant Flips: {flips}")
                    features_2_dict = self.extraer_features_lightgbm(vela, flips)
                    df_2 = pd.DataFrame([features_2_dict])
                    
                    if hasattr(self, 'modelo_signal') and self.modelo_signal is not None:
                        # Asumiendo que extraer_features_lightgbm devuelve 10 características
                        if df_2.shape[1] == 10: 
                            prob2_array = self.modelo_signal.predict_proba(df_2)
                            if isinstance(prob2_array, np.ndarray) and prob2_array.shape[0] > 0 and prob2_array.shape[1] > 1:
                                prob2 = float(prob2_array[0][1])
                            else:
                                prob2 = 0.5
                        else:
                            logging.warning(f"LightGBM: Número incorrecto de características ({df_2.shape[1]}). Se esperaban 10.")
                            prob2 = 0.0
                    else:
                        prob2 = 0.0
                        
            except Exception as e:
                logging.error(f"Error en Modelo 2: {str(e)}")
                prob2 = 0.0
                
            # === Modelo 3: Basado en la dirección del precio ===
            try:
                signal_type = str(señal.get("Type", "")).lower()
                
                if signal_type == "buy":
                    direccion_precio = "Buy"
                    prob3_direccion = 0.7
                elif signal_type == "sell":
                    direccion_precio = "Sell"
                    prob3_direccion = 0.3
                else:
                    if hasattr(self, 'predecir_direccion_precio') and self.predecir_direccion_precio is not None:
                        direccion_precio = self.predecir_direccion_precio()
                    else:
                        try:
                            price_action = float(señal.get("price_action", 0))
                            direccion_precio = "Buy" if price_action > 0 else "Sell"
                        except (ValueError, TypeError):
                            direccion_precio = "Buy"
                    
                    prob3_direccion = 0.7 if direccion_precio == "Buy" else 0.3
                
                señal["direccion_predicha"] = direccion_precio
                
            except Exception as e:
                logging.error(f"Error en Modelo 3: {str(e)}")
                signal_type = str(señal.get("Type", "")).lower()
                if signal_type == "buy":
                    prob3_direccion = 0.7
                    señal["direccion_predicha"] = "Buy"
                else:
                    prob3_direccion = 0.5
                    señal["direccion_predicha"] = "Undecided"

            # === Decisión combinada ===
            score_final = (prob1 + prob2 + prob3_direccion) / 3
            score_final = max(0.0, min(1.0, score_final)) 

            # Los campos que se añadirán/actualizarán en la señal
            señal["probabilidad_win"] = round(score_final * 100)  # De 0-1 a 0-100%
            señal["ia_decision"] = "buena" if score_final >= 0.6 else "mala"
            señal["score_ia_1"] = round(prob1, 4)  # Redondea para mejor legibilidad en JSON
            señal["score_ia_2"] = round(prob2, 4)
            señal["score_ia_3"] = round(prob3_direccion, 4)
            
            # Opcional: añadir los detalles de los scores de IA para depuración
            señal["score_detalle_ia"] = {
                "modelo_niveles": round(prob1, 4),
                "modelo_lightgbm": round(prob2, 4),
                "modelo_direccion": round(prob3_direccion, 4),
                "score_final_combinado": round(score_final, 4)
            }
            
            return score_final
        
        except Exception as e:
            logging.error(f"Error general en evaluar_con_modelos_ia: {str(e)}")
            señal["probabilidad_win"] = 0 
            señal["ia_decision"] = "error"
            señal["score_ia_1"] = 0.0
            señal["score_ia_2"] = 0.0
            señal["score_ia_3"] = 0.0
            señal["score_detalle_ia"] = {"error": str(e)}
            return 0.0

    def extraer_features_lightgbm(self, vela_actual, niveles_flip):
        """
        Extrae las 10 características para el modelo LightGBM.

        Args:
            vela_actual: pd.Series con información de la vela actual.
            niveles_flip: lista de niveles relevantes.
            
        Returns:
            dict: Diccionario con las características extraídas.
        """
        try:
            # Validar explícitamente que vela_actual sea un pd.Series
            if not isinstance(vela_actual, pd.Series):
                logging.error("Error: El argumento 'vela_actual' debe ser un pd.Series.")
                return self._get_default_lightgbm_features_10()
            
            # Extraer los features con verificación de valores
            features = {}
            
            # Para cada característica, usar get() con valor predeterminado y convertir a float
            try:
                features['score'] = float(vela_actual.get('score', 0))
            except (TypeError, ValueError):
                features['score'] = 0.0
                
            try:
                features['key_level'] = float(vela_actual.get('Level', 0))
            except (TypeError, ValueError):
                features['key_level'] = 0.0
                
            # Valor booleano para OTC
            features['is_otc'] = int(getattr(self, 'otc', False))
            
            # Codificación de variables categóricas
            trend_str = str(vela_actual.get("Trend", "Rango"))
            features['trend_encoded'] = {"Alcista": 1, "Bajista": -1, "Rango": 0, "Indefinida": 0}.get(trend_str, 0)
            
            confidence_str = str(vela_actual.get("Confidence", "Media"))
            features['confidence_encoded'] = {"Alta": 2, "Media": 1, "Baja": 0, "N/A": 0}.get(confidence_str, 1)
            
            # Tipo de señal
            features['signal_encoded'] = 1 if str(vela_actual.get("Type", "")) == "Buy" else 0
            
            # Características numéricas con validación
            for key, default in [
                ('flip_distance', 0),
                ('body_size', 0),
                ('mecha_superior_pct', 0),
                ('mecha_inferior_pct', 0)
            ]:
                try:
                    features[key] = float(vela_actual.get(key, default))
                except (TypeError, ValueError):
                    features[key] = float(default)
            
            return features

        except Exception as e:
            logging.error(f"Error en extraer_features_lightgbm: {e}")
            return self._get_default_lightgbm_features_10()
    def preparar_caracteristicas_direccion(self, señal):
        """
        Extrae y prepara las características de la señal para el modelo de dirección del mercado.
        Devuelve None si faltan características.
        """
        try:
            # Asegúrate de que los nombres de las claves en 'señal' coincidan con los nombres de las columnas que espera el modelo.
            features_direccion = {
                'price_action': señal.get('price_action'),
                'trend': señal.get('Trend'),
                'body_size': señal.get('body_size'),
                'mecha_superior_pct': señal.get('mecha_superior_pct'),
                'mecha_inferior_pct': señal.get('mecha_inferior_pct'),
                'prev_body_size': señal.get('prev_body_size'),
                'ob_body_size': señal.get('ob_body_size')
            }
            # Verifica si alguna característica falta en la señal o es None.
            if not all(key in features_direccion and features_direccion[key] is not None for key in features_direccion):
                logging.warning(f"Faltan características o hay valores None para el modelo de dirección del mercado en la señal: {señal}")
                return None
            return pd.Series(features_direccion)
        except KeyError as e:
            logging.error(f"Error al extraer características para el modelo de dirección: {e}")
            return None
        except Exception as e:
            logging.error(f"Error inesperado al preparar características de dirección: {e}")
            return None
                
    def evaluar_signal(self, señal):
        """
        Evalúa una señal con el modelo de LightGBM (signal) y el modelo de dirección (modelo_direccion).
        Devuelve True si pasa ambos umbrales de probabilidad.
        """
        try:
            # === Paso 1: Evaluar con modelo de señales (LightGBM) ===
            features = self.preparar_features_para_modelo_lgbm(señal)
            X_signal = pd.DataFrame([features])

            # Verificar columnas esperadas
            columnas_esperadas = list(self.modelo_signal.feature_name_)
            columnas_recibidas = list(X_signal.columns)

            if columnas_recibidas != columnas_esperadas:
                logging.error(f" Columnas incompatibles para modelo_signal:\nEsperadas: {columnas_esperadas}\nRecibidas: {columnas_recibidas}")
                return False

            # Predicción del modelo signal
            prob_signal = self.modelo_signal.predict_proba(X_signal)
            if isinstance(prob_signal, np.ndarray) and prob_signal.shape[0] > 0 and prob_signal.shape[1] > 1:
                prob_signal = prob_signal[0][1]  # Acceder al valor de probabilidad de la clase positiva
            else:
                logging.error(f"Formato inesperado de prob_signal: {prob_signal}")
                return False
                
            logging.info(f" Probabilidad de éxito con modelo_signal: {prob_signal:.4f}")

        except Exception as e:
            logging.error(f" Error al evaluar modelo_signal: {e}")
            prob_signal = 0.0

        # === Paso 2: Evaluar con modelo de dirección ===
        try:
            features_direccion = self.preparar_caracteristicas_direccion(señal)

            if features_direccion is None:
                logging.warning(" No se pudieron extraer características de dirección. Usando probabilidad por defecto.")
                prob_direccion = 0.5
            else:
                df_direccion = pd.DataFrame([features_direccion])
                # Codificar y escalar
                for col in df_direccion.columns:
                    if col in self.label_encoders_direccion:
                        df_direccion[col] = self.label_encoders_direccion[col].transform(df_direccion[col])

                df_scaled = self.scaler_direccion.transform(df_direccion)
                prob_direccion = self.modelo_direccion.predict_proba(df_scaled)[0][1]
                logging.info(f" Probabilidad de buena dirección: {prob_direccion:.4f}")

        except Exception as e:
            logging.error(f" Error al evaluar modelo_direccion: {e}")
            prob_direccion = 0.5

        # === Paso 3: Combinación y decisión final ===
        try:
            score_total = (0.7 * prob_signal + 0.3 * prob_direccion)
            
            # === VALIDACIÓN DE LIQUIDEZ (NUEVO CÓDIGO) ===
            if señal.get("zona_liquidez_tipo"):
                for zona in self.zonas_liquidez:
                    if abs(señal["Level"] - zona["Level"]) <= zona.get("tolerancia", 0.0002):
                        señal["liquidez_calidad"] = self.validar_calidad_liquidez(zona)
                        logging.info(f" Liquidez validada: {señal['liquidez_calidad']}")
                        break
            
            # === ASIGNACIÓN DE SCORES Y DECISIÓN ===
            señal["score_signal"] = round(prob_signal, 4)
            señal["score_direccion"] = round(prob_direccion, 4)
            señal["score_total"] = round(score_total, 4)
            señal["decision_ia"] = "buena" if score_total >= self.umbral_signal else "mala"

            logging.info(f" Evaluación IA final: {señal['decision_ia'].upper()} con score: {score_total:.4f}")
            return score_total >= self.umbral_signal

        except Exception as e:
            logging.error(f" Error al calcular score total de IA: {e}")
            return False
    async def update_candles(self):
        """Actualiza los datos de velas para 30M, 5M y 1M."""
        try:
            logging.info("Actualizando velas...")
            candles_1m, candles_5m, candles_30m = await get_candles_three_timeframes(
                self.api, self.asset_with_otc, 60, 300, 1800, 3600 * 24
            )
            self.data_1m = candles_1m
            self.data_5m = candles_5m
            self.data_30m = candles_30m
            logging.info("Velas actualizadas correctamente.")
        except Exception as e:
            logging.error(f"Error al actualizar velas: {e}")
            self.data_1m, self.data_5m, self.data_30m = None, None, None
    # Propuesta de mejora para sincronización
    async def update_all_timeframes(self):
        try:
            # Actualizar todos los timeframes de forma sincronizada
            self.data_1m = await self.actualizar_datos_1m()
            self.data_5m = await self.actualizar_datos_5m()
            self.data_30m = await self.actualizar_datos_30m()
            
            # Verificar alineación temporal
            self._verificar_sincronizacion_timeframes()
            
        except Exception as e:
            logging.error(f"Error en actualización de timeframes: {e}")
    def _verificar_sincronizacion_timeframes(self):
        """
        Verifica que todos los timeframes estén correctamente alineados
        """
        if self.data_1m is None or self.data_5m is None or self.data_30m is None:
            raise ValueError("Datos faltantes en algunos timeframes")
            
        ultimo_tiempo_1m = self.data_1m.index[-1]
        ultimo_tiempo_5m = self.data_5m.index[-1]
        ultimo_tiempo_30m = self.data_30m.index[-1]
        
        # Verificar que las diferencias temporales sean coherentes
        if (ultimo_tiempo_1m - ultimo_tiempo_5m).seconds > 300:  # 5 minutos
            logging.warning("Posible desincronización entre 1m y 5m")
        
        if (ultimo_tiempo_1m - ultimo_tiempo_30m).seconds > 1800:  # 30 minutos
            logging.warning("Posible desincronización entre 1m y 30m")
    def sincronizar_dataframes(self):
        """
        Asegura que todos los dataframes estén alineados temporalmente
        """
        tiempo_comun = min(self.data_1m.index[-1], 
                        self.data_5m.index[-1],
                        self.data_30m.index[-1])
        
        self.data_1m = self.data_1m[self.data_1m.index <= tiempo_comun]
        self.data_5m = self.data_5m[self.data_5m.index <= tiempo_comun]
        self.data_30m = self.data_30m[self.data_30m.index <= tiempo_comun]
    def validar_integridad_datos(self):
        """
        Valida la integridad y coherencia de los datos
        """
        for df, nombre in [(self.data_1m, "1m"), 
                        (self.data_5m, "5m"), 
                        (self.data_30m, "30m")]:
            if df is None:
                raise ValueError(f"Datos faltantes en timeframe {nombre}")
            if df.empty:
                raise ValueError(f"DataFrame vacío en timeframe {nombre}")
            if df.isnull().any().any():
                logging.warning(f"Valores nulos detectados en {nombre}")

    def get_current_candle(self):
        """Obtiene la vela actual de los datos de 1 minuto"""
        if self.data_1m is not None and len(self.data_1m) > 0:
            return {
                'open': self.data_1m['open'].iloc[-1],
                'high': self.data_1m['high'].iloc[-1],
                'low': self.data_1m['low'].iloc[-1],
                'close': self.data_1m['close'].iloc[-1]
            }
        else:
            logging.warning("No hay datos de 1 minuto disponibles para obtener la vela actual")
            return {'open': 0, 'high': 0, 'low': 0, 'close': 0}

    def mostrar_mejores_señales(self, resultado):
        """Muestra un resumen de las mejores señales en consola de forma legible"""
        if not resultado or "mejores_señales" not in resultado:
            print("No hay señales disponibles para mostrar")
            return
        
        print("\n================ MEJORES SEÑALES DE TRADING ================")
        print(f"Timestamp: {resultado['timestamp']}")
        print(f"Precio actual: {resultado['precio_actual']}")
        print(f"Tendencia 30m: {resultado['tendencia_30m']}, Tendencia 5m: {resultado['tendencia_5m']}")
        print(f"Total señales detectadas: {resultado['total_señales_detectadas']}")
        print("-----------------------------------------------------------")
        
        for i, señal in enumerate(resultado['mejores_señales'], 1):
            print(f"\n{i}. {señal.get('Nombre', 'Señal sin nombre')} ({señal.get('Type', 'N/A')})")
            print(f"   Nivel: {señal.get('Level', 'N/A')}")
            print(f"   Categoría: {señal.get('Categoria', 'N/A')}")
            print(f"   Confianza: {señal.get('Confidence', 'N/A')}")
            print(f"   Score: {señal.get('score', 0):.2f}")
            print(f"   Decisión IA: {señal.get('ia_decision', 'N/A')}")
            print(f"   Probabilidad: {señal.get('probabilidad_win', 0):.2f}")
            print(f"   Confirmación FVG: {'Sí' if señal.get('confirmacion_fvg', False) else 'No'}")
            print(f"   Confirmación Total: {'Sí' if señal.get('confirmacion_total', False) else 'No'}")
        
        print("\n============================================================")

    async def run(self):
        """Bucle principal del bot que analiza el mercado y reporta las mejores señales
        sin ejecutar operaciones reales."""
        logging.info("Bot de análisis iniciado correctamente.")
        errores_consecutivos = 0
        max_errores_permitidos = 5
        intervalo_analisis = 30  # Segundos entre cada análisis

        while True:
            try:
                logging.info(f"Actualizando datos de velas...")
                await self.update_candles()
                
                if any(df is None or df.empty for df in [self.data_30m, self.data_5m, self.data_1m]):
                    logging.warning("No se pudieron obtener datos de velas completos. Reintentando en 15 segundos...")
                    await asyncio.sleep(15)
                    continue
                    
                logging.info(f"Iniciando análisis de mercado...")
                resultado_analisis = await self.analyze_and_report()
                
                if isinstance(resultado_analisis, dict):
                    errores_consecutivos = 0  # Resetear errores si el análisis fue exitoso
                    
                    if resultado_analisis.get("estado") == "sin_datos":
                        logging.warning("No hay datos suficientes para análisis. Esperando...")
                        await asyncio.sleep(15)
                        continue
                        
                    if resultado_analisis.get("estado") == "sin_señales":
                        logging.info("Análisis completado: No se detectaron señales válidas")
                    elif resultado_analisis.get("mejores_señales"):
                        num_señales = len(resultado_analisis.get("mejores_señales", []))
                        logging.info(f"Análisis completado: Se encontraron {num_señales} mejores señales")
                        # Mostrar resumen en consola usando el método de la clase
                        self.mostrar_mejores_señales(resultado_analisis)
                        
                    logging.info(f"Esperando {intervalo_analisis} segundos para el próximo análisis...")
                    await asyncio.sleep(intervalo_analisis)
                else:
                    errores_consecutivos += 1
                    logging.error(f"Resultado inesperado de analyze_and_report. Reintentando en 15 segundos...")
                    await asyncio.sleep(15)

                if errores_consecutivos >= max_errores_permitidos:
                    logging.error(f"Demasiados errores consecutivos ({errores_consecutivos}). Reiniciando bot...")
                    await self.restart_bot()

            except Exception as e:
                logging.error(f"Error grave en el bucle principal: {e}")
                import traceback
                logging.error(traceback.format_exc())
                errores_consecutivos += 1
                await asyncio.sleep(15)

                if errores_consecutivos >= max_errores_permitidos:
                    logging.error(f"Demasiados errores graves ({errores_consecutivos}). Reiniciando bot...")
                    await self.restart_bot()
    async def restart_bot(self):
        """Reinicia el script completo para recuperar el bot automáticamente."""
        logging.info("Reiniciando script...")
        await asyncio.sleep(5)
        python = sys.executable
        os.execl(python, python, *sys.argv)
    def get_asset_info(self):
        """Obtiene el par de divisas y si es OTC del usuario."""
        while True:
            self.asset = input("Ingrese el par de divisas (ej: EURUSD): ").upper()
            self.otc = input("¿Es OTC? (s/n): ").lower() == 's'  # Usa 'otc' en lugar de 'is_otc'
            otc_suffix = "_otc" if self.otc else ""
            self.asset_with_otc = self.asset + otc_suffix
            
            if self.asset.isalpha() and len(self.asset) >= 6:
                break
            else:
                print("Par inválido. Intente de nuevo.")
    
    def extraer_features_niveles(self, señal):
        """
        Esta función extrae las características de los niveles de soporte y resistencia
        necesarias para la predicción del modelo.
        Maneja casos donde las columnas no existen.
        """
        try:
            # Verificar si las columnas existen, usar valores predeterminados si no
            features = [
                señal.get("nivel_soporte_1", 0),
                señal.get("nivel_resistencia_1", 0),
                señal.get("nivel_soporte_2", 0),
                señal.get("nivel_resistencia_2", 0),
                señal.get("nivel_soporte_3", 0),
                señal.get("nivel_resistencia_3", 0),
                señal.get("distancia_a_soporte", 0),
                señal.get("distancia_a_resistencia", 0),
            ]
            
            # Verificar si todos los valores son válidos
            if all(isinstance(x, (int, float)) for x in features):
                return features
            else:
                logging.warning("Algunos valores de características no son numéricos")
                return [0] * 8  # Valores predeterminados si no son numéricos
                
        except Exception as e:
            logging.error(f"Error al extraer características de niveles: {e}")
            return [0] * 8  # Devuelve una lista de valores por defecto en caso de error

    def extraer_features_de_señal(self, señal):
        """
        Extrae las características relevantes de una señal de trading para el modelo de predicción.
        Incluye manejo de columnas faltantes y valores por defecto.
        """
        try:
            # Conversión segura de valores numéricos
            def safe_get_float(key, default=0):
                try:
                    return float(señal.get(key, default))
                except:
                    return default
            
            # Mapas de codificación para variables categóricas
            trend_map = {
                'alcista': 1, 'bajista': -1, 'neutral': 0,
                'bullish': 1, 'bearish': -1
            }
            confidence_map = {
                'alta': 3, 'media': 2, 'baja': 1
            }
            flip_type_map = {
                'soporte': 1, 'resistencia': 2, 'ninguno': 0
            }

            # Normalización segura de strings
            trend = trend_map.get(str(señal.get('trend', 'neutral')).lower(), 0)
            confidence = confidence_map.get(str(señal.get('confidence', 'media')).lower(), 2)
            flip_type = flip_type_map.get(str(señal.get('flip_type', 'ninguno')).lower(), 0)

            return {
                'price_action': safe_get_float('price_action'),
                'trend': trend,
                'confidence': confidence,
                'score': safe_get_float('score'),
                'flip_distance': safe_get_float('flip_distance'),
                'body_size': safe_get_float('body_size'),
                'mecha_superior_pct': safe_get_float('mecha_superior_pct'),
                'mecha_inferior_pct': safe_get_float('mecha_inferior_pct'),
                'ob_body_size': safe_get_float('ob_body_size'),           # NUEVO
                'prev_body_size': safe_get_float('prev_body_size'),       # NUEVO
                'flip_type': flip_type,                                   # NUEVO
                'estructura': int(señal.get('estructura', 0)),            # NUEVO
                'orderblock': int(señal.get('orderblock', 0)),            # NUEVO
                'validacion5m': int(señal.get('validacion5m', 0)),        # NUEVO
            }

        except Exception as e:
            logging.error(f"❌ Error al extraer features de señal: {e}")
            # Devolver un diccionario con todas las claves necesarias en caso de error
            return {
                'price_action': 0,
                'trend': 0,
                'confidence': 2,
                'score': 0,
                'flip_distance': 0,
                'body_size': 0,
                'mecha_superior_pct': 0,
                'mecha_inferior_pct': 0,
                'ob_body_size': 0,
                'prev_body_size': 0,
                'flip_type': 0,
                'estructura': 0,
                'orderblock': 0,
                'validacion5m': 0,
            }


    def preparar_features_para_modelo_lgbm(self, senal):
        """
        Prepara exactamente las 10 características esperadas por el modelo LightGBM,
        con valores por defecto si faltan datos.
        """
        try:
            # Codificar valores categóricos como numéricos
            trend_map = {'alcista': 1, 'Alcista': 1, 'bullish': 1, 'Bullish': 1, 'bajista': -1, 'Bajista': -1, 'bearish': -1, 'Bearish': -1, 'neutral': 0, 'Neutral': 0}
            confidence_map = {'alta': 3, 'Alta': 3, 'high': 3, 'High': 3, 'media': 2, 'Media': 2, 'medium': 2, 'Medium': 2, 'baja': 1, 'Baja': 1, 'low': 1, 'Low': 1}
            signal_map = {'buy': 1, 'Buy': 1, 'sell': -1, 'Sell': -1, 'wait': 0, 'Wait': 0}
            
            # Obtener valores con manejo de errores
            trend_str = str(senal.get('trend', 'neutral')).lower()
            confidence_str = str(senal.get('confidence', 'media')).lower()
            signal_str = str(senal.get('Type', 'wait')).lower()
            
            trend_encoded = trend_map.get(trend_str, 0)
            confidence_encoded = confidence_map.get(confidence_str, 2)
            signal_encoded = signal_map.get(signal_str, 0)
            
            # Asegurar que todos los valores son numéricos
            score = float(senal.get('score', 0)) if isinstance(senal.get('score'), (int, float)) else 0
            key_level = float(senal.get('Level', 0)) if isinstance(senal.get('Level'), (int, float)) else 0
            is_otc = 1 if senal.get('is_otc', self.otc) else 0
            flip_distance = float(senal.get('flip_distance', 0)) if isinstance(senal.get('flip_distance'), (int, float)) else 0
            body_size = float(senal.get('body_size', 0)) if isinstance(senal.get('body_size'), (int, float)) else 0
            mecha_superior_pct = float(senal.get('mecha_superior_pct', 0)) if isinstance(senal.get('mecha_superior_pct'), (int, float)) else 0
            mecha_inferior_pct = float(senal.get('mecha_inferior_pct', 0)) if isinstance(senal.get('mecha_inferior_pct'), (int, float)) else 0
            
            # Arreglo de características en el orden exacto esperado por el modelo
            features = [
                score,
                key_level,
                is_otc,
                trend_encoded,
                confidence_encoded,
                signal_encoded,
                flip_distance,
                body_size,
                mecha_superior_pct,
                mecha_inferior_pct
            ]
            
            return features
            
        except Exception as e:
            logging.error(f"Error preparando features para LGBM: {e}")
            # Retornar valores predeterminados en caso de error (10 características como espera el modelo)
            return [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

    def extraer_features_lightgbm(self, vela_actual, niveles_flip):
        """
        Extrae las 10 características para el modelo LightGBM.

        vela_actual: pd.Series con información de la vela actual.
        niveles_flip: lista de niveles relevantes.
        """
        try:
            # Validar que vela_actual sea un pd.Series
            if not isinstance(vela_actual, pd.Series):
                raise TypeError("El argumento 'vela' debe ser un pd.Series.")
            
            # Extraer los features asegurando que sean numéricos donde corresponda
            features = {
                'score': float(vela_actual.get('score', 0)),
                'key_level': float(vela_actual.get('Level', 0)),
                'is_otc': int(getattr(self, 'otc', False)),
                'trend_encoded': {"Alcista": 1, "Bajista": -1, "Rango": 0, "Indefinida": 0}.get(
                    str(vela_actual.get("Trend", "Rango")), 0),
                'confidence_encoded': {"Alta": 2, "Media": 1, "Baja": 0, "N/A": 0}.get(
                    str(vela_actual.get("Confidence", "Media")), 1),
                'signal_encoded': 1 if str(vela_actual.get("Type")) == "Buy" else 0,
                'flip_distance': float(vela_actual.get('flip_distance', 0)),
                'body_size': float(vela_actual.get('body_size', 0)),
                'mecha_superior_pct': float(vela_actual.get('mecha_superior_pct', 0)),
                'mecha_inferior_pct': float(vela_actual.get('mecha_inferior_pct', 0)),
            }
            return features

        except Exception as e:
            logging.error(f"Error en extraer_features_lightgbm: {e}")
            return self._get_default_lightgbm_features_10()

    def _get_default_lightgbm_features_10(self):
        """Devuelve valores por defecto para las características del modelo LightGBM."""
        return {
            'score': 0.0,
            'key_level': 0.0,
            'is_otc': 0,
            'trend_encoded': 0,
            'confidence_encoded': 1,
            'signal_encoded': 0,
            'flip_distance': 0.0,
            'body_size': 0.0,
            'mecha_superior_pct': 0.0,
            'mecha_inferior_pct': 0.0,
        }

    

    @retry(max_retries=5, delay=10)
    async def update_candles(self):
        """Actualiza los datos de velas para 30M, 5M y 1M."""
        try:
            logging.info("Actualizando velas...")
            candles_1m, candles_5m, candles_30m = await get_candles_three_timeframes(
                self.api, self.asset_with_otc, 60, 300, 1800, 3600 * 24
            )
            self.data_1m = candles_1m
            self.data_5m = candles_5m
            self.data_30m = candles_30m
            logging.info("Velas actualizadas correctamente.")
        except Exception as e:
            logging.error(f"Error al actualizar velas: {e}")
            self.data_1m, self.data_5m, self.data_30m = None, None, None
    
   
    async def actualizar_datos_1m(self):
        """Actualiza las velas de 1 minuto."""
        try:
            data = await self.api.get_candles(self.asset_with_otc, 60, 60)  # Últimos 60 velas de 1m
            # Convertirlo en DataFrame
            self.data_1m = pd.DataFrame(data)
            logging.info(" Velas de 1M actualizadas correctamente.")
        except Exception as e:
            logging.error(f" Error actualizando velas de 1M: {e}")

    def analyze_independent_1m(self, data_1m, tested_levels_1m):
        """
        Analiza múltiples señales independientes en 1M, considerando la proximidad al precio actual.
        Devuelve todas las señales encontradas, incluyendo las características para el modelo de dirección.
        """
        señales = []
        if data_1m is None or data_1m.empty or len(data_1m) < 3 or not tested_levels_1m:
            logging.warning("No hay suficientes datos para analizar en 1M o no hay niveles testeados.")
            return señales

        last = data_1m.iloc[-1]
        prev = data_1m.iloc[-2]
        #tolerance = 0.0002  # Ya no usamos un tolerance fijo, ahora es adaptativo
        
        current_price = data_1m['close'].iloc[-1]
        proximidad_relativa = current_price * 0.001  # 0.1% del precio actual
        proximidad_absoluta = 0.1  # Por ejemplo, 0.1 unidades de precio

        for level in tested_levels_1m:
            # Rebote Alcista
            if last['low'] <= level + min(proximidad_relativa, proximidad_absoluta) and last['close'] > level and last['close'] > last['open']:
                price_action = self.calcular_price_action(data_1m)
                trend = "Buy"
                body_size = self.calcular_body_size(last)
                mecha_superior_pct = self.calcular_mecha_superior_pct(last)
                mecha_inferior_pct = self.calcular_mecha_inferior_pct(last)
                prev_body_size = self.calcular_prev_body_size(prev)
                ob_body_size = self.calcular_ob_body_size(last)
                señal = {
                    "Type": "Buy",
                    "Level": level,
                    "Reason": "Rebote 1M",
                    "Confidence": "Media",
                    "price_action": price_action,
                    "Trend": trend,
                    "body_size": body_size,
                    "mecha_superior_pct": mecha_superior_pct,
                    "mecha_inferior_pct": mecha_inferior_pct,
                    "prev_body_size": prev_body_size,
                    "ob_body_size": ob_body_size,
                }
                señales.append(señal)

            # Rebote Bajista
            elif last['high'] >= level - min(proximidad_relativa, proximidad_absoluta) and last['close'] < level and last['close'] < last['open']:
                price_action = self.calcular_price_action(data_1m)
                trend = "Sell"
                body_size = self.calcular_body_size(last)
                mecha_superior_pct = self.calcular_mecha_superior_pct(last)
                mecha_inferior_pct = self.calcular_mecha_inferior_pct(last)
                prev_body_size = self.calcular_prev_body_size(prev)
                ob_body_size = self.calcular_ob_body_size(last)
                señal = {
                    "Type": "Sell",
                    "Level": level,
                    "Reason": "Rebote 1M",
                    "Confidence": "Media",
                    "price_action": price_action,
                    "Trend": trend,
                    "body_size": body_size,
                    "mecha_superior_pct": mecha_superior_pct,
                    "mecha_inferior_pct": mecha_inferior_pct,
                    "prev_body_size": prev_body_size,
                    "ob_body_size": ob_body_size,
                }
                señales.append(señal)

            # Rompimiento Alcista
            elif last['close'] > level and prev['close'] <= level and last['close'] > last['open']:
                price_action = self.calcular_price_action(data_1m)
                trend = "Buy"
                body_size = self.calcular_body_size(last)
                mecha_superior_pct = self.calcular_mecha_superior_pct(last)
                mecha_inferior_pct = self.calcular_mecha_inferior_pct(last)
                prev_body_size = self.calcular_prev_body_size(prev)
                ob_body_size = self.calcular_ob_body_size(last)
                señal = {
                    "Type": "Buy",
                    "Level": level,
                    "Reason": "Rompimiento 1M",
                    "Confidence": "Media",
                    "price_action": price_action,
                    "Trend": trend,
                    "body_size": body_size,
                    "mecha_superior_pct": mecha_superior_pct,
                    "mecha_inferior_pct": mecha_inferior_pct,
                    "prev_body_size": prev_body_size,
                    "ob_body_size": ob_body_size,
                }
                señales.append(señal)

            # Rompimiento Bajista
            elif last['close'] < level and prev['close'] >= level and last['close'] < last['open']:
                price_action = self.calcular_price_action(data_1m)
                trend = "Sell"
                body_size = self.calcular_body_size(last)
                mecha_superior_pct = self.calcular_mecha_superior_pct(last)
                mecha_inferior_pct = self.calcular_mecha_inferior_pct(last)
                prev_body_size = self.calcular_prev_body_size(prev)
                ob_body_size = self.calcular_ob_body_size(last)
                señal = {
                    "Type": "Sell",
                    "Level": level,
                    "Reason": "Rompimiento 1M",
                    "Confidence": "Media",
                    "price_action": price_action,
                    "Trend": trend,
                    "body_size": body_size,
                    "mecha_superior_pct": mecha_superior_pct,
                    "mecha_inferior_pct": mecha_inferior_pct,
                    "prev_body_size": prev_body_size,
                    "ob_body_size": ob_body_size,
                }
                señales.append(señal)

            # Falso rompimiento Alcista
            elif prev['close'] > level and last['close'] < level and last['close'] < last['open']:
                price_action = self.calcular_price_action(data_1m)
                trend = "Sell"
                body_size = self.calcular_body_size(last)
                mecha_superior_pct = self.calcular_mecha_superior_pct(last)
                mecha_inferior_pct = self.calcular_mecha_inferior_pct(last)
                prev_body_size = self.calcular_prev_body_size(prev)
                ob_body_size = self.calcular_ob_body_size(last)
                señal = {
                    "Type": "Sell",
                    "Level": level,
                    "Reason": "Falso Rompimiento 1M",
                    "Confidence": "Baja",
                    "price_action": price_action,
                    "Trend": trend,
                    "body_size": body_size,
                    "mecha_superior_pct": mecha_superior_pct,
                    "mecha_inferior_pct": mecha_inferior_pct,
                    "prev_body_size": prev_body_size,
                    "ob_body_size": ob_body_size,
                }
                señales.append(señal)

            # Falso rompimiento Bajista
            elif prev['close'] < level and last['close'] > level and last['close'] > last['open']:
                price_action = self.calcular_price_action(data_1m)
                trend = "Buy"
                body_size = self.calcular_body_size(last)
                mecha_superior_pct = self.calcular_mecha_superior_pct(last)
                mecha_inferior_pct = self.calcular_mecha_inferior_pct(last)
                prev_body_size = self.calcular_prev_body_size(prev)
                ob_body_size = self.calcular_ob_body_size(last)
                señal = {
                    "Type": "Buy",
                    "Level": level,
                    "Reason": "Falso Rompimiento 1M",
                    "Confidence": "Baja",
                    "price_action": price_action,
                    "Trend": trend,
                    "body_size": body_size,
                    "mecha_superior_pct": mecha_superior_pct,
                    "mecha_inferior_pct": mecha_inferior_pct,
                    "prev_body_size": prev_body_size,
                    "ob_body_size": ob_body_size,
                }
                señales.append(señal)
        return señales

   
    def analyze_validacion_5m(self, data_1m, validated_5m, ob_signals):
        """
        Genera señales basadas en la validación de niveles de 5M, incluyendo la proximidad al precio actual
        y las características necesarias para el modelo de dirección del mercado.

        Args:
            data_1m (pd.DataFrame): DataFrame con datos de 1 minuto.
            validated_5m (list): Lista de niveles validados en 5M.
            ob_signals (list): Lista de señales de Order Blocks.

        Returns:
            list: Lista de señales generadas.
        """
        if not validated_5m:
            return []

        señales = []
        last_candle_1m = data_1m.iloc[-1]
        direction = "Buy" if last_candle_1m['close'] > last_candle_1m['open'] else "Sell"
        
        current_price = data_1m['close'].iloc[-1]
        proximidad_relativa = current_price * 0.001  # 0.1% del precio actual
        proximidad_absoluta = 0.1  # Por ejemplo, 0.1 unidades de precio

        for nivel_5m in validated_5m:
            # Extraer el nivel del diccionario si es un diccionario, o usar el valor directamente si es un número
            nivel_valor = nivel_5m.get('Level') if isinstance(nivel_5m, dict) else nivel_5m
            
            # Verifica que el nivel sea un número válido
            if not isinstance(nivel_valor, (int, float)):
                continue
                
            # Verifica la proximidad del nivel al precio actual
            if abs(current_price - nivel_valor) <= min(proximidad_relativa, proximidad_absoluta):
                # Calcula las características para el modelo de dirección
                price_action = self.calcular_price_action(data_1m)
                trend = self.obtener_tendencia(data_1m)  # Usa data_1m para la tendencia a corto plazo
                body_size = self.calcular_body_size(data_1m)
                mecha_superior_pct = self.calcular_mecha_superior_pct(data_1m)
                mecha_inferior_pct = self.calcular_mecha_inferior_pct(data_1m)
                prev_body_size = self.calcular_prev_body_size(data_1m)
                ob_body_size = self.calcular_ob_body_size(data_1m)

                señal = {
                    "Type": direction,
                    "Level": nivel_valor,
                    "Confidence": "Media",  # O el valor que corresponda
                    "Categoria": "Validacion5M",
                    "Reason": "Nivel probado 5M",
                    # Añade las características para el modelo de dirección
                    "price_action": price_action,
                    "Trend": trend,
                    "body_size": body_size,
                    "mecha_superior_pct": mecha_superior_pct,
                    "mecha_inferior_pct": mecha_inferior_pct,
                    "prev_body_size": prev_body_size,
                    "ob_body_size": ob_body_size,
                    "OrderBlockRelacionado": any(abs(nivel_valor - ob['nivel_ob']) <= 0.0008 for ob in ob_signals),
                }
                señales.append(señal)
        return señales

    def analyze_coincidencias_1m_5m(self, data_1m, tested_1m, validated_5m, ob_signals):
        """
        Evalúa coincidencias entre niveles 1M y 5M, combinando proximidad relativa y absoluta.
        Devuelve una lista de señales válidas.
        """
        señales = []
        if not tested_1m or not validated_5m:
            return señales

        current_price = data_1m['close'].iloc[-1]
        proximidad_relativa = current_price * 0.001  # 0.1% del precio actual
        proximidad_absoluta = 0.1  # Por ejemplo, 0.1 unidades de precio

        last = data_1m.iloc[-1]
        prev = data_1m.iloc[-2]  # Agregamos la vela anterior
        direction = 'Buy' if last['close'] > last['open'] else 'Sell'

        for lvl1 in tested_1m:
            # Extraer el nivel 1M
            nivel_1m = lvl1.get('Level') if isinstance(lvl1, dict) else lvl1
            if not isinstance(nivel_1m, (int, float)):
                continue
                
            for lvl5 in validated_5m:
                # Extraer el nivel 5M
                nivel_5m = lvl5.get('Level') if isinstance(lvl5, dict) else lvl5
                if not isinstance(nivel_5m, (int, float)):
                    continue
                    
                # Combinamos ambos criterios: la proximidad debe ser menor que *ambos* límites.
                if abs(nivel_1m - nivel_5m) <= min(proximidad_relativa, proximidad_absoluta):
                    # Aseguramos que todas las características estén presentes
                    price_action = self.calcular_price_action(data_1m)
                    trend = direction  # La tendencia aquí se basa en la última vela de 1M
                    body_size = self.calcular_body_size(last)
                    mecha_superior_pct = self.calcular_mecha_superior_pct(last)
                    mecha_inferior_pct = self.calcular_mecha_inferior_pct(last)
                    prev_body_size = self.calcular_prev_body_size(prev)  # Usamos prev
                    ob_body_size = self.calcular_ob_body_size(last)

                    señal = {
                        "Type": direction,
                        "Level": nivel_1m,
                        "Reason": "Coincidencia 1M-5M",
                        "Confidence": "Alta",
                        "OrderBlockRelacionado": any(abs(nivel_1m - ob['nivel_ob']) <= 0.0008 for ob in ob_signals),
                        # Características para el modelo de dirección
                        "price_action": price_action,
                        "Trend": trend,
                        "body_size": body_size,
                        "mecha_superior_pct": mecha_superior_pct,
                        "mecha_inferior_pct": mecha_inferior_pct,
                        "prev_body_size": prev_body_size,
                        "ob_body_size": ob_body_size,
                    }
                    señales.append(señal)
        return señales

    def analyze_flexible_strategy(self, data_1m, data_5m, flexible_m5_analyzer, flexible_m1_analyzer):
        """
        Ejecuta la estrategia flexible detectando niveles en 5M y buscando confirmaciones en 1M,
        considerando la proximidad del precio actual al nivel.
        Asegura que se proporcionen todas las características necesarias para el modelo de dirección.
        """
        señales_finales = []

        try:
            esquemas_5m = flexible_m5_analyzer.analyze(data_5m)
            señales_1m = flexible_m1_analyzer.analyze_concepts(data_1m, esquemas_5m)
            
            current_price = data_1m['close'].iloc[-1]
            proximidad_relativa = current_price * 0.001  # 0.1% del precio actual
            proximidad_absoluta = 0.1  # Por ejemplo, 0.1 unidades de precio

            for señal in señales_1m:
                level = señal.get("Level")
                tipo = señal.get("Type")
                reason = señal.get("Reason", "Flexible")
                confidence = señal.get("Confidence", "Media")

                # Verificamos si esta señal tiene un esquema 5M cerca
                esquema_relacionado = None
                for esquema in esquemas_5m:
                    if abs(level - esquema['Level']) <= 0.0005:
                        esquema_relacionado = esquema
                        break
                
                # Solo considerar la señal si el precio está cerca del nivel
                if abs(current_price - level) <= min(proximidad_relativa, proximidad_absoluta):

                    # Dirección asegurada
                    direccion = tipo if tipo in ["Buy", "Sell"] else "Buy"  # define dirección correctamente

                    # *** Aseguramos que todas las características estén presentes ***
                    price_action = self.calcular_price_action(data_1m)  # Debes implementar esta función
                    trend = self.obtener_tendencia(data_5m)  # Debes implementar esta función
                    body_size = self.calcular_body_size(data_1m)  # Debes implementar esta función
                    mecha_superior_pct = self.calcular_mecha_superior_pct(data_1m)  # Debes implementar esta función
                    mecha_inferior_pct = self.calcular_mecha_inferior_pct(data_1m)  # Debes implementar esta función
                    prev_body_size = self.calcular_prev_body_size(data_1m)  # Debes implementar esta función
                    ob_body_size = self.calcular_ob_body_size(data_1m)  # Debes implementar esta función

                    señal_flexible = {
                        "Type": direccion,
                        "Level": level,
                        "Confidence": confidence,
                        "Categoria": "Flexible",
                        "Reason": reason,
                        "Strategy": "Flexible_M1M5",
                        "Nombre": f"{reason} confirmado en esquema flexible",
                        "Esquema": esquema_relacionado['scheme'] if esquema_relacionado else "Sin esquema",
                        "OrderBlockRelacionado": False,  # Por ahora lo dejamos en False ya que no tenemos ob_signals aquí
                        "price_action": price_action,
                        "Trend": trend,
                        "body_size": body_size,
                        "mecha_superior_pct": mecha_superior_pct,
                        "mecha_inferior_pct": mecha_inferior_pct,
                        "prev_body_size": prev_body_size,
                        "ob_body_size": ob_body_size,
                    }

                    señales_finales.append(señal_flexible)

        except Exception as e:
            logging.error(f"Error en estrategia flexible: {e}")

        return señales_finales
    

    def _detectar_bos_choch(self):
        """
        Detecta niveles BOS/CHOCH para diagnóstico de estructura.
        Retorna lista de niveles/señales detectadas.
        """
        try:
            # Verificar datos disponibles
            if self.data_1m is None or self.data_5m is None:
                logging.warning("Datos 1M o 5M no disponibles para BOS/CHOCH")
                self.bos_choch = []
                return []
            
            # Obtener tendencia
            tendencia = self.m5_analyzer.get_trend(self.data_5m)
            
            # Verificar analyzers
            if self.flexible_m1_analyzer is None or self.flexible_m5_analyzer is None:
                logging.warning("Analyzers no disponibles para BOS/CHOCH")
                self.bos_choch = []
                return []
            
           
            
            # Detectar BOS/CHOCH (asumiendo que la función existe)
            if hasattr(self, 'detectar_bos_choch') or 'detectar_bos_choch' in globals():
                bos_choch_results = detectar_bos_choch(self.data_1m, tendencia_actual=tendencia)
            else:
                # Si no existe la función externa, crear estructura básica
                logging.warning("Función detectar_bos_choch no encontrada, creando estructura vacía")
                bos_choch_results = []
            
            # Asignar y retornar
            self.bos_choch = bos_choch_results if isinstance(bos_choch_results, list) else []
            
            logging.info(f"BOS/CHOCH detectados: {len(self.bos_choch)}")
            return self.bos_choch
            
        except Exception as e:
            logging.error(f"Error en _detectar_bos_choch: {e}")
            self.bos_choch = []
            return []

    def detectar_sibi_bisi(self):
        if self.data_1m is not None:
            self.sibi_bisi = detectar_fvg(self.data_1m)
        else:
            self.sibi_bisi = []
    
    def _calculate_sibi_bisi_and_bos_choch(self, data_30m: pd.DataFrame, data_5m: pd.DataFrame) -> Tuple[str, str, str, str]:
        """
        Calculates simplified string states for SIBI, BISI, BOS, and CHoCH
        based on overall market context (30M, 5M data).
        """
        states = {
        'sibi': "none",
        'bisi': "none",
        'bos': "none",
        'choch': "none"
        }

        try:
            if (not data_30m.empty and len(data_30m) >= 2 and 
                not data_5m.empty and len(data_5m) >= 2):
                
                last_30m_close = data_30m['close'].iloc[-1]
                last_5m_close = data_5m['close'].iloc[-1]

                # SIBI/BISI calculation
                if last_30m_close > last_5m_close:
                    states['sibi'] = "presente"
                else:
                    states['bisi'] = "presente"
                
                # BOS calculation
                states['bos'] = ("alcista" if data_5m['close'].iloc[-1] > 
                            data_5m['close'].iloc[-2] else "bajista")
                
                # TODO: Implement proper CHoCH logic instead of fixed value
                states['choch'] = "bajista"

            else:
                insufficient_data_msg = ("Insufficient candles in 30M or 5M for "
                                    "precise market states calculation.")
                logging.warning(insufficient_data_msg)

        except Exception as e:
            logging.error(f"Error calculating market states: {e}", exc_info=True)
        
        return states['sibi'], states['bisi'], states['bos'], states['choch']
        
        

    def resumen_bos_choch(self): # <--- PLACE THE FUNCTION HERE
        """
        Genera un resumen de los últimos eventos BOS y CHoCH detectados.
        """
        resumen = {"bos": "none", "choch": "none"}
        for item in self.bos_choch:
            if item.get("tipo") == "bos":
                resumen["bos"] = item.get("direccion")
            elif item.get("tipo") == "choch":
                resumen["choch"] = item.get("direccion")
        return resumen
    def detectar_orderblocks(self):
        if self.data_5m is not None and self.data_1m is not None:
            niveles = self.m5_analyzer.find_tested_levels(self.data_5m)
            resultado = self.detectar_order_blocks(self.data_5m, self.data_1m, niveles)

            if isinstance(resultado, list) and all(isinstance(x, dict) for x in resultado):
                self.orderblocks = resultado
            else:
                print(" detectar_order_blocks devolvió un tipo inesperado")
                self.orderblocks = []
        else:
            self.orderblocks = []
    def _detect_fvg(self, data: pd.DataFrame) -> List[Dict[str, Any]]:
        """
        Detecta Fair Value Gaps (FVG), BISI y SIBI en los datos de precio y genera señales.
        Este es el método interno de la clase TradingBot.

        Args:
            data (pd.DataFrame): DataFrame con datos de velas (high, low, open, close, time).
                                 Debería ser self.candles_m1 o self.candles_m5.

        Returns:
            list: Lista de diccionarios, donde cada diccionario representa un FVG, BISI o SIBI
                  y contiene información para generar una señal de trading.
        """
        fvg_zonas = []
        
        if data.empty or len(data) < 3:
            logging.debug("FVG: Datos insuficientes para detectar FVG. Se requieren al menos 3 velas.")
            return fvg_zonas

        current_price = data['close'].iloc[-1]
        proximidad_relativa = current_price * 0.005  # 0.5% del precio actual
        proximidad_absoluta = 0.5  # 0.5 unidades de precio (ajusta según el instrumento)
        
        # Iteramos en orden inverso para encontrar los patrones más recientes primero
        for i in range(len(data) - 1, 2, -1):
            # Si ya tenemos suficientes patrones, paramos
            if len(fvg_zonas) >= self.fvg_max_patterns:
                break
                
            vela_1 = data.iloc[i - 2]
            vela_2 = data.iloc[i - 1]
            vela_3 = data.iloc[i]

            # --- FVG Alcista ---
            # Un FVG alcista ocurre cuando el low de la vela 2 es mayor que el high de la vela 1
            # y el low de la vela 2 es mayor que el high de la vela 3.
            # Esto crea un "vacío" de liquidez que el precio tiende a rellenar.
            if vela_2['low'] > vela_1['high'] and vela_2['low'] > vela_3['high']:
                nivel_fvg = vela_2['low']
                # Solo comprobamos proximidad si no estamos ignorándola
                if self.fvg_ignore_proximity or abs(current_price - nivel_fvg) <= min(proximidad_relativa, proximidad_absoluta):
                    fvg_zonas.append({
                        'tipo': 'fvg_alcista',
                        'señal': 'Compra',  # Señal de compra para FVG alcista
                        'zona_superior': vela_1['high'],
                        'zona_inferior': vela_3['low'],
                        'nivel': nivel_fvg,  # Añadimos el nivel específico
                        'timestamp': vela_2['time'],
                        'esquema': 'FVG',
                        'Confidence': 'Media',
                        'distancia_precio': abs(current_price - nivel_fvg)
                    })

            # --- FVG Bajista ---
            # Un FVG bajista ocurre cuando el high de la vela 2 es menor que el low de la vela 1
            # y el high de la vela 2 es menor que el low de la vela 3.
            # Esto también crea un "vacío" de liquidez.
            elif vela_2['high'] < vela_1['low'] and vela_2['high'] < vela_3['low']:
                nivel_fvg = vela_2['high']
                if self.fvg_ignore_proximity or abs(current_price - nivel_fvg) <= min(proximidad_relativa, proximidad_absoluta):
                    fvg_zonas.append({
                        'tipo': 'fvg_bajista',
                        'señal': 'Venta',  # Señal de venta para FVG bajista
                        'zona_superior': vela_1['low'],
                        'zona_inferior': vela_3['high'],
                        'nivel': nivel_fvg,  # Añadimos el nivel específico
                        'timestamp': vela_2['time'],
                        'esquema': 'FVG',
                        'Confidence': 'Media',
                        'distancia_precio': abs(current_price - nivel_fvg)
                    })

            # --- BISI (Buy-Side Imbalance Sell-Side Inefficiency) ---
            # Un BISI indica una ineficiencia del lado de la venta, a menudo un área donde el precio
            # podría subir para rellenar.
            elif (vela_1['close'] > vela_1['open'] and   # Vela 1 alcista (verde)
                  vela_3['close'] < vela_3['open'] and   # Vela 3 bajista (roja)
                  vela_2['low'] > max(vela_1['high'], vela_3['high'])):  # Vela 2 por encima
                nivel_bisi = vela_2['low']
                if self.fvg_ignore_proximity or abs(current_price - nivel_bisi) <= min(proximidad_relativa, proximidad_absoluta):
                    fvg_zonas.append({
                        'tipo': 'bisi',
                        'señal': 'Venta',  # Señal de venta para BISI (esperamos que el precio caiga para rellenar)
                        'zona_superior': vela_2['low'],
                        'zona_inferior': max(vela_1['high'], vela_3['high']),
                        'nivel': nivel_bisi,  # Añadimos el nivel específico
                        'timestamp': vela_2['time'],
                        'esquema': 'BISI',
                        'Confidence': 'Alta',
                        'distancia_precio': abs(current_price - nivel_bisi)
                    })

            # --- SIBI (Sell-Side Imbalance Buy-Side Inefficiency) ---
            # Un SIBI indica una ineficiencia del lado de la compra, a menudo un área donde el precio
            # podría caer para rellenar.
            elif (vela_1['close'] < vela_1['open'] and   # Vela 1 bajista (roja)
                  vela_3['close'] > vela_3['open'] and   # Vela 3 alcista (verde)
                  vela_2['high'] < min(vela_1['low'], vela_3['low'])):  # Vela 2 por debajo
                nivel_sibi = min(vela_1['low'], vela_3['low'])
                if self.fvg_ignore_proximity or abs(current_price - nivel_sibi) <= min(proximidad_relativa, proximidad_absoluta):
                    fvg_zonas.append({
                        'tipo': 'sibi',
                        'señal': 'Compra',  # Señal de compra para SIBI (esperamos que el precio suba para rellenar)
                        'zona_superior': min(vela_1['low'], vela_3['low']),
                        'zona_inferior': vela_2['high'],
                        'nivel': nivel_sibi,  # Añadimos el nivel específico
                        'timestamp': vela_2['time'],
                        'esquema': 'SIBI',
                        'Confidence': 'Alta',
                        'distancia_precio': abs(current_price - nivel_sibi)
                    })
        
        # Ordenamos por distancia al precio actual para priorizar los más cercanos
        fvg_zonas.sort(key=lambda x: x['distancia_precio'])
        return fvg_zonas
    def detectar_consolidaciones(self):
        if self.data_5m is not None:
            niveles = self.m5_analyzer.find_tested_levels(self.data_5m)
            self.consolidaciones = self.detectar_consolidaciones(self.data_5m, niveles)
        else:
            self.consolidaciones = []

    def analizar_estructura_total(self):
        self.detectar_bos_choch()
        self.detectar_sibi_bisi()
        self.detectar_orderblocks()
        self.detectar_consolidaciones()

    def estructura_valida(self):
        return bool(self.bos_choch) or any(x['tipo'] in ['sibi', 'bisi'] for x in self.sibi_bisi)

    def analizar_y_validar_estructura(self):
        self.analizar_estructura_total()
        if not self.estructura_valida():
            print(" Estructura inválida: no hay BOS/CHOCH ni SIBI/BISI.")
            return False
        print(" Estructura válida detectada.")
        return True

    def determinar_tendencia(self, data, ventana=10):
        """
        Determina la tendencia predominante en los datos usando un método simple de comparación de medias móviles.

        Args:
            data (pd.DataFrame): DataFrame con datos de velas.
            ventana (int): Número de velas para el cálculo de la media móvil.

        Returns:
            str: "Alcista" o "Bajista".
        """
        data['SMA'] = data['close'].rolling(window=ventana).mean()
        ultima_media = data['SMA'].iloc[-1]
        penultima_media = data['SMA'].iloc[-2]

        if ultima_media > penultima_media:
            return "Alcista"
        else:
            return "Bajista"
    # ========== Funciones auxiliares de gestión de flips ==========

    def get_flip_info(self, level=None, distance_threshold=float('inf'), time_threshold=float('inf')):
        """
        Obtiene flips ya detectados por FlexibleM1Analyzer y FlexibleM5Analyzer,
        filtrando por distancia y tiempo.
        """
        relevant_flips = []
        now = time.time()
        fuentes = []

        try:
            current_price = self.data_1m['close'].iloc[-1] if not self.data_1m.empty else None
            if current_price is None:
                logging.warning("No se puede obtener el precio actual en get_flip_info. Devolviendo lista vacía.")
                return [] # Retorno seguro: siempre una lista

            # Si no se proporciona nivel, usar precio actual
            if level is None:
                level = current_price
                distance_threshold = current_price * 0.002 # 0.2% del precio actual

            # 1. Flips del M5Analyzer
            if hasattr(self, 'flexible_m5_analyzer') and hasattr(self.flexible_m5_analyzer, 'levels_df'):
                df = self.flexible_m5_analyzer.levels_df
                # Añadir validación aquí: asegurarse de que df es un DataFrame
                if isinstance(df, pd.DataFrame) and not df.empty:
                    flips_m5 = df[df['Type'].str.contains('Flip', case=False)].to_dict('records')
                    for flip in flips_m5:
                        flip['Source'] = 'M5'
                    fuentes.extend(flips_m5)
                elif not isinstance(df, pd.DataFrame):
                    logging.warning(f"flexible_m5_analyzer.levels_df no es un DataFrame, es {type(df)}")


            # 2. Flips del M1Analyzer
            if hasattr(self, 'flexible_m1_analyzer') and hasattr(self.flexible_m1_analyzer, 'levels_df'):
                df = self.flexible_m1_analyzer.levels_df
                # Añadir validación aquí: asegurarse de que df es un DataFrame
                if isinstance(df, pd.DataFrame) and not df.empty:
                    flips_m1 = df[df['Type'].str.contains('Flip', case=False)].to_dict('records')
                    for flip in flips_m1:
                        flip['Source'] = 'M1'
                    fuentes.extend(flips_m1)
                elif not isinstance(df, pd.DataFrame):
                    logging.warning(f"flexible_m1_analyzer.levels_df no es un DataFrame, es {type(df)}")


            # 3. Flips recientes (si están)
            # Asegúrate de que self.flip_1m_recientes sea siempre una lista o iterable
            if hasattr(self, 'flip_1m_recientes') and isinstance(self.flip_1m_recientes, list) and self.flip_1m_recientes:
                for flip in self.flip_1m_recientes:
                    flip['Source'] = 'Recientes'
                fuentes.extend(self.flip_1m_recientes)
            elif hasattr(self, 'flip_1m_recientes') and not isinstance(self.flip_1m_recientes, list):
                logging.warning(f"self.flip_1m_recientes no es una lista, es {type(self.flip_1m_recientes)}")

            # 4. Procesar y filtrar flips
            for flip in fuentes:
                try:
                    # Validar que flip sea un diccionario antes de usar .get()
                    if not isinstance(flip, dict):
                        logging.warning(f"Elemento inesperado en fuentes, no es un diccionario: {type(flip)} - {flip}")
                        continue

                    flip_level = float(flip.get('Level', 0))
                    distancia = abs(level - flip_level)
                    timestamp = flip.get('timestamp', now)
                    
                    # Convertir timestamp si es string
                    if isinstance(timestamp, str):
                        try:
                            timestamp = pd.to_datetime(timestamp).timestamp()
                        except:
                            timestamp = now

                    tiempo_pasado = now - timestamp if isinstance(timestamp, (float, int)) else 0
                    
                    # Calcular métricas adicionales
                    distance_to_price = abs(flip_level - current_price)
                    proximity_score = max(0, 1 - distance_to_price / (current_price * 0.002))
                    is_recent = tiempo_pasado <= 1200 # 20 minutos
                    
                    if distancia <= distance_threshold and tiempo_pasado <= time_threshold:
                        # Enriquecer la información del flip
                        flip_info = {
                            "Level": flip_level,
                            "Type": flip.get("Type", "Buy" if "Bullish" in str(flip.get("Trend", "")) else "Sell"),
                            "timestamp": pd.to_datetime(timestamp, unit='s').isoformat(),
                            "Categoria": "Flip",
                            "Strategy": f"Flip_{flip.get('Source')}",
                            "Confidence": "Alta" if is_recent and proximity_score > 0.7 else "Media",
                            "Reason": f"Flip {'reciente' if is_recent else 'histórico'} en {flip.get('Source')}",
                            "OrderBlockRelacionado": False,
                            "Esquema": "Level_Flip",
                            "Nombre": f"Flip {'alcista' if 'Bullish' in str(flip.get('Trend', '')) else 'bajista'} {'reciente' if is_recent else ''}",
                            "is_recent_flip": is_recent,
                            "proximity_to_current_price": proximity_score,
                            "distancia_precio_actual": distance_to_price,
                            "Source": flip.get('Source'),
                            "tiempo_pasado": tiempo_pasado
                        }
                        relevant_flips.append(flip_info)

                except Exception as e:
                    logging.error(f"Error procesando flip individual en get_flip_info (bucle): {e}")
                    # No es necesario un continue aquí, el bucle ya avanza
                    continue

            # Ordenar por proximidad y si son recientes
            relevant_flips.sort(key=lambda x: (
                x.get("is_recent_flip", False),
                x.get("proximity_to_current_price", 0)
            ), reverse=True)
            
            # Limitar a los 5 flips más relevantes
            relevant_flips = relevant_flips[:5]
            
            logging.info(f"Detectados {len(relevant_flips)} flips relevantes en get_flip_info.")
            return relevant_flips

        except Exception as e:
            logging.error(f"Error general en get_flip_info: {e}. Devolviendo lista vacía.")
            return [] # Retorno seguro: siempre una lista


    def find_relevant_flips(self, signal_level, signal_type, distance_threshold=0.0005, time_threshold=30):
        try:
            return [
                flip for flip in self.get_flip_info(signal_level, distance_threshold, time_threshold)
                if flip.get('Trend', '').lower() == signal_type.lower()
            ]
        except Exception as e:
            logging.error(f"Error al encontrar flips relevantes: {e}")
            return []


    def check_flip_distance(self, current_price, flip_level, max_distance=0.002):
        return abs(current_price - flip_level) <= max_distance


    def get_new_signal_based_on_flip(self, current_price, trend_direction):
        flip_levels = [f['Level'] for f in self.get_flip_info(current_price, distance_threshold=0.001)]
        closest_flip = None

        for level in sorted(flip_levels):
            if trend_direction == "Alcista" and level > current_price:
                closest_flip = level
                break
            elif trend_direction == "Bajista" and level < current_price:
                closest_flip = level
                break

        if closest_flip:
            return {
                "Type": "Buy" if trend_direction == "Alcista" else "Sell",
                "Level": closest_flip,
                "Reason": "Flip cercano basado en tendencia",
                    "Confidence": "Alta",
                "Categoria": "Flip Detectado",
                "Strategy": "Reversión",
                "Nombre": f"Flip en nivel {closest_flip}",
                    "OrderBlockRelacionado": False,
                "Esquema": "Reversión"
            }
            return None
                

    def detectar_flip_tocado(self, current_price, vela, tolerancia_precio=0.0002, tolerancia_vela=0.0002):
        """
        Verifica si el precio actual o la vela ha tocado un flip detectado por los analyzers.
        """
        flip_tocado = None
        max_price = vela.get('high')
        min_price = vela.get('low')

        for flip in self.get_flip_info(current_price, distance_threshold=0.002):
            nivel = flip.get('Level')
            tipo = flip.get('Type')
            if nivel is not None:
                try:
                    nivel = float(nivel)
                    # Check por precio actual
                    if abs(current_price - nivel) <= tolerancia_precio:
                        flip_tocado = {"Level": nivel, "Type": tipo, "Source": flip.get('Source')}
                        logging.info(f"Flip tocado por precio actual en {nivel} (Tipo: {tipo})")
                        return flip_tocado
                    # Check por vela
                    if max_price and min_price and (min_price - tolerancia_vela <= nivel <= max_price + tolerancia_vela):
                        flip_tocado = {"Level": nivel, "Type": tipo, "Source": flip.get('Source')}
                        logging.warning(f"Flip tocado por vela en {nivel} (rango: {min_price}-{max_price}, Tipo: {tipo})")
                        return flip_tocado
                except Exception as e:
                    logging.warning(f"Error al procesar flip: {e}")
                    continue

                return None
                
    def confirmar_con_fvg_y_testeo(self, señal, current_price, fvg_signals):
        """
        Confirma señales usando FVG y testeo mejorado
        """
        # Use current UTC timestamp
        current_time = "2025-06-10 08:30:26"  # Current UTC time
        current_user = "gonzalo00123"
        
        try:
            # Si no hay FVG signals, manejo especial para flips recientes
            if not fvg_signals:
                if señal.get("Categoria") == "Flip" and señal.get("is_recent_flip", False):
                    señal.update({
                        "ConfirmacionFVG": "Parcial",
                        "confirmacion_timestamp": current_time,
                        "confirmacion_details": {
                            "tipo": "flip_reciente",
                            "razon": "Sin FVG pero flip reciente",
                            "usuario": current_user
                        }
                    })
                    return True
                return False

            # Análisis de FVG mejorado
            max_distancia = current_price * 0.0015
            fvg_cercanos = []
            
            for fvg in fvg_signals:
                try:
                    distancia = abs(float(señal.get("Level", 0)) - float(fvg.get("Level", 0)))
                    if distancia <= max_distancia:
                        fvg_cercanos.append({
                            "distancia": distancia,
                            "tipo": fvg.get("tipo"),
                            "nivel": fvg.get("Level", 0)
                        })
                except (ValueError, TypeError) as e:
                    logging.warning(f"Error procesando FVG: {str(e)}")
                    continue

            if fvg_cercanos:
                # Ordenar FVGs por cercanía
                fvg_cercanos.sort(key=lambda x: x["distancia"])
                mejor_fvg = fvg_cercanos[0]

                # Actualizar señal con información detallada
                señal.update({
                    "ConfirmacionFVG": "Sí",
                    "confirmacion_timestamp": current_time,
                    "confirmacion_details": {
                        "tipo": "fvg_cercano",
                        "distancia_fvg": mejor_fvg["distancia"],
                        "tipo_fvg": mejor_fvg["tipo"],
                        "nivel_fvg": mejor_fvg["nivel"],
                        "total_fvgs_cercanos": len(fvg_cercanos),
                        "usuario": current_user
                    }
                })
                
                # Bonus de score por confirmación FVG
                if señal.get("score"):
                    señal["score"] *= 1.1  # 10% bonus
                
                return True
            
            # Si no hay FVGs cercanos
            señal.update({
                "ConfirmacionFVG": "No",
                "confirmacion_timestamp": current_time,
                "confirmacion_details": {
                    "tipo": "sin_fvg_cercano",
                    "max_distancia_permitida": max_distancia,
                    "usuario": current_user
                }
            })
            return False

        except Exception as e:
            logging.error(f"Error en confirmar_con_fvg_y_testeo: {str(e)}")
            señal.update({
                "ConfirmacionFVG": "Error",
                "confirmacion_timestamp": current_time,
                "confirmacion_details": {
                    "tipo": "error",
                    "error": str(e),
                    "usuario": current_user
                }
            })
            return False

    def organizar_estructura_smc(self, current_time):
        """
        Organiza la estructura SMC para reportes
        """
        smc = self.estructura_mercado["smc"]
        
        return {
            "resumen": {
                "tendencia_actual": smc.get("current_trend", "Indefinida"),
                "ultima_actualizacion": current_time,
                "patrones_activos": {
                    "bos": bool(smc.get("bos")),
                    "choch": bool(smc.get("choch")),
                    "orderblocks": len(smc.get("ob_bull", [])) + len(smc.get("ob_bear", [])) > 0,
                    "fvg": len(smc.get("fvg_bull", [])) + len(smc.get("fvg_bear", [])) > 0
                }
            },
            "estructura": smc,
            "señales": [s for s in self.todas_las_senales if s.get("Strategy", "").startswith("SMC_")],
            "last_update": current_time
        }

    
    def deep_check_json_serializable(obj):
        try:
            json.dumps(obj)
            return True
        except Exception as e:
            raise ValueError(f"No serializable: {e}")
    
    def get_señales_activas(self):
        """
        Retorna las señales activas actuales
        """
        return {
            "señales": self.señales_activas,
            "última_actualización": self.última_actualización,
            "total": len(self.señales_activas)
        }
        
    def get_ultimo_resultado(self):
        """
        Retorna el último resultado del análisis
        """
        if self.último_resultado:
            return {
                "timestamp": self.última_actualización,
                "resultado": self.último_resultado,
                "señales_activas": len(self.señales_activas)
            }
        return None
    def filtrar_señales_válidas(self, señales, current_price):
        """
        Filtra señales basadas en criterios de calidad
        """
        señales_válidas = []
        for señal in señales:
            if not isinstance(señal, dict):
                continue
                
            try:
                # Criterios básicos
                if not all(k in señal for k in ['Level', 'Type', 'Categoria']):
                    continue
                    
                # Criterios de calidad
                if (señal.get('score', 0) >= 60 and  # Score mínimo
                    señal.get('win_rate', 0) >= 50 and  # Win rate mínimo
                    señal.get('ia_decision') == 'buena' and  # Decisión IA
                    señal.get('ConfirmacionFVG') in ['Sí', 'Parcial']):  # Confirmación FVG
                    
                    señales_válidas.append(señal)
                    
            except Exception as e:
                logging.warning(f"Error filtrando señal: {str(e)}")
                continue
                
        return señales_válidas

    def initialize_signal_metadata(self, señal, current_price):
        """Helper method to initialize signal metadata"""
        if not isinstance(señal, dict):
            return None
        
        try:
            nivel = float(señal.get("Level", current_price))
            distancia = abs(nivel - current_price)
            distancia_relativa = distancia / current_price
            
            basic_metadata = {
                "distancia_precio_actual": distancia,
                "distancia_relativa": round(distancia_relativa * 100, 4),
                "timestamp": self.current_timestamp,
                "last_updated_by": self.current_user
            }
            
            señal.update(basic_metadata)
            return señal
        except Exception as e:
            logging.error(f"Error inicializando metadata de señal: {str(e)}")
            return None
    
    

    async def analyze_and_report(self):
        try:
            # Inicializar listas de señales al principio
            señales_cercanas = []
            señales_descartadas = []
            self.todas_las_senales = []
            
                       
            # Get current UTC timestamp and user
            current_timestamp = "2025-06-18 03:57:57" # Current UTC time
            current_user = "gonzalo00123"
            logging.info(f"Columnas disponibles en data_1m: {self.data_1m.columns.tolist()}")
            logging.info(f"Iniciando análisis de señales (sin ejecución)... UTC: {current_timestamp}")

            # 1. Actualizar velas
            await self.update_candles()

            # 2. Validar datos iniciales
            if any(df is None or not isinstance(df, pd.DataFrame) or df.empty 
                for df in [self.data_30m, self.data_5m, self.data_1m]):
                logging.warning("Datos de velas no disponibles o vacíos.")
                return {
                    "estado": "sin_datos",
                    "mensaje": "Datos de velas no disponibles o vacíos",
                    "señales": [],
                    "estructura_mercado": {"sibi": "none", "bisi": "none", "bos": "none", "choch": "none"}
                }

            self.señales = self.todas_las_senales
            
            # Reset de todas las señales y estructuras
            
            self.todas_las_senales = []
            self.estructura_mercado = {}
            
            # Obtener precio actual primero
            async def get_current_price():
                """Obtiene el precio actual priorizando broker sobre chart"""
                broker_price = None
                try:
                    if hasattr(self, 'get_broker_price') and callable(getattr(self, 'get_broker_price')):
                        broker_price = await self.get_broker_price()
                    elif hasattr(self, 'current_tick') and hasattr(self.current_tick, 'price'):
                        broker_price = self.current_tick.price
                except Exception as e:
                    logging.debug(f"No se pudo obtener precio del broker: {e}")
                
                chart_price = self.data_1m['close'].iloc[-1] if not self.data_1m.empty else None
                current_price = broker_price if broker_price is not None else chart_price
                
                return {
                    "price": current_price,
                    "broker_price": broker_price,
                    "chart_price": chart_price,
                    "source": "broker" if broker_price is not None else "chart",
                    "timestamp": current_timestamp
                }

            price_data = await get_current_price()
            current_price = price_data["price"]
            
            if current_price is None:
                logging.error("No se pudo obtener el precio actual. Abortando análisis.")
                return {
                    "estado": "error",
                    "mensaje": "No se pudo obtener el precio actual",
                    "señales": [],
                    "estructura_mercado": {"sibi": "none", "bisi": "none", "bos": "none", "choch": "none"}
                }
            
            logging.info(f"Precio actual: {current_price} (fuente: {price_data['source']})")

            

            # Actualizar estructura del mercado
            self.actualizar_estructura_mercado(self.data_1m, self.data_5m, self.data_30m)

            # ======= ANÁLISIS DE TENDENCIAS =======
            trend_30m = self.m30_analyzer.get_trend(self.data_30m)
            trend_5m = self.m5_analyzer.get_trend(self.data_5m)
            m1_trend = self.m1_analyzer.get_trend(self.data_1m)

            # Realizar análisis adicionales
            tested_levels_1m = self.m1_analyzer.find_tested_levels(self.data_1m, current_price)
            señales_indep = self.analyze_independent_1m(self.data_1m, tested_levels_1m)
            self.todas_las_senales.extend(señales_indep)

            señales_flex = self.analyze_flexible_strategy(self.data_1m, self.data_5m, 
                                                        self.flexible_m5_analyzer, self.flexible_m1_analyzer)
            self.todas_las_senales.extend(señales_flex)

            validated_5m = self.m5_analyzer.validate_concepts(self.data_5m, tested_levels_1m, trend_5m)
            señales_val_5m = self.analyze_validacion_5m(self.data_1m, validated_5m, self.orderblocks)
            self.todas_las_senales.extend(señales_val_5m)

            señales_coincidencias = self.analyze_coincidencias_1m_5m(self.data_1m, tested_levels_1m, 
                                                                validated_5m, self.orderblocks)
            self.todas_las_senales.extend(señales_coincidencias)

            # --- AÑADIR LA DETECCIÓN DE LIQUIDEZ AQUÍ ---
            # 1. Ejecutar la detección de liquidez con manejo de errores
            try:
                # Inicializar el detector unificado
                unified_detector = UnifiedLiquidityDetector()
                
                # Ejecutar la detección completa
                liquidity_result = unified_detector.detect_all_liquidity(self.data_1m)
                
                # Extender las señales con los resultados
                self.todas_las_senales.extend(liquidity_result['signals'])
                
                # Actualizar la estructura de mercado con las zonas de liquidez
                self.estructura_mercado['liquidez'] = {
                    'zones': liquidity_result['zones'],
                    'sweeps': liquidity_result['sweeps'],
                    'stats': liquidity_result['stats']
                }
                
                logging.info(f"Detectadas {len(liquidity_result['signals'])} señales de liquidez")
                logging.info(f"Estadísticas de liquidez: {liquidity_result['stats']}")
                
            except Exception as e:
                logging.error(f"Error en detección de liquidez unificada: {str(e)}")
                traceback.print_exc()
            # Antes del filtro de proximidad
            cat_count = {}
            for s in self.todas_las_senales:
                cat = s.get("Categoria")
                cat_count[cat] = cat_count.get(cat, 0) + 1
            logging.info(f"Categorías ANTES del filtro de proximidad: {cat_count}")

            # Categorías detectadas
            categorias = {}
            for señal in self.todas_las_senales:
                if isinstance(señal, dict):
                    cat = señal.get('Categoria')
                    categorias[cat] = categorias.get(cat, 0) + 1

            logging.info("\nSeñales por categoría:")
            for cat, count in categorias.items():
                logging.info(f"- {cat}: {count}")

           

            # ======= FILTRO DE PROXIMIDAD GENERAL (REEMPLAZA FLIPS) =======
            # Filtrar señales por proximidad al precio actual para acción rápida
            max_distance_percent = 0.1  # 0.15% del precio actual (ajustable)
            min_confidence_required = "Baja"  # Aceptar señales de cualquier nivel de confianza

            
            logging.info(f"Aplicando filtro de proximidad: máximo {max_distance_percent}% del precio actual")
            
            for señal in self.todas_las_senales:
                if isinstance(señal, dict):
                    try:
                        nivel = float(señal.get('Level', 0))
                        distancia = abs(nivel - current_price)
                        distancia_porcentual = (distancia / current_price) * 100
                        
                        # Criterios más flexibles por categoría
                        max_allowed_distance = max_distance_percent
                     
                        if distancia_porcentual <= max_allowed_distance:
                            # Calcular score de proximidad inversamente proporcional a la distancia
                            proximidad_score = 100 * (1 - distancia_porcentual / max_allowed_distance)
                            
                            señal.update({
                                "es_señal_cercana": True,
                                "accion_rapida": True,
                                "proximidad_score": proximidad_score,
                                "distancia_porcentual": distancia_porcentual,
                                "timestamp": current_timestamp,
                                "last_updated": current_timestamp
                            })
                            señales_cercanas.append(señal)
                            
                            # Logging detallado de señal aceptada
                            
                        else:
                            señal.update({
                                "es_señal_cercana": False,
                                "accion_rapida": False,
                                "razon_descarte": f"Distancia {distancia_porcentual:.3f}% > {max_allowed_distance}%"
                            })
                            señales_descartadas.append(señal)
                            
                    except Exception as e:
                        logging.error(f"Error procesando señal: {e}")
                        señales_descartadas.append(señal)
            
            # Reemplazar todas las señales con solo las cercanas
            self.todas_las_senales = señales_cercanas
            
            # Log del filtrado
            logging.info(f"Filtro de proximidad aplicado:")
            logging.info(f"  - Señales cercanas (ejecutables): {len(señales_cercanas)}")
            logging.info(f"  - Señales descartadas (lejanas): {len(señales_descartadas)}")
            
            # Ordenar señales cercanas por proximidad (más cercanas primero)
            self.todas_las_senales.sort(key=lambda x: x.get("proximidad_score", 0), reverse=True)

            # Actualizar estructura con resumen
            self.actualizar_estructura_con_resumen()

            # Preparar resultado final
            resultado = {
                "estado": "exito",
                "mensaje": "Análisis completado",
                "señales": self.todas_las_senales,
                "estructura_mercado": self.estructura_mercado,
                "timestamp": current_timestamp
            }

            # Asegurar columna de volumen
            self._ensure_volume_column(self.data_30m, '30m')
            self._ensure_volume_column(self.data_5m, '5m')
            self._ensure_volume_column(self.data_1m, '1m')

            # Resetear contenedores de señales
            self.todas_las_senales = [s for s in self.todas_las_senales if isinstance(s, dict)]
            
            self.bos_choch = []
            self.consolidaciones = []
            self.sibi_bisi = []
            self.orderblocks = [ob for ob in self.orderblocks if isinstance(ob, dict)]

            # Validación de estructura de mercado
            estructura_actual = self.get_current_market_structure(self.data_1m)
            if estructura_actual:
                self.estructura_mercado.update({
                    "current_trend": estructura_actual["current_trend"],
                    "last_bos_choch": estructura_actual["last_bos_choch"],
                    "bos_choch_events": estructura_actual["bos_choch_events"]
                })

            # ======= INFORMACIÓN DE PRECIOS Y ESTRUCTURA BASE =======
            precio_info = {
                "broker_price": price_data["broker_price"],
                "chart_price": price_data["chart_price"],
                "final_price_used": current_price,
                "price_source": price_data["source"],
                "timestamp_precio": price_data["timestamp"]
            }

            resultado_base = {
                "timestamp": datetime.now().isoformat(),
                "precio_actual": current_price,
                "info_precios": precio_info,
                "tendencia_30m": trend_30m,
                "tendencia_5m": trend_5m,
                "total_señales_detectadas": len(self.todas_las_senales),
                "total_señales_descartadas": len(señales_descartadas),
                "filtro_proximidad": {
                    "max_distance_percent": max_distance_percent,
                    "señales_ejecutables": len(self.todas_las_senales),
                    "señales_lejanas_descartadas": len(señales_descartadas)
                },
                "estructura_mercado": self.estructura_mercado
            }

            # Validación de estructura (solo informativa)
            if not self.estructura_valida():
                logging.warning("⚠️ Estructura inválida: No hay BOS/CHOCH ni SIBI/BISI claros. Las operaciones se basarán en otras señales.")

            if not self.todas_las_senales:
                logging.info("No se detectaron señales válidas cercanas al precio actual.")
                resultado_base.update({
                    "estado": "sin_señales_cercanas",
                    "mensaje": f"No se detectaron señales ejecutables dentro del rango de {max_distance_percent}%",
                    "señales": []
                })
                
                resultado_limpio = self._clean_for_json(resultado_base)
                with open("diagnostico_actual.json", "w", encoding="utf-8") as f:
                    json.dump(resultado_limpio, f, indent=2, ensure_ascii=False)
                return resultado_limpio

            # ======= RESUMEN DE SEÑALES CERCANAS =======
            categorias = {}
            for señal in self.todas_las_senales:
                cat = señal.get("Categoria", "Desconocido") if isinstance(señal, dict) else "Desconocido"
                categorias[cat] = categorias.get(cat, 0) + 1
            
            logging.info("Resumen de señales cercanas encontradas (ejecutables):")
            for categoria, cantidad in categorias.items():
                logging.info(f"    {categoria}: {cantidad}")

            def score_signal(señal, current_price_for_scoring):
                """Función de scoring con sistema de influencia SMC dinámico
                
                Args:
                    señal (dict): Diccionario con la información de la señal
                    current_price_for_scoring (float): Precio actual para el cálculo de distancias
                
                Returns:
                    float: Score total calculado para la señal
                """
                tipo = señal.get("Type")
                nivel = señal.get("Level", current_price_for_scoring)
                distancia = abs(nivel - current_price_for_scoring)
                
                # ======= FACTOR DE PROXIMIDAD DOMINANTE CON AJUSTE DINÁMICO =======
                distancia_relativa = distancia / current_price_for_scoring
                
                # Ajuste dinámico de umbrales basado en volatilidad
                volatility_multiplier = getattr(self, 'volatility_multiplier', 1.0)
                proximity_thresholds = {
                    "ULTRA_CLOSE": 0.0009 * volatility_multiplier,
                    "VERY_CLOSE": 0.003 * volatility_multiplier,
                    "CLOSE": 0.003 * volatility_multiplier,
                    "MODERATE": 0.06 * volatility_multiplier
                }
                
                # Scoring de proximidad con ajuste por volatilidad
                if distancia_relativa <= proximity_thresholds["ULTRA_CLOSE"]:
                    proximidad_score = 100
                    proximidad_tier = "ULTRA_CLOSE"
                elif distancia_relativa <= proximity_thresholds["VERY_CLOSE"]:
                    proximidad_score = 80
                    proximidad_tier = "VERY_CLOSE"
                elif distancia_relativa <= proximity_thresholds["CLOSE"]:
                    proximidad_score = 60
                    proximidad_tier = "CLOSE"
                elif distancia_relativa <= proximity_thresholds["MODERATE"]:
                    proximidad_score = 40
                    proximidad_tier = "MODERATE"
                else:
                    proximidad_score = max(5, 30 - (distancia_relativa * 10000))
                    proximidad_tier = "FAR"
                
                # ======= SCORING DE CALIDAD ORIGINAL (SIN CAMBIOS BASE) =======
                categoria = señal.get("Categoria", "")
                base_scores = {
                    "OrderBlock": 35,  # Aumentado
                    "Coincidencia": 25,  # Aumentado
                    "Flip": 15,        # Aumentado
                    "Independiente": 20,
                    "Flexible": 25,    # Aumentado
                    "Validacion5M": 25,
                    "FVG": 35,         # Aumentado
                    "Estructura": 35,   # Aumentado
                    "Liquidez": 30      # Nueva categoría
                }
                
                # Multiplicadores de confianza originales
                confidence_levels = {
                    "Alta": {"multiplier": 1.2, "bonus": 8},    # Mejorado
                    "Media": {"multiplier": 0.8, "bonus": 5},   # Mejorado
                    "Baja": {"multiplier": 0.4, "bonus": 2}     # Mejorado
                }
                confidence = señal.get("Confidence", "Media")
                confidence_data = confidence_levels[confidence]
                
                # Cálculos base originales
                base_score = base_scores.get(categoria, 0)
                confidence_score = confidence_data["multiplier"] * 5 + confidence_data["bonus"]
                
                # ======= SISTEMA DE BONIFICACIONES ORIGINAL =======
                ob_bonus = 8 if señal.get("OrderBlockRelacionado", False) else 0
                # ======= INTEGRACIÓN DE LIQUIDEZ =======
                liquidez_bonus = 0
                if señal.get("zona_liquidez_tipo"):
                    liquidez_weights = {
                        "Equal_Highs": 1.2,
                        "Equal_Lows": 1.2,
                        "Sweep_High": 1.1,
                        "Sweep_Low": 1.1
                    }
                    liquidez_tipo = señal["zona_liquidez_tipo"]
                    liquidez_bonus = 15 * liquidez_weights.get(liquidez_tipo, 1.0)
                    
                    # Bonus adicional si hay confluencia con otros elementos SMC
                    if señal.get("OrderBlockRelacionado") or señal.get("FVGRelacionado"):
                        liquidez_bonus *= 1.3
                
                # Esquemas con bonificaciones originales
                esquema_bonuses = {
                    "BOS": {"score": 15, "win_rate_bonus": 5},
                    "CHoCH": {"score": 15, "win_rate_bonus": 5},
                    "FVG": {"score": 10, "win_rate_bonus": 3},
                    "BISI": {"score": 12, "win_rate_bonus": 4},
                    "SIBI": {"score": 12, "win_rate_bonus": 4},
                    "Level_Flip": {"score": 10, "win_rate_bonus": 5}
                }
                
                esquema = señal.get("Esquema", señal.get("esquema", ""))
                esquema_data = esquema_bonuses.get(esquema, {"score": 0, "win_rate_bonus": 0})
                esquema_bonus = esquema_data["score"]
                
                # ======= SISTEMA DE INFLUENCIA SMC DINÁMICO (NUEVO) =======
                smc_influence = {
                    "total_bonus": 0,
                    "win_rate_bonus": 0,
                    "influences": [],
                    "confluence_count": 0,
                    "strength_multiplier": 1.0
                }
                
                # Análisis de influencias SMC cercanas
                def analyze_smc_influence():
                    influences = []
                    
                    # 1. INFLUENCIA DE ORDER BLOCKS
                    ob_zones = getattr(self, 'order_block_zones', [])
                    for ob in ob_zones:
                        ob_distance = abs(nivel - ob.get("level", 0))
                        ob_influence_radius = ob.get("influence_radius", current_price_for_scoring * 0.002)
                        
                        if ob_distance <= ob_influence_radius:
                            influence_strength = (1 - ob_distance / ob_influence_radius) * ob.get("strength", 1.0)
                            direction_match = (tipo.lower() == ob.get("type", "").lower())
                            
                            influences.append({
                                "type": "OrderBlock",
                                "strength": influence_strength,
                                "direction_match": direction_match,
                                "bonus": influence_strength * (20 if direction_match else 12),
                                "win_rate_bonus": influence_strength * (8 if direction_match else 4)
                            })
                    
                    # 2. INFLUENCIA DE FVG (Fair Value Gaps)
                    fvg_zones = getattr(self, 'fvg_zones', [])
                    for fvg in fvg_zones:
                        fvg_distance = abs(nivel - fvg.get("center", 0))
                        fvg_influence_radius = fvg.get("size", current_price_for_scoring * 0.001)
                        
                        if fvg_distance <= fvg_influence_radius:
                            influence_strength = (1 - fvg_distance / fvg_influence_radius) * fvg.get("strength", 0.8)
                            
                            influences.append({
                                "type": "FVG",
                                "strength": influence_strength,
                                "direction_match": True,  # FVG generalmente neutral
                                "bonus": influence_strength * 15,
                                "win_rate_bonus": influence_strength * 6
                            })
                    
                    # 3. INFLUENCIA DE ESTRUCTURA (BOS/CHoCH)
                    structure_levels = getattr(self, 'structure_levels', [])
                    for struct in structure_levels:
                        struct_distance = abs(nivel - struct.get("level", 0))
                        struct_influence_radius = struct.get("influence_radius", current_price_for_scoring * 0.0015)
                        
                        if struct_distance <= struct_influence_radius:
                            influence_strength = (1 - struct_distance / struct_influence_radius) * struct.get("strength", 1.2)
                            structure_type = struct.get("structure_type", "")
                            direction_match = (
                                (tipo == "Buy" and structure_type in ["BOS_Bullish", "CHoCH_Bullish"]) or
                                (tipo == "Sell" and structure_type in ["BOS_Bearish", "CHoCH_Bearish"])
                            )
                            
                            influences.append({
                                "type": f"Structure_{structure_type}",
                                "strength": influence_strength,
                                "direction_match": direction_match,
                                "bonus": influence_strength * (25 if direction_match else 15),
                                "win_rate_bonus": influence_strength * (10 if direction_match else 6)
                            })
                    
                    # 4. INFLUENCIA DE LIQUIDITY SWEEPS (actualizado)
                    liquidity_data = self.estructura_mercado.get('liquidez', {})
                    liquidity_zones = liquidity_data.get('zones', [])
                    liquidity_sweeps = liquidity_data.get('sweeps', [])
                    
                    for zone in liquidity_zones:
                        zone_distance = abs(nivel - zone['Level'])
                        zone_influence_radius = current_price_for_scoring * 0.002  # Radio de influencia aumentado
                        
                        if zone_distance <= zone_influence_radius:
                            # Calcular fuerza de influencia basada en la confianza y fuerza de la zona
                            base_strength = float(zone.get('strength', 50)) / 100
                            confidence_mult = {
                                'Alta': 1.2,
                                'Media': 1.0,
                                'Baja': 0.8
                            }.get(zone.get('Confidence', 'Media'), 1.0)
                            
                            influence_strength = (1 - zone_distance / zone_influence_radius) * base_strength * confidence_mult
                            
                            # Determinar dirección basada en el tipo de zona
                            zone_type = zone.get('zona_liquidez_tipo', '')
                            direction_match = (
                                (tipo == "Buy" and zone_type in ['Equal_Lows', 'swing_low']) or
                                (tipo == "Sell" and zone_type in ['Equal_Highs', 'swing_high', 'psychological'])
                            )
                            
                            # Bonus adicional si hay un sweep reciente
                            sweep_bonus = 0
                            for sweep in liquidity_sweeps:
                                if abs(sweep['Level'] - zone['Level']) < zone_influence_radius:
                                    sweep_bonus = 0.2 * float(sweep.get('confidence_numeric', 0.5))
                                    break
                            
                            influences.append({
                                "type": f"Liquidity_{zone_type}",
                                "strength": influence_strength + sweep_bonus,
                                "direction_match": direction_match,
                                "bonus": influence_strength * (25 if direction_match else 15) + (sweep_bonus * 10),
                                "win_rate_bonus": influence_strength * (10 if direction_match else 5) + (sweep_bonus * 5)
                            })
                    
                    # 5. INFLUENCIA DE PREMIUM/DISCOUNT ZONES
                    pd_zones = getattr(self, 'premium_discount_zones', [])
                    for pd in pd_zones:
                        if pd.get("zone_type") == "discount" and tipo == "Buy":
                            pd_distance = abs(nivel - pd.get("center", 0))
                            if pd_distance <= pd.get("size", current_price_for_scoring * 0.003):
                                influence_strength = pd.get("strength", 0.7)
                                influences.append({
                                    "type": "Discount_Zone",
                                    "strength": influence_strength,
                                    "direction_match": True,
                                    "bonus": influence_strength * 12,
                                    "win_rate_bonus": influence_strength * 5
                                })
                        elif pd.get("zone_type") == "premium" and tipo == "Sell":
                            pd_distance = abs(nivel - pd.get("center", 0))
                            if pd_distance <= pd.get("size", current_price_for_scoring * 0.003):
                                influence_strength = pd.get("strength", 0.7)
                                influences.append({
                                    "type": "Premium_Zone",
                                    "strength": influence_strength,
                                    "direction_match": True,
                                    "bonus": influence_strength * 12,
                                    "win_rate_bonus": influence_strength * 5
                                })
                    
                    return influences
                
                # Ejecutar análisis de influencia SMC
                smc_influence["influences"] = analyze_smc_influence()
                smc_influence["confluence_count"] = len(smc_influence["influences"])
                
                # Calcular bonos totales de influencia SMC
                for influence in smc_influence["influences"]:
                    smc_influence["total_bonus"] += influence["bonus"]
                    smc_influence["win_rate_bonus"] += influence["win_rate_bonus"]
                
                # Multiplicador por confluencia (más influencias = mayor multiplicador)
                if smc_influence["confluence_count"] >= 3:
                    smc_influence["strength_multiplier"] = 1.5
                elif smc_influence["confluence_count"] >= 2:
                    smc_influence["strength_multiplier"] = 1.3
                elif smc_influence["confluence_count"] >= 1:
                    smc_influence["strength_multiplier"] = 1.1
                
                # Aplicar multiplicador de confluencia
                smc_influence["total_bonus"] *= smc_influence["strength_multiplier"]
                smc_influence["win_rate_bonus"] *= smc_influence["strength_multiplier"]
                
                # Bonus adicional por alta confluencia SMC
                confluence_bonus = 0
                if smc_influence["confluence_count"] >= 3:
                    confluence_bonus = 20  # Bonus por confluencia excepcional
                elif smc_influence["confluence_count"] >= 2:
                    confluence_bonus = 12  # Bonus por buena confluencia
                
                # ======= LÓGICA DE FLIPS ORIGINAL CON INFLUENCIA SMC =======
                flip_data = {
                    "influence_bonus": 0,
                    "recency_bonus": 0,
                    "proximity_bonus": 0,
                    "trend_bonus": 0,
                    "smc_boost": 0  # Nuevo: boost por influencia SMC
                }
                
                if categoria == "Flip":
                    # Bonus por influencia SMC en flips
                    if smc_influence["confluence_count"] > 0:
                        flip_data["smc_boost"] = min(25, smc_influence["total_bonus"] * 0.8)
                    
                    if señal.get("is_recent_flip", False):
                        flip_data["recency_bonus"] = 10
                        
                        # Bonus adicional por proximidad para flips recientes
                        if proximidad_tier in ["ULTRA_CLOSE", "VERY_CLOSE"]:
                            flip_data["proximity_bonus"] = 15
                        elif proximidad_tier == "CLOSE":
                            flip_data["proximity_bonus"] = 10
                    
                    # Análisis de tendencia para flips
                    trend_5m = getattr(self, 'trend_5m', 'Neutral')
                    if ((tipo == "Buy" and trend_5m == "Alcista") or 
                        (tipo == "Sell" and trend_5m == "Bajista")):
                        flip_data["trend_bonus"] = 10
                
                # Influencia de zonas de flip con boost SMC
                elif getattr(self, 'flip_influence_zones', None):
                    for zone in self.flip_influence_zones:
                        zone_distance = abs(nivel - zone["center"])
                        if zone_distance <= zone["radius"]:
                            influence_strength = zone["strength"] * (1 - zone_distance / zone["radius"])
                            direction_match = (tipo == zone["type"])
                            
                            base_influence = influence_strength * 12
                            if direction_match:
                                base_influence += influence_strength * 8
                            
                            # Boost por influencia SMC
                            if smc_influence["confluence_count"] > 0:
                                base_influence *= (1 + smc_influence["confluence_count"] * 0.2)
                            
                            flip_data["influence_bonus"] = base_influence
                            break
                
                # ======= ANÁLISIS DE ESTRUCTURA DE MERCADO ORIGINAL =======
                estructura_data = {
                    "bonus": 0,
                    "trend_alignment": False,
                    "bos_alignment": False
                }
                
                if getattr(self, 'estructura_mercado', None):
                    market_structure = self.estructura_mercado
                    current_trend = market_structure.get("current_trend")
                    bos_state = market_structure.get("bos")
                    
                    if tipo == "Buy":
                        if current_trend == "Bullish":
                            estructura_data["bonus"] += 15
                            estructura_data["trend_alignment"] = True
                        if bos_state == "bullish":
                            estructura_data["bonus"] += 10
                            estructura_data["bos_alignment"] = True
                    elif tipo == "Sell":
                        if current_trend == "Bearish":
                            estructura_data["bonus"] += 15
                            estructura_data["trend_alignment"] = True
                        if bos_state == "bearish":
                            estructura_data["bonus"] += 10
                            estructura_data["bos_alignment"] = True
                
                # ======= CÁLCULO DE TENDENCIA Y PENALIZACIONES ORIGINALES =======
                trend_analysis = {
                    "contra_tendencia": False,
                    "penalty": 0
                }
                
                trend_30m = getattr(self, 'trend_30m', 'Neutral')
                trend_5m = getattr(self, 'trend_5m', 'Neutral')
                
                trend_analysis["contra_tendencia"] = (
                    (tipo == "Buy" and trend_30m == "Bajista") or
                    (tipo == "Sell" and trend_30m == "Alcista") or
                    (tipo == "Buy" and trend_5m == "Bajista") or
                    (tipo == "Sell" and trend_5m == "Alcista")
                )
                
                # Penalización adaptativa con reducción por influencia SMC
                if trend_analysis["contra_tendencia"]:
                    base_penalty = -10
                    
                    # Reducir penalización según influencia SMC
                    smc_reduction = min(8, smc_influence["confluence_count"] * 3)
                    
                    if proximidad_tier in ["ULTRA_CLOSE", "VERY_CLOSE"]:
                        trend_analysis["penalty"] = max(-3, base_penalty + smc_reduction + 5)
                    elif categoria == "Flip" and señal.get("is_recent_flip", False):
                        trend_analysis["penalty"] = max(-3, base_penalty + smc_reduction + 5)
                    else:
                        trend_analysis["penalty"] = max(-5, base_penalty + smc_reduction)

                # ======= CÁLCULO FINAL DEL SCORE CON INFLUENCIA SMC =======
                # Sumatorio de bonificaciones de flips
                total_flip_bonus = sum(flip_data.values())
                
                # Cálculo de score de calidad CON influencia SMC
                calidad_score = (
                    base_score +
                    confidence_score +
                    ob_bonus +
                    esquema_bonus +
                    total_flip_bonus +
                    smc_influence["total_bonus"] +  # BONUS DINÁMICO SMC
                    confluence_bonus                 # BONUS POR CONFLUENCIA
                )
                
                # Score final con pesos originales
                total_score = (
                    (proximidad_score * 0.6) +
                    (calidad_score * 0.3) +
                    (estructura_data["bonus"] * 0.1)
                ) + trend_analysis["penalty"]
                
                # ======= CÁLCULO DE WIN RATE CON INFLUENCIA SMC =======
                base_win_rate = 50 if categoria != "Flip" else 55
                
                # Bonificaciones de win rate con SMC
                win_rate_additions = [
                    proximity_win_bonus := {
                        "ULTRA_CLOSE": 25,
                        "VERY_CLOSE": 20,
                        "CLOSE": 15,
                        "MODERATE": 10,
                        "FAR": 0
                    }.get(proximidad_tier, 0),
                    8 if señal.get("is_recent_flip", False) else 0,
                    confidence_data["bonus"],
                    4 if señal.get("OrderBlockRelacionado", False) else 0,
                    esquema_data["win_rate_bonus"],
                    int(flip_data["influence_bonus"] / 3),
                    min(10, estructura_data["bonus"] / 3),
                    int(smc_influence["win_rate_bonus"]),  # WIN RATE BOOST SMC
                    min(15, smc_influence["confluence_count"] * 5),  # BONUS POR CONFLUENCIA
                    -8 if trend_analysis["contra_tendencia"] else 3
                ]
                
                win_probability = min(95, max(10, base_win_rate + sum(win_rate_additions)))
                
                # ======= METADATA ACTUALIZADA CON DATOS SMC =======
                metadata = {
                    "score": round(total_score, 2),
                    "win_rate": win_probability,
                    "distancia_precio_actual": distancia,
                    "distancia_relativa": round(distancia_relativa * 100, 4),
                    "proximidad_score": proximidad_score,
                    "proximidad_tier": proximidad_tier,
                    "calidad_score": round(calidad_score, 2),
                    "flip_data": {k: round(v, 2) for k, v in flip_data.items()},
                    "smc_influence": {
                        "total_bonus": round(smc_influence["total_bonus"], 2),
                        "win_rate_bonus": round(smc_influence["win_rate_bonus"], 2),
                        "confluence_count": smc_influence["confluence_count"],
                        "strength_multiplier": smc_influence["strength_multiplier"],
                        "influences": [
                            {
                                "type": inf["type"],
                                "strength": round(inf["strength"], 3),
                                "direction_match": inf["direction_match"],
                                "bonus": round(inf["bonus"], 2)
                            } for inf in smc_influence["influences"]
                        ]
                    },
                    "confluence_bonus": confluence_bonus,
                    "estructura_data": estructura_data,
                    "trend_analysis": trend_analysis,
                    "timestamp": current_timestamp,
                    "last_updated_by": current_user
                }
                
                señal.update(metadata)
                return total_score
            # Aplicar scoring a todas las señales
            # Aplicar scoring a todas las señales
            for señal in self.todas_las_senales:
                if not isinstance(señal, dict):
                    continue  # Ignora cualquier cosa que no sea un diccionario
                
                # Aplicar scoring con influencia SMC (aquí iría tu función score_signal)
                score = score_signal(señal, current_price)

            # ======= SELECCIÓN NORMALIZADA BASADA ÚNICAMENTE EN SCORE =======
            UMBRAL_CERCANIA = current_price * 0.1

            # Filtrar señales válidas y aplicar scoring
            señales_validas = [
                s for s in self.todas_las_senales 
                if isinstance(s, dict) and s.get("score", 0) > 0
            ]

            # Separar señales cercanas y lejanas para análisis
            señales_cercanas = [
                s for s in señales_validas 
                if s.get("distancia_precio_actual", float('inf')) <= UMBRAL_CERCANIA
            ]

            señales_lejanas = [
                s for s in señales_validas 
                if s.get("distancia_precio_actual", float('inf')) > UMBRAL_CERCANIA
            ]

            # ======= ESTRATEGIA DE SELECCIÓN INTELIGENTE =======
            def select_best_signals(cercanas, lejanas, max_signals=5):
                """
                Selecciona las mejores señales basándose únicamente en score y proximidad
                """
                señales_seleccionadas = []
                
                # Ordenar por score descendente
                cercanas_ordenadas = sorted(cercanas, key=lambda s: s.get("score", 0), reverse=True)
                lejanas_ordenadas = sorted(lejanas, key=lambda s: s.get("score", 0), reverse=True)
                
                # ESTRATEGIA 1: Si hay señales cercanas con buen score, priorizarlas
                if cercanas_ordenadas:
                    # Analizar la calidad de señales cercanas
                    scores_cercanas = [s.get("score", 0) for s in cercanas_ordenadas[:3]]
                    score_promedio_cercanas = sum(scores_cercanas) / len(scores_cercanas) if scores_cercanas else 0
                    
                    # Si las señales cercanas son de buena calidad (score > 60), priorizarlas
                    if score_promedio_cercanas >= 60:
                        # Tomar mayoría de cercanas, complementar con lejanas si es necesario
                        señales_seleccionadas.extend(cercanas_ordenadas[:4])  # Máximo 4 cercanas
                        
                        # Complementar con mejores lejanas si no llegamos a 5
                        remaining_slots = max_signals - len(señales_seleccionadas)
                        if remaining_slots > 0 and lejanas_ordenadas:
                            señales_seleccionadas.extend(lejanas_ordenadas[:remaining_slots])
                            
                    else:
                        # Si las cercanas no son tan buenas, mezclar equilibradamente
                        max_cercanas = min(2, len(cercanas_ordenadas))  # Máximo 2 cercanas
                        max_lejanas = max_signals - max_cercanas
                        
                        señales_seleccionadas.extend(cercanas_ordenadas[:max_cercanas])
                        señales_seleccionadas.extend(lejanas_ordenadas[:max_lejanas])
                
                # ESTRATEGIA 2: Si no hay señales cercanas, tomar las mejores por score
                else:
                    señales_seleccionadas = lejanas_ordenadas[:max_signals]
                
                return señales_seleccionadas[:max_signals]

            # Ejecutar selección
            señales_ordenadas = select_best_signals(señales_cercanas, señales_lejanas, 5)

            # ======= ANÁLISIS Y LOGGING DE SELECCIÓN =======
            def log_selection_analysis(señales_seleccionadas):
                """
                Analiza y loguea la composición de señales seleccionadas
                """
                if not señales_seleccionadas:
                    logging.warning("No se encontraron señales válidas para seleccionar")
                    return
                
                # Análisis de composición
                composicion = {}
                smc_influences = []
                scores = []
                
                for señal in señales_seleccionadas:
                    categoria = señal.get("Categoria")
                    composicion[categoria] = composicion.get(categoria, 0) + 1
                    
                    # Analizar influencia SMC
                    smc_data = señal.get("smc_influence", {})
                    confluence_count = smc_data.get("confluence_count", 0)
                    smc_influences.append(confluence_count)
                    
                    scores.append(señal.get("score", 0))
                
                # Logging detallado
                score_promedio = sum(scores) / len(scores)
                smc_promedio = sum(smc_influences) / len(smc_influences)
                
                logging.info(f"=== ANÁLISIS DE SELECCIÓN DE SEÑALES ===")
                logging.info(f"Señales seleccionadas: {len(señales_seleccionadas)}")
                
                
                # Detalles de las mejores señales
                for i, señal in enumerate(señales_seleccionadas[:3], 1):
                    smc_data = señal.get("smc_influence", {})
                    influences = smc_data.get("influences", [])
                    influence_types = [inf.get("type", "") for inf in influences]
                    
                  

            # Ejecutar análisis
            log_selection_analysis(señales_ordenadas)

            # ======= SELECCIÓN FINAL CON VALIDACIÓN =======
            # Validación adicional: asegurar diversidad si es posible
            def ensure_signal_diversity(señales, max_same_category=3):
                """
                Asegura que no haya demasiadas señales de la misma categoría
                """
                if len(señales) <= 3:
                    return señales  # Si son pocas señales, no aplicar restricción
                
                categoria_count = {}
                señales_diversas = []
                señales_exceso = []
                
                for señal in señales:
                    categoria = señal.get("Categoria")
                    count = categoria_count.get(categoria, 0)
                    
                    if count < max_same_category:
                        señales_diversas.append(señal)
                        categoria_count[categoria] = count + 1
                    else:
                        señales_exceso.append(señal)
                
                # Si quedaron slots libres, llenar con las de exceso por score
                remaining_slots = 5 - len(señales_diversas)
                if remaining_slots > 0 and señales_exceso:
                    señales_exceso_ordenadas = sorted(señales_exceso, key=lambda s: s.get("score", 0), reverse=True)
                    señales_diversas.extend(señales_exceso_ordenadas[:remaining_slots])
                
                return señales_diversas

            # Aplicar diversificación
            señales_ordenadas = ensure_signal_diversity(señales_ordenadas)

            # ======= VALIDACIÓN FINAL Y BACKUP =======
            # Si por alguna razón no hay señales, usar backup
            if not señales_ordenadas:
                logging.warning("No se encontraron señales con el método principal, usando backup")
                backup_signals = sorted(
                    [s for s in self.todas_las_senales if isinstance(s, dict)],
                    key=lambda s: s.get("score", 0),
                    reverse=True
                )
                señales_ordenadas = backup_signals[:5]

            # Seleccionar hasta 5 mejores para evaluación IA
            señales_a_evaluar = señales_ordenadas[:5]

            logging.info(f"=== SELECCIÓN FINAL ===")
            logging.info(f"Total señales para evaluación: {len(señales_a_evaluar)}")

            # Log final de cada señal seleccionada
            for i, señal in enumerate(señales_a_evaluar, 1):
                logging.info(f"Señal final #{i}: {señal.get('Categoria', 'N/A')} | "
                            f"Score: {señal.get('score', 0):.2f} | "
                            f"SMC: {señal.get('smc_influence', {}).get('confluence_count', 0)} | "
                            f"Distancia: {señal.get('distancia_precio_actual', 0):.4f}")
            
            logging.info(f"Señales seleccionadas para evaluación IA: {len(señales_a_evaluar)}")
            flip_count = len([s for s in señales_a_evaluar if s.get("Categoria") == "Flip"])
            if flip_count > 0:
                logging.info(f"  - {flip_count} son flips (priorizados por ser recientes/cercanos)")

            # Evaluar con IA y actualizar metadatos
            # Before the confirmation loop, get FVG signals
            fvg_signals = self.estructura_mercado.get("fvg", []) + \
                        self.estructura_mercado.get("bisi", []) + \
                        self.estructura_mercado.get("sibi", [])
            # Confirmar con FVG
            señales_finales = [] 
            señales_procesadas = []
            for señal in señales_finales:
                if señal.get('estado') == 'confirmada':
                    señal_detallada = {
                        "symbol": self.symbol,
                        "Nombre": señal.get('Nombre'),
                        "Level": float(señal.get('Level')),
                        "Type": señal.get('Type'),
                        "Categoria": señal.get('Categoria'),
                        "Strategy": señal.get('Strategy'),
                        "Confidence": señal.get('Confidence'),
                        "score": float(señal.get('score', 0)),
                        "win_rate": float(señal.get('win_rate', 0)),
                        "distancia_precio_actual": float(señal.get('distancia_precio_actual', 0)),
                        "distancia_porcentual": float(señal.get('distancia_porcentual', 0)),
                        "is_recent_flip": bool(señal.get('is_recent_flip', False)),
                        "ConfirmacionFVG": señal.get('ConfirmacionFVG'),
                        "ia_decision": señal.get('ia_decision'),
                        "timestamp": current_timestamp,
                        "estado": "confirmada",
                        "metadata": {
                            "created_at": current_timestamp,
                            "updated_at": current_timestamp,
                            "created_by": current_user,
                            "precio_activacion": float(current_price)
                        }
                    }
                    señales_procesadas.append(señal_detallada)
            # Analiza las señales cercanas que ya tienes:
            buy_signals = [s for s in self.todas_las_senales if s.get("Type") == "Buy"]
            sell_signals = [s for s in self.todas_las_senales if s.get("Type") == "Sell"]

            # Suma scores y win_rates
            avg_buy = sum(s.get("score", 0) for s in buy_signals) / len(buy_signals) if buy_signals else 0
            avg_sell = sum(s.get("score", 0) for s in sell_signals) / len(sell_signals) if sell_signals else 0

            # Considera la tendencia
            trend = self.estructura_mercado.get("current_trend", "Lateral")

            if avg_buy > avg_sell and trend == "Bullish":
                probable = "BUY (alcista)"
            elif avg_sell > avg_buy and trend == "Bearish":
                probable = "SELL (bajista)"
            elif avg_buy > avg_sell:
                probable = "BUY (pero tendencia no confirma)"
            elif avg_sell > avg_buy:
                probable = "SELL (pero tendencia no confirma)"
            else:
                probable = "INDEFINIDO / RANGO"
            # Llama a la función usando los datos de 1 minuto (o los que quieras)
            prediccion_tec = predecir_direccion_precio(data_1m=self.data_1m)
            

            # Primero define resultado_final con los datos base
            resultado_final = {
                "estado": "exito",
                "mensaje": "Análisis completado",
                "timestamp": current_timestamp,
                "data": {
                    "symbol": self.symbol,
                    "precio_actual": float(current_price),
                    "fuente_precio": price_data.get('source', 'chart'),
                    "señales": {
                        "total": len(señales_procesadas),
                        "lista": señales_procesadas
                    },
                    "tendencias": {
                        "30m": trend_30m,
                        "5m": trend_5m,
                        "1m": m1_trend
                    },
                    "estructura_mercado": self.estructura_mercado
                },
                "metadata": {
                    "total_señales_evaluadas": len(señales_a_evaluar),
                    "señales_confirmadas": len(señales_procesadas),
                    "flips_recientes": len([s for s in señales_procesadas if s.get("is_recent_flip", True)]),
                    "última_actualización": current_timestamp,
                    "usuario": current_user,
                    "version": "2.0"
                }
            }

            # Ahora puedes hacer el update!
            resultado_final.update({
                "prediccion_tecnica": {
                    "direccion": prediccion_tec,
                    "explicacion": "Basada en indicadores técnicos clásicos (RSI, SMA, ADX, Bollinger Bands)."
                },
                "prediccion_simple": {
                    "direccion": probable,
                    "score_buy": avg_buy,
                    "score_sell": avg_sell,
                    "trend": trend,
                    "razon": "Se calcula a partir de las señales cercanas y la tendencia SMC."
                }
            })

            # Actualizar estado interno del bot
            self.señales_activas = señales_procesadas
            self.último_resultado = resultado_final
            self.última_actualización = current_timestamp

            # Logging detallado
            if señales_procesadas:
                logging.info(f"Análisis completado. Encontradas {len(señales_procesadas)} señales válidas.")
                for señal in señales_procesadas:
                    logging.info(
                        f"- {señal['Nombre']} "
                        f"(Nivel: {señal['Level']}, "
                        f"Score: {señal['score']:.2f}, "
                        f"Win Rate: {señal['win_rate']:.1f}%)"
                    )
            else:
                logging.info("No se encontraron señales válidas en este análisis")
        
            

            # Mantener el resultado final como estaba
            resultado_final = {
                "estado": "exito",
                "mensaje": "Análisis completado",
                "timestamp": "2025-06-10 09:33:20",
                "señales": señales_finales,
                "total": len(señales_finales)
            }
             # Evaluar con IA y actualizar metadatos
             # Lista para almacenar señales procesadas
            for señal in señales_a_evaluar:
                try:
                    self.evaluar_con_modelos_ia(señal)
                    señal.update({
                        "timestamp": "2025-06-10 08:52:42",
                        "ia_evaluation_timestamp": "2025-06-10 08:52:42",
                        "last_updated_by": "gonzalo00123"
                    })
                    score_signal(señal, current_price)
                    
                    # Confirmar con FVG
                    confirmacion = self.confirmar_con_fvg_y_testeo(señal, current_price, fvg_signals)
                    conteo_estrategias = []
                    # Solo agregar señales que pasen los criterios
                    if confirmacion and señal.get('ia_decision') == 'buena':
                        señal['estado'] = 'confirmada'
                        señales_finales.append(señal)
                        logging.info(f"Señal confirmada: {señal.get('Nombre', 'Sin nombre')} - "
                                f"Nivel: {señal.get('Level')} - "
                                f"Score: {señal.get('score', 0):.2f}")
                    else:
                        señal['estado'] = 'rechazada'
                        logging.debug(f"Señal rechazada: {señal.get('Nombre', 'Sin nombre')}")
                    
                except Exception as e:
                    logging.error(f"Error procesando señal: {str(e)}")
                    continue
                       
            # Preparar resultado detallado
            resultado_detallado = {
                "estado": "exito",
                "mensaje": "Análisis completado",
                "timestamp": "2025-06-10 09:52:26",
                "metadata": {
                    "total_señales_evaluadas": len(señales_a_evaluar),
                    "señales_confirmadas": len(señales_finales),
                    "última_actualización": "2025-06-10 09:52:26",
                    "usuario": "gonzalo00123"
                },
                "análisis": {
                    "precio_actual": current_price,
                    "fuente_precio": price_data['source'],
                    "tendencias": {
                        "30m": trend_30m,
                        "5m": trend_5m,
                        "1m": m1_trend
                    }
                },
                "estructura_mercado": {
                    "current_trend": self.estructura_mercado.get("current_trend", "Lateral"),
                    "bos": self.estructura_mercado.get("bos", "none"),
                    "choch": self.estructura_mercado.get("choch", "none"),
                    "sibi": self.estructura_mercado.get("sibi", "none"),
                    "bisi": self.estructura_mercado.get("bisi", "none"),
                    "last_bos_choch": self.estructura_mercado.get("last_bos_choch", {}),
                    "bos_choch_events": self.estructura_mercado.get("bos_choch_events", [])
                },
                "señales": {
                    "confirmadas": señales_finales,
                    "total_analizadas": len(self.todas_las_senales),
                    "flips_recientes": len([s for s in self.todas_las_senales if s.get("Categoria") == "Flip" and s.get("is_recent_flip", False)]),
                    "detalle_categorias": {
                        "Flip": len([s for s in señales_finales if s.get("Categoria") == "Flip"]),
                        "OrderBlock": len([s for s in señales_finales if s.get("Categoria") == "OrderBlock"]),
                        "Coincidencia": len([s for s in señales_finales if s.get("Categoria") == "Coincidencia"]),
                        "Validacion5M": len([s for s in señales_finales if s.get("Categoria") == "Validacion5M"])
                    }
                },
                "configuración": {
                    "UMBRAL_CERCANIA": current_price * 0.05,
                    "volatility_multiplier": getattr(self, 'volatility_multiplier', 1.0),
                    "max_señales": 5
                }
            }

            # Actualizar las señales en el bot
            self.señales_activas = señales_finales
            self.última_actualización = "2025-06-10 09:52:26"

            # Logging detallado del resultado
            if señales_finales:
                logging.info(f"Se encontraron {len(señales_finales)} señales válidas:")
                for señal in señales_finales:
                    logging.info(f"- {señal.get('Nombre', 'Sin nombre')} "
                            f"(Nivel: {señal.get('Level')}, "
                            f"Score: {señal.get('score', 0):.2f}, "
                            f"Win Rate: {señal.get('win_rate', 0):.1f}%)")
            else:
                logging.info("No se encontraron señales válidas en este análisis")

            # ======= GUARDADO FINAL DE DIAGNÓSTICO =======
            resultado_base = resultado_detallado.copy()
            resultado_base.update({
                "estado": "ok",
                "mensaje": "Análisis completado",
                "señales": señales_a_evaluar
            })

            # Limpiar resultado para JSON y guardar
            try:
                resultado_limpio = self._clean_for_json(resultado_base)
                with open("diagnostico_actual.json", "w", encoding="utf-8") as f:
                    json.dump(resultado_limpio, f, indent=2, ensure_ascii=False)
                logging.info("Diagnóstico guardado en diagnostico_actual.json")
            except Exception as e:
                logging.error(f"Error guardando diagnóstico: {e}")

            # Guardar resultado en el bot
            self.último_resultado = resultado_detallado

            return resultado_limpio

        except Exception as e:
            logging.error(f"Error en analyze_and_report: {e}")
            traceback.print_exc()
            return {
                "estado": "error",
                "mensaje": str(e),
                "timestamp": current_timestamp,
                "data": {
                    "symbol": self.symbol,
                    "señales": {"total": 0, "lista": []},
                    "estructura_mercado": {
                        "sibi": "none",
                        "bisi": "none",
                        "bos": "none",
                        "choch": "none",
                        "current_trend": "Lateral"
                    }
                }
            }
async def restart_bot(self):
    """Reinicia el script completo para recuperar el bot automáticamente."""
    logging.info("Reiniciando script...")
    await asyncio.sleep(5)
    python = sys.executable
    os.execl(python, python, *sys.argv)@retry(max_retries=3, delay=5)
async def get_candles_three_timeframes(api, symbol, timeframe1, timeframe2, timeframe3, period):
    """Obtiene datos de velas para tres temporalidades diferentes."""
    try:
        raw_candles1 = await api.get_candles(symbol, timeframe1, period)
        raw_candles2 = await api.get_candles(symbol, timeframe2, period)
        raw_candles3 = await api.get_candles(symbol, timeframe3, period)

        def process_raw_candles(raw_data, timeframe_label):
            if not raw_data: # Handle empty list of candles
                logging.warning(f"No raw candle data received for {timeframe_label}.")
                return pd.DataFrame() # Return an empty DataFrame

            df = pd.DataFrame.from_dict(raw_data)

            # Ensure 'time' column is present and convert to datetime and set as index
            if 'time' in df.columns:
                # *** FIX HERE: Remove unit='ms' as the time is already a string timestamp ***
                df['time'] = pd.to_datetime(df['time'])
                df = df.set_index('time')
                df.index.name = 'time' # Ensure index name is consistent
            else:
                logging.error(f"Missing 'time' column in {timeframe_label} candle data.")
                return pd.DataFrame() # Return empty if no time column

            # Ensure numeric columns are correct and handle potential NaNs
            numeric_cols = ['open', 'high', 'low', 'close']
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                else:
                    logging.warning(f"Missing '{col}' column in {timeframe_label} candle data.")

            # Ensure 'volume' column exists and is numeric
            if 'volume' not in df.columns:
            # Volumen sintético basado en rango de vela (más realista)
                df['volume'] = (df['high'] - df['low']) * 1000
                logging.info(f"Volumen sintético generado para {timeframe_label}")
            else:
                df['volume'] = pd.to_numeric(df['volume'], errors='coerce')

            # Llenar NaNs en volumen
            df['volume'] = df['volume'].fillna((df['high'] - df['low']) * 1000)
                        
            # Fill any remaining NaNs in numeric columns with 0 or a sensible default
            df = df.fillna(0) # Or another appropriate fill value like the previous candle's value

            # Sort by index (time) to ensure chronological order
            df = df.sort_index()

            return df

        df1 = process_raw_candles(raw_candles1, timeframe1)
        df2 = process_raw_candles(raw_candles2, timeframe2)
        df3 = process_raw_candles(raw_candles3, timeframe3)

        return df1, df2, df3

    except Exception as e:
        logging.error(f"Error obteniendo velas: {e}")
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame() # Return empty DataFrames on error
async def main(ssid):
    api = PocketOptionAsync(ssid)
    await asyncio.sleep(5)
    bot = TradingBot(api)
    await bot.run()

if __name__ == '__main__':
    # Tu SSID REAL aquí:
    ssid = '42["auth",{"session":"jvhu08qp216l4v746aau0sqn2f","isDemo":1,"uid":82503292,"platform":2}]'
    asyncio.run(main(ssid))
