import pandas as pd
import asyncio
import logging
from BinaryOptionsToolsV2.pocketoption import PocketOptionAsync
from datetime import datetime
import time
import unicodedata
import os
from collections import Counter
from collections import defaultdict
from typing import Union, Dict
import sys
import numpy as np
import joblib
import pickle
import json
import traceback
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
import io
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

logging.basicConfig(
    encoding='utf-8',
    level=logging.INFO
)
# --- CLASES PARA REPLICAR PINE SCRIPT TYPES ---
class Alerts:
    swingBullishBOS: bool = False
    swingBearishBOS: bool = False
    swingBullishCHoCH: bool = False
    swingBearishCHoCH: bool = False
    internalBullishBOS: bool = False
    internalBearishBOS: bool = False
    internalBullishCHoCH: bool = False
    internalBearishCHoCH: bool = False
    bullishFairValueGap: bool = False
    bearishFairValueGap: bool = False
    swingBullishOrderBlock: bool = False
    swingBearishOrderBlock: bool = False
    internalBullishOrderBlock: bool = False
    internalBearishOrderBlock: bool = False
    equalHighs: bool = False
    equalLows: bool = False

class TrailingExtremes:
    swingHigh: float = float('nan')
    swingLow: float = float('nan')
    internalHigh: float = float('nan')
    internalLow: float = float('nan')

class Pivot:
    high: float = float('nan')
    low: float = float('nan')
    indexHigh: int = -1
    indexLow: int = -1

class OrderBlock:
    def __init__(self, index: int = -1, level: float = float('nan'),
                 is_bullish: bool = False, is_swing: bool = False,
                 is_mitigated: bool = False):
        self.index = index
        self.level = level
        self.is_bullish = is_bullish
        self.is_swing = is_swing
        self.is_mitigated = is_mitigated

class FairValueGap:
    def __init__(self, index: int = -1, level: float = float('nan'),
                 is_bullish: bool = False, is_mitigated: bool = False):
        self.index = index
        self.level = level
        self.is_bullish = is_bullish
        self.is_mitigated = is_mitigated
# --- CLASE PRINCIPAL DEL INDICADOR ---
class SmartMoneyConcepts:
    def __init__(self,
                 data_1m: pd.DataFrame,
                 data_5m: pd.DataFrame,
                 use_swing_structure: bool = True,
                 use_internal_structure: bool = True,
                 swing_pivot_lookback: int = 10,
                 internal_pivot_lookback: int = 5, # This is the parameter
                 ob_min_body_factor: float = 0.0005,
                 ob_max_wick_factor: float = 0.8,
                 fvg_lookback: int = 3,
                 use_ob: bool = True,
                 use_fvg: bool = True,
                 use_eqh_eql: bool = True,
                 ob_lookback: int = 50):

        self.data_1m = data_1m.copy()
        self.data_5m = data_5m.copy()
        self.use_swing_structure = use_swing_structure
        self.use_internal_structure = use_internal_structure
        self.swing_pivot_lookback = swing_pivot_lookback
        self.internal_pivot_lookback = internal_pivot_lookback # <--- FIX THIS LINE
        self.ob_min_body_factor = ob_min_body_factor
        self.ob_max_wick_factor = ob_max_wick_factor
        self.fvg_lookback = fvg_lookback
        self.use_ob = use_ob
        self.use_fvg = use_fvg
        self.use_eqh_eql = use_eqh_eql
        self.ob_lookback = ob_lookback
        self.alerts = Alerts()
        self.trailing_extremes = TrailingExtremes()
        self.swing_pivot = Pivot()
        self.internal_pivot = Pivot()
        self.ob_history: List[OrderBlock] = []
        self.fvg_history: List[FairValueGap] = []
        self.bos_choch_history: List[Dict] = []
        self.equal_highs_lows: List[Dict] = []
        self.current_trend: str = "Neutral"
        self.last_bos_choch: Optional[Dict] = None
        self.last_swing_high_time = None
        self.last_swing_low_time = None
    def _identify_pivot_and_trend(self, data: pd.DataFrame):
        """
        Identifica pivotes (swing highs/lows) y la tendencia de las velas individuales.
        Ajustado para evitar errores de índice fuera de los límites y usar .iloc.
        """
        # Asegúrate de que los DataFrames no estén vacíos o sean muy pequeños
        # Necesitamos al menos 3 velas para los cálculos de i-2 y i+1
        if data.empty or len(data) < 3:
            logging.warning("Datos insuficientes para identificar pivotes y tendencias en _identify_pivot_and_trend. Se requiere al menos 3 velas.")
            # Inicializa las columnas si el DataFrame es muy pequeño para evitar KeyError más adelante
            data['is_high_pivot'] = False
            data['is_low_pivot'] = False
            data['trend_1m_candle'] = 'Lateral'
            data['trend_1m_prev_candle'] = 'Lateral'
            return data

        # Inicializa las columnas booleanas y de tendencia
        data['is_high_pivot'] = False
        data['is_low_pivot'] = False
        data['trend_1m_candle'] = 'Lateral'  # Inicializa todas a Lateral por defecto
        data['trend_1m_prev_candle'] = 'Lateral' # Inicializa todas a Lateral por defecto

        # Parámetros para la detección de pivotes
        # Esto define cuántas velas a cada lado se usan para determinar un pivote
        left_bars = 2
        right_bars = 2

        # Asegúrate de que la ventana de rolling no sea más grande que los datos disponibles
        rolling_window_size = min(left_bars + right_bars + 1, len(data))
        if rolling_window_size < 1: # En caso de que left_bars o right_bars sean 0 o negativos
            logging.warning("Tamaño de ventana de rolling inválido para _identify_pivot_and_trend.")
            return data

        # Calcula los máximos y mínimos de la ventana de rolling
        # .iloc es para asegurar que se use el indexado posicional
        highs = data['high'].rolling(window=rolling_window_size, center=True).max()
        lows = data['low'].rolling(window=rolling_window_size, center=True).min()

        # Ajusta el rango del bucle para garantizar que los accesos a `i-N` y `i+N` sean siempre válidos.
        start_index = 2 # Mínimo necesario para data.iloc[i - 2]
        end_index = len(data) - 1 # Máximo 'i' para que data.iloc[i + 1] sea válido (es decir, i+1 < len(data))

        # Si el rango de bucle no es válido (ej. data es muy corta), retorna
        if start_index >= end_index:
            logging.warning("Rango de bucle no válido para la detección de pivotes y tendencias. Datos demasiado cortos para la ventana.")
            return data

        for i in range(start_index, end_index):
            # Detección de pivotes: Usa .iloc consistentemente
            if data['high'].iloc[i] == highs.iloc[i]:
                data.loc[data.index[i], 'is_high_pivot'] = True
            elif data['low'].iloc[i] == lows.iloc[i]:
                data.loc[data.index[i], 'is_low_pivot'] = True

            # Tendencia de la vela actual (considerando velas adyacentes)
            if (data['close'].iloc[i] > data['close'].iloc[i - 1] and
                data['close'].iloc[i] > data['close'].iloc[i + 1]):
                data.loc[data.index[i], 'trend_1m_candle'] = 'Alcista'
            elif (data['close'].iloc[i] < data['close'].iloc[i - 1] and
                  data['close'].iloc[i] < data['close'].iloc[i + 1]):
                data.loc[data.index[i], 'trend_1m_candle'] = 'Bajista'
            # Si no es alcista ni bajista, se mantiene como 'Lateral' (por la inicialización)

            # Tendencia de la vela anterior (para confirmar)
            if data['close'].iloc[i - 1] > data['close'].iloc[i - 2]:
                data.loc[data.index[i], 'trend_1m_prev_candle'] = 'Alcista'
            elif data['close'].iloc[i - 1] < data['close'].iloc[i - 2]:
                data.loc[data.index[i], 'trend_1m_prev_candle'] = 'Bajista'
            # Si no es alcista ni bajista, se mantiene como 'Lateral' (por la inicialización)

        return data # Retorna el DataFrame modificado
    def leg(self, series: pd.Series) -> pd.Series:
        """Determines the direction of each bar in a series."""
        result = series.diff()
        result[result > 0] = 1
        result[result < 0] = 0
        return result

    def is_pivot(self, data: pd.DataFrame, index: int, is_high: bool, lookback: int) -> bool:
        """
        Determines if a bar is a pivot high or pivot low.
        """
        # Asegurarse de que el índice esté dentro de los límites válidos para el lookback
        # Si el índice está demasiado cerca del principio o del final para aplicar el lookback,
        # no puede ser un pivote y se retorna False.
        if index < lookback or index >= len(data) - lookback:
            return False

        # Comprobar si es un pivot alto o bajo dentro de la ventana de lookback
        for i in range(1, lookback + 1):
            if is_high: # Es un posible pivot alto
                # Si alguna vela a la izquierda (index - i) o derecha (index + i) es más alta, no es un pivot alto
                # Usamos .iloc para acceso posicional seguro
                if data['high'].iloc[index + i] > data['high'].iloc[index] or \
                   data['high'].iloc[index - i] > data['high'].iloc[index]:
                    return False
            else: # Es un posible pivot bajo
                # Si alguna vela a la izquierda (index - i) o derecha (index + i) es más baja, no es un pivot bajo
                # Usamos .iloc para acceso posicional seguro
                if data['low'].iloc[index + i] < data['low'].iloc[index] or \
                   data['low'].iloc[index - i] < data['low'].iloc[index]:
                    return False
        return True

    def update_swing_pivots(self, data: pd.DataFrame, index: int):
        """
        Updates swing pivot points.
        """
        # Se llama a is_pivot, que ya tiene sus propios checks de límites.
        # Aquí también se usa .iloc para asegurar el acceso posicional a los datos.
        if self.is_pivot(data, index, True, self.swing_pivot_lookback):
            self.swing_pivot.high = data['high'].iloc[index]
            self.swing_pivot.indexHigh = index
            self.last_swing_high_time = data.index[index] # Accediendo al índice de fecha/hora
        if self.is_pivot(data, index, False, self.swing_pivot_lookback):
            self.swing_pivot.low = data['low'].iloc[index]
            self.swing_pivot.indexLow = index
            self.last_swing_low_time = data.index[index] # Accediendo al índice de fecha/hora

    def update_internal_pivots(self, data: pd.DataFrame, index: int):
        """
        Updates internal pivot points.
        """
        # Similar a update_swing_pivots, se basa en is_pivot y usa .iloc.
        if self.is_pivot(data, index, True, self.internal_pivot_lookback):
            self.internal_pivot.high = data['high'].iloc[index]
            self.internal_pivot.indexHigh = index
        if self.is_pivot(data, index, False, self.internal_pivot_lookback):
            self.internal_pivot.low = data['low'].iloc[index]
            self.internal_pivot.indexLow = index

    def update_trailing_extremes(self, data: pd.DataFrame):
        """
        Updates trailing extremes based on pivot points.
        """
        if pd.notna(self.swing_pivot.high) and (pd.isna(self.trailing_extremes.swingHigh) or self.swing_pivot.high > self.trailing_extremes.swingHigh):
            self.trailing_extremes.swingHigh = self.swing_pivot.high
        if pd.notna(self.swing_pivot.low) and (pd.isna(self.trailing_extremes.swingLow) or self.swing_pivot.low < self.trailing_extremes.swingLow):
            self.trailing_extremes.swingLow = self.swing_pivot.low
        if pd.notna(self.internal_pivot.high) and (pd.isna(self.trailing_extremes.internalHigh) or self.internal_pivot.high > self.trailing_extremes.internalHigh):
            self.trailing_extremes.internalHigh = self.internal_pivot.high
        if pd.notna(self.internal_pivot.low) and (pd.isna(self.trailing_extremes.internalLow) or self.internal_pivot.low < self.trailing_extremes.internalLow):
            self.trailing_extremes.internalLow = self.internal_pivot.low

    def detect_bos_choch(self, data: pd.DataFrame, index: int):
        """
        Detects Break of Structure (BOS) and Change of Character (CHoCH).
        """

        if self.use_swing_structure:
            # Swing BOS/CHoCH
            if data['close'].iloc[index] > self.trailing_extremes.swingHigh and pd.notna(self.trailing_extremes.swingHigh):
                self.alerts.swingBullishBOS = True
                self.bos_choch_history.append({
                    "type": "BOS",
                    "direction": "Bullish",
                    "timeframe": "swing",
                    "level": self.trailing_extremes.swingHigh,
                    "index": index,
                    "timestamp": data.index[index]
                })
                self.current_trend = "Bullish"
                self.last_bos_choch = {
                    "type": "BOS",
                    "direction": "Bullish",
                    "timeframe": "swing",
                    "level": self.trailing_extremes.swingHigh,
                    "index": index,
                    "timestamp": data.index[index]
                }
            elif data['close'].iloc[index] < self.trailing_extremes.swingLow and pd.notna(self.trailing_extremes.swingLow):
                self.alerts.swingBearishBOS = True
                self.bos_choch_history.append({
                    "type": "BOS",
                    "direction": "Bearish",
                    "timeframe": "swing",
                    "level": self.trailing_extremes.swingLow,
                    "index": index,
                    "timestamp": data.index[index]
                })
                self.current_trend = "Bearish"
                self.last_bos_choch = {
                    "type": "BOS",
                    "direction": "Bearish",
                    "timeframe": "swing",
                    "level": self.trailing_extremes.swingLow,
                    "index": index,
                    "timestamp": data.index[index]
                }

            # Swing CHoCH
            if self.current_trend == "Bearish" and data['close'].iloc[index] > self.trailing_extremes.swingHigh and pd.notna(self.trailing_extremes.swingHigh):
                self.alerts.swingBullishCHoCH = True
                self.bos_choch_history.append({
                    "type": "CHoCH",
                    "direction": "Bullish",
                    "timeframe": "swing",
                    "level": self.trailing_extremes.swingHigh,
                    "index": index,
                    "timestamp": data.index[index]
                })
                self.current_trend = "Bullish"
                self.last_bos_choch = {
                    "type": "CHoCH",
                    "direction": "Bullish",
                    "timeframe": "swing",
                    "level": self.trailing_extremes.swingHigh,
                    "index": index,
                    "timestamp": data.index[index]
                }
            elif self.current_trend == "Bullish" and data['close'].iloc[index] < self.trailing_extremes.swingLow and pd.notna(self.trailing_extremes.swingLow):
                self.alerts.swingBearishCHoCH = True
                self.bos_choch_history.append({
                    "type": "CHoCH",
                    "direction": "Bearish",
                    "timeframe": "swing",
                    "level": self.trailing_extremes.swingLow,
                    "index": index,
                    "timestamp": data.index[index]
                })
                self.current_trend = "Bearish"
                self.last_bos_choch = {
                    "type": "CHoCH",
                    "direction": "Bearish",
                    "timeframe": "swing",
                    "level": self.trailing_extremes.swingLow,
                    "index": index,
                    "timestamp": data.index[index]
                }

        if self.use_internal_structure:
            # Internal BOS/CHoCH
            if data['close'].iloc[index] > self.trailing_extremes.internalHigh and pd.notna(self.trailing_extremes.internalHigh):
                self.alerts.internalBullishBOS = True
                self.bos_choch_history.append({
                    "type": "BOS",
                    "direction": "Bullish",
                    "timeframe": "internal",
                    "level": self.trailing_extremes.internalHigh,
                    "index": index,
                    "timestamp": data.index[index]
                })
                self.last_bos_choch = {
                    "type": "BOS",
                    "direction": "Bullish",
                    "timeframe": "internal",
                    "level": self.trailing_extremes.internalHigh,
                    "index": index,
                    "timestamp": data.index[index]
                }
            elif data['close'].iloc[index] < self.trailing_extremes.internalLow and pd.notna(self.trailing_extremes.internalLow):
                self.alerts.internalBearishBOS = True
                self.bos_choch_history.append({
                    "type": "BOS",
                    "direction": "Bearish",
                    "timeframe": "internal",
                    "level": self.trailing_extremes.internalLow,
                    "index": index,
                    "timestamp": data.index[index]
                })
                self.last_bos_choch = {
                    "type": "BOS",
                    "direction": "Bearish",
                    "timeframe": "internal",
                    "level": self.trailing_extremes.internalLow,
                    "index": index,
                    "timestamp": data.index[index]
                }

            # Internal CHoCH
            if self.current_trend == "Bearish" and data['close'].iloc[index] > self.trailing_extremes.internalHigh and pd.notna(self.trailing_extremes.internalHigh):
                self.alerts.internalBullishCHoCH = True
                self.bos_choch_history.append({
                    "type": "CHoCH",
                    "direction": "Bullish",
                    "timeframe": "internal",
                    "level": self.trailing_extremes.internalHigh,
                    "index": index,
                    "timestamp": data.index[index]
                })
                self.last_bos_choch = {
                    "type": "CHoCH",
                    "direction": "Bullish",
                    "timeframe": "internal",
                    "level": self.trailing_extremes.internalHigh,
                    "index": index,
                    "timestamp": data.index[index]
                }
            elif self.current_trend == "Bullish" and data['close'].iloc[index] < self.trailing_extremes.internalLow and pd.notna(self.trailing_extremes.internalLow):
                self.alerts.internalBearishCHoCH = True
                self.bos_choch_history.append({
                    "type": "CHoCH",
                    "direction": "Bearish",
                    "timeframe": "internal",
                    "level": self.trailing_extremes.internalLow,
                    "index": index,
                    "timestamp": data.index[index]
                })
                self.last_bos_choch = {
                    "type": "CHoCH",
                    "direction": "Bearish",
                    "timeframe": "internal",
                    "level": self.trailing_extremes.internalLow,
                    "index": index,
                    "timestamp": data.index[index]
                }
    def detect_order_blocks(self, data: pd.DataFrame, index: int):
        """
        Detects Order Blocks.
        """
        if not self.use_ob or index == 0:
            return
        if data['volume'].iloc[index] == 0:
             return
        for i in range(max(0, index - self.ob_lookback), index): # THIS LINE CAUSES THE ERROR
            # Bullish Order Block
            if data['close'].iloc[index] > data['open'].iloc[index] and index > 0 and data['close'].iloc[index - 1] < data['open'].iloc[index - 1]:
                is_swing_ob = self.is_pivot(data, index, True, self.swing_pivot_lookback)
                ob = OrderBlock(index=index, level=data['low'].iloc[index], is_bullish=True, is_swing=is_swing_ob)
                self.ob_history.append(ob)
                self.alerts.swingBullishOrderBlock = True if is_swing_ob else False
                self.alerts.internalBullishOrderBlock = True if not is_swing_ob else False
            # Bearish Order Block
            elif data['close'].iloc[index] < data['open'].iloc[index] and index > 0 and data['close'].iloc[index - 1] > data['open'].iloc[index - 1]:
                is_swing_ob = self.is_pivot(data, index, False, self.swing_pivot_lookback)
                ob = OrderBlock(index=index, level=data['high'].iloc[index], is_bullish=False, is_swing=is_swing_ob)
                self.ob_history.append(ob)
                self.alerts.swingBearishOrderBlock = True if is_swing_ob else False
                self.alerts.internalBearishOrderBlock = True if not is_swing_ob else False

    def detect_fair_value_gaps(self, data: pd.DataFrame, index: int):
        """
        Detects Fair Value Gaps (FVGs).
        """
        if not self.use_fvg or index < 2:
            return

        for i in range(max(0, index - self.fvg_lookback), index):
            # Bullish FVG
            if data['low'].iloc[i] > data['high'].iloc[i + 2]:
                fvg_level = data['high'].iloc[i + 2]
                is_mitigated = False
                for j in range(i + 3, index + 1):
                    if data['low'].iloc[j] <= fvg_level:
                        is_mitigated = True
                        break
                if not is_mitigated and abs(fvg_level - data['close'].iloc[index]) / data['close'].iloc[index] <= 0.001:  # Proximity filter
                    fvg = FairValueGap(index=i, level=fvg_level, is_bullish=True, is_mitigated=is_mitigated)
                    self.fvg_history.append(fvg)
                    self.alerts.bullishFairValueGap = True
                    break  # Only one FVG per bar

            # Bearish FVG
            elif data['high'].iloc[i] < data['low'].iloc[i + 2]:
                fvg_level = data['low'].iloc[i + 2]
                is_mitigated = False
                for j in range(i + 3, index + 1):
                    if data['high'].iloc[j] >= fvg_level:
                        is_mitigated = True
                        break
                if not is_mitigated and abs(fvg_level - data['close'].iloc[index]) / data['close'].iloc[index] <= 0.001:  # Proximity filter
                    fvg = FairValueGap(index=i, level=fvg_level, is_bullish=False, is_mitigated=is_mitigated)
                    self.fvg_history.append(fvg)
                    self.alerts.bearishFairValueGap = True
                    break  # Only one FVG per bar

    def detect_equal_highs_lows(self, data: pd.DataFrame, index: int):
        """
        Detects Equal Highs and Equal Lows.
        """
        if not self.use_eqh_eql or index < 1:
            return

        # Equal Highs
        if abs(data['high'].iloc[index] - data['high'].iloc[index - 1]) / data['high'].iloc[index] <= 0.0001:
            self.equal_highs_lows.append({
                "type": "Equal_Highs",
                "level": data['high'].iloc[index],
                "index": index,
                "timestamp": data.index[index]
            })
            self.alerts.equalHighs = True

        # Equal Lows
        if abs(data['low'].iloc[index] - data['low'].iloc[index - 1]) / data['low'].iloc[index] <= 0.0001:
            self.equal_highs_lows.append({
                "type": "Equal_Lows",
                "level": data['low'].iloc[index],
                "index": index,
                "timestamp": data.index[index]
            })
            self.alerts.equalLows = True

    def process_bar(self, data: pd.DataFrame, bar: pd.Series, index: int):
        """
        Processes a single bar of data.
        """
        self.update_swing_pivots(data, index)
        self.update_internal_pivots(data, index)
        self.update_trailing_extremes(data)
        self.detect_bos_choch(data, index)
        self.detect_order_blocks(data, index)
        self.detect_fair_value_gaps(data, index)
        self.detect_equal_highs_lows(data, index)

        # Clear alerts after processing
        self.alerts = Alerts()

    def analyze_smc(self, data: pd.DataFrame, timeframe: str) -> List[Dict]:
        """
        Main function to analyze SMC concepts.
        """
        smc_analyzer = SmartMoneyConcepts(
            use_swing_structure=True,
            use_internal_structure=True,
            swing_pivot_lookback=10,
            internal_pivot_lookback=5,
            ob_min_body_factor=0.0005,
            ob_max_wick_factor=0.8,
            fvg_lookback=3,
            use_ob=True,
            use_fvg=True,
            use_eqh_eql=True
        )

        for i in range(len(data)):
            smc_analyzer.process_bar(data, data.iloc[i], i)

        # Extract and return the relevant SMC information
        smc_signals = []

        # BOS/CHoCH
        for event in smc_analyzer.bos_choch_history:
            smc_signals.append({
                "tipo": f"SMC_{event['type']}_{event['direction']}",
                "timeframe": timeframe,
                "level": event['level'],
                "timestamp": event['timestamp']
            })

        # Order Blocks (Optional, if you want them)
        for ob in smc_analyzer.ob_history:
            if not ob.is_mitigated:
                smc_signals.append({
                    "tipo": f"SMC_OB_{'Bullish' if ob.is_bullish else 'Bearish'}",
                    "timeframe": timeframe,
                    "level": ob.level,
                    "timestamp": data.index[ob.index]
                })

        # Fair Value Gaps (Optional, if you want them)
        for fvg in smc_analyzer.fvg_history:
            if not fvg.is_mitigated:
                smc_signals.append({
                    "tipo": f"SMC_FVG_{'Bullish' if fvg.is_bullish else 'Bearish'}",
                    "timeframe": timeframe,
                    "level": fvg.level,
                    "timestamp": data.index[fvg.index]
                })

        # Equal Highs/Lows (Optional, if you want them)
        for eq in smc_analyzer.equal_highs_lows:
            smc_signals.append({
                "tipo": f"SMC_{eq['type']}",
                "timeframe": timeframe,
                "level": eq['level'],
                "timestamp": eq['timestamp']
            })

        return smc_signals

    def get_current_market_structure(self, data: pd.DataFrame) -> Dict:
        """
        Returns the current market structure state (BOS/CHoCH).
        """
        bos_choch_events = [
            event for event in self.bos_choch_history
            if data.index[-1] == event["timestamp"]  # Only get the latest events
        ]

        return {
            "current_trend": self.current_trend,
            "last_bos_choch": self.last_bos_choch,
            "bos_choch_events": bos_choch_events  # Return only BOS/CHoCH
            # "active_order_blocks": [ob.__dict__ for ob in self.ob_history if not ob.is_mitigated],  # Optional
            # "active_fvgs": [fvg.__dict__ for fvg in self.fvg_history if not fvg.is_mitigated],  # Optional
            # "equal_highs_lows": self.equal_highs_lows  # Optional
        }
   
def guardar_diagnostico(señal, informacion_adicional=None, filename="diagnostico_actual.json"):
    """
    Guarda el diagnóstico de la señal en un archivo JSON.

    Args:
        señal (dict): El diccionario que contiene el diagnóstico de la señal.
        informacion_adicional (dict, optional): Información adicional para guardar junto con el diagnóstico. Defaults to None.
        filename (str, optional): El nombre del archivo en el que se guardará el diagnóstico. Defaults to "diagnostico_actual.json".
    """
    try:
        datos_a_guardar = {
            "diagnostico": señal,
            "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S")
        }
        if informacion_adicional:
            datos_a_guardar["info_extra"] = informacion_adicional

        with open(filename, "w", encoding="utf-8") as f:
            json.dump(datos_a_guardar, f, indent=2, ensure_ascii=False)
        print(f" Diagnóstico guardado en {filename}")
        
    except Exception as e:
        print(f" Error al guardar diagnóstico: {e}")

os.environ["LOKY_MAX_CPU_COUNT"] = "6"
# Cargar el modelo
# Cargar modelos y recursos
modelo_signal = joblib.load('modelo_lightgbm.pkl')
modelo_niveles = joblib.load('modelo_niveles.pkl')
modelo_direccion = joblib.load('modelo_direccion_mercado.pkl')  # Cargar el nuevo modelo
scaler_direccion = joblib.load('scaler_direccion.pkl')        # Cargar el scaler
label_encoders_direccion = joblib.load('label_encoders_direccion.pkl')  # Cargar los label encoders

logging.basicConfig(
    level=logging.INFO, # Cambia a logging.DEBUG para más verbosidad
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("trading_bot.log"), # Guarda logs en un archivo
        logging.StreamHandler() # Muestra logs en consola también
    ]
)

# Funciones de carga de modelos (manteniendo la estructura existente)
def cargar_modelo_niveles(path="modelo_niveles.pkl"):
    try:
        modelo = joblib.load(path)
        print("Modelo de niveles cargado correctamente.")
        return modelo
    except Exception as e:
        print(f"Error al cargar el modelo de niveles: {e}")
        return None

def cargar_modelo_lightgbm(path="modelo_lightgbm.pkl"):
    try:
        modelo = joblib.load(path)
        logging.info("Modelo LightGBM cargado correctamente.")
        return modelo
    except Exception as e:
        logging.error(f"Error al cargar el modelo LightGBM: {e}")
        return None


def predecir_direccion_precio(self, data=None):
    """
    Predice la dirección del precio basándose en indicadores técnicos.
    Retorna 'Buy', 'Sell' o None según la predicción.
    
    Parameters:
    -----------
    data : pd.DataFrame, opcional
        DataFrame con datos OHLC. Si es None, se usa self.data_1m
        
    Returns:
    --------
    str
        'Buy', 'Sell' o None según la dirección predicha
    """
    try:
        # Si no se proporcionan datos, usar los datos internos de 1 minuto
        if data is None:
            if self.data_1m is None or len(self.data_1m) < 100:  # Aumentado a 100 para permitir SMA de 100 períodos
                logging.warning("Datos insuficientes para predecir dirección")
                return None
            data = self.data_1m.copy()
        
        # Asegurarnos de tener suficientes datos
        if len(data) < 100:  # Aumentado a 100 para permitir SMA de 100 períodos
            logging.warning("Datos insuficientes para predecir dirección")
            return None
            
        # Calcular indicadores técnicos
        # Calcular indicadores técnicos
        # 1. RSI con periodo 10 (según la captura)
        data['rsi'] = self.calcular_rsi(data['close'], periodo=10)
        
        # 2. SMA blanca de 100 y SMA verde fluorescente de 20
        data['sma_100'] = data['close'].rolling(window=100).mean()  # SMA blanca de 100 períodos
        data['sma_20'] = data['close'].rolling(window=20).mean()    # SMA verde fluorescente de 20 períodos
        
        # 3. ADX con periodo 5.5 (según la captura)
        data['adx'] = self.calcular_adx(data, periodo=5)
        
        # 4. Bandas de Bollinger (mantenidas del código original)
        data['sma20'] = data['close'].rolling(window=20).mean()
        data['std20'] = data['close'].rolling(window=20).std()
        data['bband_upper'] = data['sma20'] + (data['std20'] * 2)
        data['bband_lower'] = data['sma20'] - (data['std20'] * 2)
        
        # Obtener los últimos valores para tomar la decisión
        ultimo_indice = len(data) - 1
        rsi = data['rsi'].iloc[ultimo_indice]
        sma_20 = data['sma_20'].iloc[ultimo_indice]
        sma_100 = data['sma_100'].iloc[ultimo_indice]
        adx = data['adx'].iloc[ultimo_indice]
        precio_actual = data['close'].iloc[ultimo_indice]
        bband_upper = data['bband_upper'].iloc[ultimo_indice]
        bband_lower = data['bband_lower'].iloc[ultimo_indice]
        
        # Sistema de puntuación para tomar decisión
        puntuacion = 0
        
        # RSI: Sobrecompra/Sobreventa
        if rsi > 70:
            puntuacion -= 2  # Sobrecompra, posible bajada
        elif rsi < 30:
            puntuacion += 2  # Sobreventa, posible subida
        
        # Media móvil: Cruce alcista/bajista usando SMA
        if sma_20 > sma_100:
            puntuacion += 1  # Cruce alcista
        else:
            puntuacion -= 1  # Cruce bajista
            
        # ADX: Fuerza de la tendencia
        if adx > 25:
            # Si hay fuerte tendencia, reforzar la dirección actual
            if sma_20 > sma_100:
                puntuacion += 1  # Reforzar tendencia alcista
            else:
                puntuacion -= 1  # Reforzar tendencia bajista
            
        # Bandas de Bollinger: Posición del precio
        if precio_actual > bband_upper:
            puntuacion -= 1  # Sobrecompra
        elif precio_actual < bband_lower:
            puntuacion += 1  # Sobreventa
            
        # Determinar dirección según la puntuación
        if puntuacion >= 2:
            return "Buy"
        elif puntuacion <= -2:
            return "Sell"
        else:
            return None  # Sin dirección clara
            
    except Exception as e:
        logging.error(f"Error al predecir dirección del precio: {str(e)}")
        return None
        
def calcular_rsi(self, serie, periodo=10):
    """Calcula el RSI para una serie de precios con periodo 10 (según la captura)"""
    try:
        delta = serie.diff()
        
        # Separar ganancia y pérdida
        ganancia = delta.copy()
        perdida = delta.copy()
        ganancia[ganancia < 0] = 0
        perdida[perdida > 0] = 0
        perdida = abs(perdida)
        
        # Calcular media de ganancia y pérdida
        avg_ganancia = ganancia.rolling(window=periodo).mean()
        avg_perdida = perdida.rolling(window=periodo).mean()
        
        # Calcular RS y RSI
        rs = avg_ganancia / avg_perdida
        rsi = 100 - (100 / (1 + rs))
        
        return rsi
    except Exception as e:
        logging.error(f"Error al calcular RSI: {str(e)}")
        return pd.Series([50] * len(serie))  # Valor neutro

def calcular_adx(self, data, periodo=5):
    """
    Calcula el ADX (Average Directional Index) con periodo 5.5 como se muestra en la captura
    
    Parameters:
    -----------
    data : pd.DataFrame
        DataFrame con datos OHLC
    periodo : int
        Período para el cálculo del ADX (5 según la captura)
        
    Returns:
    --------
    pd.Series
        Serie con los valores del ADX
    """
    try:
        # Calcular True Range (TR)
        data = data.copy()
        data['tr1'] = abs(data['high'] - data['low'])
        data['tr2'] = abs(data['high'] - data['close'].shift(1))
        data['tr3'] = abs(data['low'] - data['close'].shift(1))
        data['tr'] = data[['tr1', 'tr2', 'tr3']].max(axis=1)
        
        # Calcular +DM y -DM
        data['plus_dm'] = 0.0
        data['minus_dm'] = 0.0
        
        # +DM
        data.loc[(data['high'] - data['high'].shift(1)) > (data['low'].shift(1) - data['low']), 'plus_dm'] = \
            (data['high'] - data['high'].shift(1)).clip(lower=0)
            
        # -DM
        data.loc[(data['low'].shift(1) - data['low']) > (data['high'] - data['high'].shift(1)), 'minus_dm'] = \
            (data['low'].shift(1) - data['low']).clip(lower=0)
        
        # Calcular ATR de periodo
        data['atr'] = data['tr'].rolling(window=periodo).mean()
        
        # Calcular +DI y -DI
        data['plus_di'] = 100 * (data['plus_dm'].rolling(window=periodo).mean() / data['atr'])
        data['minus_di'] = 100 * (data['minus_dm'].rolling(window=periodo).mean() / data['atr'])
        
        # Calcular DX
        data['dx'] = 100 * abs(data['plus_di'] - data['minus_di']) / (data['plus_di'] + data['minus_di'])
        
        # Calcular ADX (media móvil del DX)
        adx = data['dx'].rolling(window=periodo).mean()
        
        return adx
    except Exception as e:
        logging.error(f"Error al calcular ADX: {str(e)}")
        return pd.Series([20] * len(data))  # Valor neutro para ADX
    
def detectar_order_blocks(data_5m, data_1m, niveles_filtrados):
    """
    Detección sensible de Order Blocks:
    - Reversión fuerte o razonable desde zona relevante.
    - Consolidación amplia seguida de ruptura.
    """
    ob_signals = []
    current_price_1m = data_1m['close'].iloc[-1]  # Precio actual de 1 minuto
    proximidad_relativa = current_price_1m * 0.001  # 0.1% del precio actual
    proximidad_absoluta = 0.1  # Por ejemplo, 0.1 unidades de precio

    if len(data_5m) < 15:
        return ob_signals

    ultimas_velas = data_5m.tail(15).reset_index(drop=True)

    # --- BLOQUE 1: REVERSIÓN FUERTE O MODERADA ---
    for i in range(1, len(ultimas_velas)):
        prev = ultimas_velas.iloc[i - 1]
        curr = ultimas_velas.iloc[i]

        cuerpo_prev = abs(prev['close'] - prev['open'])
        cuerpo_curr = abs(curr['close'] - curr['open'])

        es_bajista_prev = prev['close'] < prev['open']
        es_alcista_curr = curr['close'] > curr['open']

        es_alcista_prev = prev['close'] > prev['open']
        es_bajista_curr = curr['close'] < curr['open']

        # Reversión Alcista
        if es_bajista_prev and es_alcista_curr and cuerpo_curr >= cuerpo_prev * 0.8:
            direccion = 'compra'
            nivel_ob = prev['low']
            if abs(current_price_1m - nivel_ob) <= min(proximidad_relativa, proximidad_absoluta): #añadido
                for nivel in niveles_filtrados:
                    if abs(nivel - nivel_ob) <= 0.0008:
                        ob_signals.append({
                            'tipo': direccion,
                            'Type': 'Buy',
                            'Level': nivel_ob,
                            'Reason': 'Reversión Alcista fuerte',
                            'Confidence': 'Media',
                            'Categoria': 'OrderBlock',
                            'Strategy': 'Reversión',
                            'Nombre': f"Order Block alcista - reversión",
                            'Esquema': 'Reversión',
                            'OrderBlockRelacionado': True
                        })

        # Reversión Bajista
        if es_alcista_prev and es_bajista_curr and cuerpo_curr >= cuerpo_prev * 0.8:
            direccion = 'venta'
            nivel_ob = prev['high']
            if abs(current_price_1m - nivel_ob) <= min(proximidad_relativa, proximidad_absoluta): #añadido
                for nivel in niveles_filtrados:
                    if abs(nivel - nivel_ob) <= 0.0008:
                        ob_signals.append({
                            'tipo': direccion,
                            'Type': 'Sell',
                            'Level': nivel_ob,
                            'Reason': 'Reversión Bajista fuerte',
                            'Confidence': 'Media',
                            'Categoria': 'OrderBlock',
                            'Strategy': 'Reversión',
                            'Nombre': f"Order Block bajista - reversión",
                            'Esquema': 'Reversión',
                            'OrderBlockRelacionado': True
                        })

    # --- BLOQUE 2: CONSOLIDACIÓN + RUPTURA ---
    ventana = 3  # Velas de consolidación
    for i in range(ventana, len(ultimas_velas)):
        consolidacion = ultimas_velas.iloc[i - ventana:i]
        ruptura = ultimas_velas.iloc[i]

        rango_cons = consolidacion['high'].max() - consolidacion['low'].min()
        cuerpo_ruptura = abs(ruptura['close'] - ruptura['open'])

        if rango_cons < 0.002 and cuerpo_ruptura > rango_cons * 1.3:
            direccion = 'compra' if ruptura['close'] > ruptura['open'] else 'venta'
            nivel_ob = consolidacion['low'].min() if direccion == 'compra' else consolidacion['high'].max()
            if abs(current_price_1m - nivel_ob) <= min(proximidad_relativa, proximidad_absoluta): #añadido
                for nivel in niveles_filtrados:
                    if abs(nivel - nivel_ob) <= 0.0008:
                        ob_signals.append({
                            'tipo': direccion,
                            'Type': 'Buy' if direccion == 'compra' else 'Sell',
                            'nivel_ob': nivel_ob,
                            'origen': 'consolidación + ruptura',
                            'clasificacion': 'Alta' if cuerpo_ruptura > rango_cons * 2 else 'Media',
                            'Confidence': 'Alta' if cuerpo_ruptura > rango_cons * 2 else 'Media',
                            'Categoria': 'OrderBlock'
                        })
    return ob_signals


def detectar_consolidaciones(data_5m, niveles_filtrados):
    """
    Detección de consolidaciones seguidas de ruptura.
    """
    consolidacion_signals = []
    rango_maximo = 0.0012  # Configuración del rango máximo de consolidación
    current_price_1m = data_5m['close'].iloc[-1] #precio actual
    proximidad_relativa = current_price_1m * 0.001  # 0.1% del precio actual
    proximidad_absoluta = 0.1  # Por ejemplo, 0.1 unidades de precio

    for i in range(3, len(data_5m)):  # Analizamos bloques de 3 velas
        rango_velas = data_5m.iloc[i - 3:i]
        max_high = rango_velas['high'].max()
        min_low = rango_velas['low'].min()

        if max_high - min_low <= rango_maximo:
            vela_actual = data_5m.iloc[i]
            ruptura_alcista = vela_actual['close'] > max_high
            ruptura_bajista = vela_actual['close'] < min_low

            if ruptura_alcista or ruptura_bajista:
                nivel_ob = max_high if ruptura_alcista else min_low
                if abs(current_price_1m - nivel_ob) <= min(proximidad_relativa, proximidad_absoluta): #añadido
                    consolidacion_signals.append({
                        'tipo': 'compra' if ruptura_alcista else 'venta',
                        'Type': 'Buy' if ruptura_alcista else 'Sell',
                        'nivel_ob': nivel_ob,
                        'origen': 'ruptura consolidación',
                        'clasificacion': 'Alta',
                        'Confidence': 'Alta',
                        'Categoria': 'Consolidación'
                    })
    return consolidacion_signals
# Función para registrar resultados en un archivo CSV
def detectar_fvg(data, max_patrones=5, ignorar_proximidad=True):
    """
    Detecta Fair Value Gaps (FVG), BISI y SIBI en los datos de precio y genera señales.

    Args:
        data (pd.DataFrame): DataFrame con datos de velas (high, low, open, close, time).
        max_patrones (int): Número máximo de patrones a devolver (los más recientes).
        ignorar_proximidad (bool): Si es True, ignora la restricción de proximidad al precio actual.

    Returns:
        list: Lista de diccionarios, donde cada diccionario representa un FVG, BISI o SIBI
              y contiene información para generar una señal de trading.
    """
    fvg_zonas = []
    current_price_1m = data['close'].iloc[-1]
    proximidad_relativa = current_price_1m * 0.005  # Aumentado a 0.5% del precio actual
    proximidad_absoluta = 0.5  # Aumentado a 0.5 unidades de precio
    
    if len(data) < 3:
        return fvg_zonas  # Necesitamos al menos 3 velas para detectar un FVG

    # Iteramos en orden inverso para encontrar los patrones más recientes primero
    for i in range(len(data) - 1, 2, -1):
        # Si ya tenemos suficientes patrones, paramos
        if len(fvg_zonas) >= max_patrones:
            break
            
        vela_1 = data.iloc[i - 2]
        vela_2 = data.iloc[i - 1]
        vela_3 = data.iloc[i]

        # --- FVG Alcista ---
        if vela_2['low'] > vela_1['high'] and vela_2['low'] > vela_3['high']:
            nivel_fvg = vela_2['low']
            # Solo comprobamos proximidad si no estamos ignorándola
            if ignorar_proximidad or abs(current_price_1m - nivel_fvg) <= min(proximidad_relativa, proximidad_absoluta):
                fvg_zonas.append({
                    'tipo': 'fvg_alcista',
                    'señal': 'Compra',  # Señal de compra para FVG alcista
                    'zona_superior': vela_1['high'],
                    'zona_inferior': vela_3['low'],
                    'nivel': nivel_fvg,  # Añadimos el nivel específico
                    'timestamp': vela_2['time'],
                    'esquema': 'FVG',
                    'Confidence': 'Media',
                    'distancia_precio': abs(current_price_1m - nivel_fvg)
                })

        # --- FVG Bajista ---
        elif vela_2['high'] < vela_1['low'] and vela_2['high'] < vela_3['low']:
            nivel_fvg = vela_2['high']
            if ignorar_proximidad or abs(current_price_1m - nivel_fvg) <= min(proximidad_relativa, proximidad_absoluta):
                fvg_zonas.append({
                    'tipo': 'fvg_bajista',
                    'señal': 'Venta',  # Señal de venta para FVG bajista
                    'zona_superior': vela_1['low'],
                    'zona_inferior': vela_3['high'],
                    'nivel': nivel_fvg,  # Añadimos el nivel específico
                    'timestamp': vela_2['time'],
                    'esquema': 'FVG',
                    'Confidence': 'Media',
                    'distancia_precio': abs(current_price_1m - nivel_fvg)
                })

        # --- BISI (Buy-Side Imbalance Sell-Side Inefficiency) ---
        elif (vela_1['close'] > vela_1['open'] and  # Vela 1 alcista (verde)
              vela_3['close'] < vela_3['open'] and  # Vela 3 bajista (roja)
              vela_2['low'] > max(vela_1['high'], vela_3['high'])):  # Vela 2 por encima
            nivel_bisi = vela_2['low']
            if ignorar_proximidad or abs(current_price_1m - nivel_bisi) <= min(proximidad_relativa, proximidad_absoluta):
                fvg_zonas.append({
                    'tipo': 'bisi',
                    'señal': 'Venta',  # Señal de venta para BISI
                    'zona_superior': vela_2['low'],
                    'zona_inferior': max(vela_1['high'], vela_3['high']),
                    'nivel': nivel_bisi,  # Añadimos el nivel específico
                    'timestamp': vela_2['time'],
                    'esquema': 'BISI',
                    'Confidence': 'Alta',
                    'distancia_precio': abs(current_price_1m - nivel_bisi)
                })

        # --- SIBI (Sell-Side Imbalance Buy-Side Inefficiency) ---
        elif (vela_1['close'] < vela_1['open'] and  # Vela 1 bajista (roja)
              vela_3['close'] > vela_3['open'] and  # Vela 3 alcista (verde)
              vela_2['high'] < min(vela_1['low'], vela_3['low'])):  # Vela 2 por debajo
            nivel_sibi = min(vela_1['low'], vela_3['low'])
            if ignorar_proximidad or abs(current_price_1m - nivel_sibi) <= min(proximidad_relativa, proximidad_absoluta):
                fvg_zonas.append({
                    'tipo': 'sibi',
                    'señal': 'Compra',  # Señal de compra para SIBI
                    'zona_superior': min(vela_1['low'], vela_3['low']),
                    'zona_inferior': vela_2['high'],
                    'nivel': nivel_sibi,  # Añadimos el nivel específico
                    'timestamp': vela_2['time'],
                    'esquema': 'SIBI',
                    'Confidence': 'Alta',
                    'distancia_precio': abs(current_price_1m - nivel_sibi)
                })
    
    # Ordenamos por distancia al precio actual para priorizar los más cercanos
    fvg_zonas.sort(key=lambda x: x['distancia_precio'])
    return fvg_zonas

def _detectar_fvg_individual(data, current_price, proximidad_relativa, proximidad_absoluta, ignorar_proximidad, max_patrones):
    fvg_signals = []
    for i in range(len(data) - 1, 2, -1):
        if len(fvg_signals) >= max_patrones:
            break
        vela_1 = data.iloc[i - 2]
        vela_2 = data.iloc[i - 1]
        vela_3 = data.iloc[i]
        timestamp_vela_2 = data.index[i - 1]
        if vela_2['low'] > vela_1['high'] and vela_2['low'] > vela_3['high']:
            nivel_fvg = vela_2['low']
            if ignorar_proximidad or abs(current_price - nivel_fvg) <= min(proximidad_relativa, proximidad_absoluta):
                fvg_signals.append({
                    'Type': 'Buy', 'Level': nivel_fvg, 'Reason': 'FVG', 'Esquema': 'FVG',
                    'DireccionEstructural': 'alcista', 'TipoEstructura': 'continuacion',
                    'Confidence': 'Media', 'Categoria': 'Imbalance', 'Strategy': 'FVG_M1',
                    'Nombre': 'FVG alcista en 1M', 'OrderBlockRelacionado': False,
                    'Timestamp': timestamp_vela_2, 'DistanciaAlPrecioActual': abs(current_price - nivel_fvg)
                })
        elif vela_2['high'] < vela_1['low'] and vela_2['high'] < vela_3['low']:
            nivel_fvg = vela_2['high']
            if ignorar_proximidad or abs(current_price - nivel_fvg) <= min(proximidad_relativa, proximidad_absoluta):
                fvg_signals.append({
                    'Type': 'Sell', 'Level': nivel_fvg, 'Reason': 'FVG', 'Esquema': 'FVG',
                    'DireccionEstructural': 'bajista', 'TipoEstructura': 'continuacion',
                    'Confidence': 'Media', 'Categoria': 'Imbalance', 'Strategy': 'FVG_M1',
                    'Nombre': 'FVG bajista en 1M', 'OrderBlockRelacionado': False,
                    'Timestamp': timestamp_vela_2, 'DistanciaAlPrecioActual': abs(current_price - nivel_fvg)
                })
    return fvg_signals

def _detectar_bisi(data, current_price, proximidad_relativa, proximidad_absoluta, ignorar_proximidad, max_patrones):
    bisi_signals = []
    for i in range(len(data) - 1, 2, -1):
        if len(bisi_signals) >= max_patrones:
            break
        vela_1 = data.iloc[i - 2]
        vela_2 = data.iloc[i - 1]
        vela_3 = data.iloc[i]
        timestamp_vela_2 = data.index[i - 1]
        if (vela_1['close'] > vela_1['open'] and vela_3['close'] < vela_3['open'] and
            vela_2['low'] > max(vela_1['high'], vela_3['high'])):
            nivel_bisi = vela_2['low']
            if ignorar_proximidad or abs(current_price - nivel_bisi) <= min(proximidad_relativa, proximidad_absoluta):
                bisi_signals.append({
                    'Type': 'Sell', 'Level': nivel_bisi, 'Reason': 'BISI', 'Esquema': 'BISI',
                    'DireccionEstructural': 'bajista', 'TipoEstructura': 'reversion',
                    'Confidence': 'Alta', 'Categoria': 'Imbalance', 'Strategy': 'BISI_M1',
                    'Nombre': 'BISI en 1M', 'OrderBlockRelacionado': False,
                    'Timestamp': timestamp_vela_2, 'DistanciaAlPrecioActual': abs(current_price - nivel_bisi)
                })
    return bisi_signals

def _detectar_sibi(data, current_price, proximidad_relativa, proximidad_absoluta, ignorar_proximidad, max_patrones):
    sibi_signals = []
    for i in range(len(data) - 1, 2, -1):
        if len(sibi_signals) >= max_patrones:
            break
        vela_1 = data.iloc[i - 2]
        vela_2 = data.iloc[i - 1]
        vela_3 = data.iloc[i]
        timestamp_vela_2 = data.index[i - 1]
        if (vela_1['close'] < vela_1['open'] and vela_3['close'] > vela_3['open'] and
            vela_2['high'] < min(vela_1['low'], vela_3['low'])):
            nivel_sibi = min(vela_1['low'], vela_3['low'])
            if ignorar_proximidad or abs(current_price - nivel_sibi) <= min(proximidad_relativa, proximidad_absoluta):
                sibi_signals.append({
                    'Type': 'Buy', 'Level': nivel_sibi, 'Reason': 'SIBI', 'Esquema': 'SIBI',
                    'DireccionEstructural': 'alcista', 'TipoEstructura': 'reversion',
                    'Confidence': 'Alta', 'Categoria': 'Imbalance', 'Strategy': 'SIBI_M1',
                    'Nombre': 'SIBI en 1M', 'OrderBlockRelacionado': False,
                    'Timestamp': timestamp_vela_2, 'DistanciaAlPrecioActual': abs(current_price - nivel_sibi)
                })
    return sibi_signals

def detectar_fvg(data, max_patrones=5, ignorar_proximidad=True):
    all_signals = []
    if len(data) < 3:
        return all_signals
    current_price_1m = data['close'].iloc[-1]
    proximidad_relativa = current_price_1m * 0.005
    proximidad_absoluta = 0.5
    all_signals.extend(_detectar_fvg_individual(data, current_price_1m, proximidad_relativa, proximidad_absoluta, ignorar_proximidad, max_patrones))
    all_signals.extend(_detectar_bisi(data, current_price_1m, proximidad_relativa, proximidad_absoluta, ignorar_proximidad, max_patrones))
    all_signals.extend(_detectar_sibi(data, current_price_1m, proximidad_relativa, proximidad_absoluta, ignorar_proximidad, max_patrones))
    
    if not ignorar_proximidad:
        all_signals.sort(key=lambda x: x['DistanciaAlPrecioActual'])
    else:
        all_signals.sort(key=lambda x: x['Timestamp'], reverse=True)
    return all_signals[:max_patrones]

def detectar_bos_choch(data, tendencia_actual=None, ventana_estructura=10, confirmacion=True,
                       max_patrones=5):
    """
    Detecta estructuras BOS (Break of Structure) y CHoCH (Change of Character)
    en el gráfico de 1 minuto con mayor precisión.

    Args:
        data_1m (pd.DataFrame): Velas de 1 minuto con columnas 'open', 'high', 'low', 'close'.
                                Se asume que el índice es el Timestamp si se necesita.
        tendencia_actual (str, optional): Tendencia actual del mercado ('Alcista' o 'Bajista' o 'Lateral').
                                         Si es None, la función intenta inferirla.
        ventana_estructura (int): Número de velas a cada lado para identificar swings (puntos clave de estructura).
                                  Un valor mayor genera swings más significativos.
        confirmacion (bool): Si es True, requiere que el precio de cierre de la vela supere el nivel
                             para confirmar la señal (además del high/low).
        max_patrones (int): Número máximo de patrones a devolver (los más recientes primero).

    Returns:
        list[dict]: Lista de señales detectadas (BOS/CHoCH), ordenadas por timestamp descendente.
    """

    señales = []

    if data is None or len(data) < max(ventana_estructura * 2 + 1, 5):
        # Necesitamos al menos (ventana_estructura * 2 + 1) velas para la detección de swings
        # y un mínimo general de 5 para el resto de la lógica.
        return señales

    df = data.copy()

    # --- 1. Inferir Tendencia si no se proporciona ---
    if tendencia_actual is None:
        ventana_tendencia_inferencia = min(20, len(df) // 4) # Usar una ventana razonable para inferir
        if ventana_tendencia_inferencia >= 5: # Asegurar que hay suficientes datos para la inferencia
            primeras_high_max = df['high'].iloc[-ventana_tendencia_inferencia*2:-ventana_tendencia_inferencia].max()
            ultimas_high_max = df['high'].iloc[-ventana_tendencia_inferencia:].max()
            primeras_low_min = df['low'].iloc[-ventana_tendencia_inferencia*2:-ventana_tendencia_inferencia].min()
            ultimas_low_min = df['low'].iloc[-ventana_tendencia_inferencia:].min()

            if ultimas_high_max > primeras_high_max and ultimas_low_min > primeras_low_min:
                tendencia_actual = "Alcista"
            elif ultimas_high_max < primeras_high_max and ultimas_low_min < primeras_low_min:
                tendencia_actual = "Bajista"
            else:
                tendencia_actual = "Lateral"
        else:
            tendencia_actual = "Lateral" # No hay suficientes datos para inferir

    # --- 2. Identificar Swings (Puntos Estructurales) ---
    df['swing_high'] = False
    df['swing_low'] = False

    # Ventana efectiva para la detección de swings (asegura al menos 1 para cada lado)
    ventana_efectiva = max(1, min(ventana_estructura, (len(df) - 1) // 2))

    for i in range(ventana_efectiva, len(df) - ventana_efectiva):
        # Swing high: el precio es el más alto en la ventana a la izquierda y derecha
        is_swing_high = True
        for j in range(1, ventana_efectiva + 1):
            if df['high'].iloc[i] < df['high'].iloc[i - j] or \
               df['high'].iloc[i] < df['high'].iloc[i + j]:
                is_swing_high = False
                break
        if is_swing_high:
            df.loc[df.index[i], 'swing_high'] = True

        # Swing low: el precio es el más bajo en la ventana a la izquierda y derecha
        is_swing_low = True
        for j in range(1, ventana_efectiva + 1):
            if df['low'].iloc[i] > df['low'].iloc[i - j] or \
               df['low'].iloc[i] > df['low'].iloc[i + j]:
                is_swing_low = False
                break
        if is_swing_low:
            df.loc[df.index[i], 'swing_low'] = True

    # --- 3. Detectar BOS y CHoCH ---
    patrones_encontrados = 0

    # Iteramos desde el final del DataFrame hacia atrás para encontrar los patrones más recientes
    for i in range(len(df) - 1, ventana_efectiva, -1): # Start from current_bar, go back to where swings can be found
        if patrones_encontrados >= max_patrones:
            break

        # Buscar el swing high y swing low más recientes ANTES del índice actual `i`
        # Aseguramos que el swing point está estrictamente antes de la vela actual `i`
        swing_high_indices = df.index[(df.index < df.index[i]) & df['swing_high']].tolist()
        swing_low_indices = df.index[(df.index < df.index[i]) & df['swing_low']].tolist()

        if not swing_high_indices or not swing_low_indices:
            continue

        ultimo_swing_high_idx = swing_high_indices[-1] # El más reciente de los encontrados
        ultimo_swing_low_idx = swing_low_indices[-1]   # El más reciente de los encontrados

        ultimo_swing_high_valor = df['high'].loc[ultimo_swing_high_idx]
        ultimo_swing_low_valor = df['low'].loc[ultimo_swing_low_idx]

        current_high = df['high'].iloc[i]
        current_low = df['low'].iloc[i]
        current_close = df['close'].iloc[i]
        current_timestamp = df.index[i] # El timestamp de la vela actual que está rompiendo

        # Rango significativo (0.2% del precio actual de la vela de ruptura)
        rango_significativo = current_close * 0.002

        # --- BOS Alcista (Bullish BOS) ---
        # Rompimiento por encima del último swing high en tendencia alcista/lateral
        if current_high > ultimo_swing_high_valor and tendencia_actual in ["Alcista", "Lateral"]:
            if (current_high - ultimo_swing_high_valor) > rango_significativo:
                if not confirmacion or current_close > ultimo_swing_high_valor:
                    señales.append({
                        "Type": "Buy",
                        "Level": ultimo_swing_high_valor,
                        "Reason": "BOS",
                        "Esquema": "BOS",
                        "DireccionEstructural": "alcista",
                        "TipoEstructura": "continuacion",
                        "Confidence": "Alta",
                        "Categoria": "Estructura",
                        "Strategy": "BOS_CHOCH_M1",
                        "OrderBlockRelacionado": False, # Esto requeriría lógica adicional
                        "Nombre": "BOS alcista en 1M",
                        "Timestamp": current_timestamp,
                        "DistanciaBreakout": f"{(current_high - ultimo_swing_high_valor) / ultimo_swing_high_valor * 100:.2f}%",
                        "PrecioActualEnBreak": current_close
                    })
                    patrones_encontrados += 1

        # --- CHoCH Bajista (Bearish CHoCH) ---
        # Rompimiento por debajo del último swing low en tendencia alcista/lateral (cambio de carácter)
        if current_low < ultimo_swing_low_valor and tendencia_actual in ["Alcista", "Lateral"]:
            if (ultimo_swing_low_valor - current_low) > rango_significativo:
                if not confirmacion or current_close < ultimo_swing_low_valor:
                    señales.append({
                        "Type": "Sell",
                        "Level": ultimo_swing_low_valor,
                        "Reason": "CHoCH",
                        "Esquema": "CHoCH",
                        "DireccionEstructural": "bajista",
                        "TipoEstructura": "reversion",
                        "Confidence": "Alta",
                        "Categoria": "Estructura",
                        "Strategy": "BOS_CHOCH_M1",
                        "OrderBlockRelacionado": False,
                        "Nombre": "CHoCH bajista en 1M",
                        "Timestamp": current_timestamp,
                        "DistanciaBreakout": f"{(ultimo_swing_low_valor - current_low) / ultimo_swing_low_valor * 100:.2f}%",
                        "PrecioActualEnBreak": current_close
                    })
                    patrones_encontrados += 1

        # --- BOS Bajista (Bearish BOS) ---
        # Rompimiento por debajo del último swing low en tendencia bajista/lateral
        if current_low < ultimo_swing_low_valor and tendencia_actual in ["Bajista", "Lateral"]:
            if (ultimo_swing_low_valor - current_low) > rango_significativo:
                if not confirmacion or current_close < ultimo_swing_low_valor:
                    señales.append({
                        "Type": "Sell",
                        "Level": ultimo_swing_low_valor,
                        "Reason": "BOS",
                        "Esquema": "BOS",
                        "DireccionEstructural": "bajista",
                        "TipoEstructura": "continuacion",
                        "Confidence": "Alta",
                        "Categoria": "Estructura",
                        "Strategy": "BOS_CHOCH_M1",
                        "OrderBlockRelacionado": False,
                        "Nombre": "BOS bajista en 1M",
                        "Timestamp": current_timestamp,
                        "DistanciaBreakout": f"{(ultimo_swing_low_valor - current_low) / ultimo_swing_low_valor * 100:.2f}%",
                        "PrecioActualEnBreak": current_close
                    })
                    patrones_encontrados += 1

        # --- CHoCH Alcista (Bullish CHoCH) ---
        # Rompimiento por encima del último swing high en tendencia bajista/lateral (cambio de carácter)
        if current_high > ultimo_swing_high_valor and tendencia_actual in ["Bajista", "Lateral"]:
            if (current_high - ultimo_swing_high_valor) > rango_significativo:
                if not confirmacion or current_close > ultimo_swing_high_valor:
                    señales.append({
                        "Type": "Buy",
                        "Level": ultimo_swing_high_valor,
                        "Reason": "CHoCH",
                        "Esquema": "CHoCH",
                        "DireccionEstructural": "alcista",
                        "TipoEstructura": "reversion",
                        "Confidence": "Alta",
                        "Categoria": "Estructura",
                        "Strategy": "BOS_CHOCH_M1",
                        "OrderBlockRelacionado": False,
                        "Nombre": "CHoCH alcista en 1M",
                        "Timestamp": current_timestamp,
                        "DistanciaBreakout": f"{(current_high - ultimo_swing_high_valor) / ultimo_swing_high_valor * 100:.2f}%",
                        "PrecioActualEnBreak": current_close
                    })
                    patrones_encontrados += 1

    # Ordenar por timestamp descendente para tener los más recientes primero
    señales.sort(key=lambda x: x['Timestamp'], reverse=True)
    return señales


def generar_resumen_estructura(bos_choch):
    """
    Resume la estructura detectada en un formato BOS/CHoCH para mostrar.
    """
    resumen = {"bos": "none", "choch": "none"}
    for evento in bos_choch:
        if evento.get("Reason") == "BOS" and resumen["bos"] == "none":
            resumen["bos"] = evento.get("DireccionEstructural", "none")
        elif evento.get("Reason") == "CHoCH" and resumen["choch"] == "none":
            resumen["choch"] = evento.get("DireccionEstructural", "none")
    return resumen


def ejecutar_deteccion_completa(data, max_patrones_por_tipo=3, ignorar_proximidad=True):
    """
    Ejecuta la detección completa de todos los patrones disponibles.

    Args:
        data (pd.DataFrame): DataFrame con datos OHLC
        max_patrones_por_tipo (int): Número máximo de patrones a detectar por cada tipo
        ignorar_proximidad (bool): Si es True, ignora la restricción de proximidad al precio actual

    Returns:
        dict: Diccionario con todos los patrones detectados organizados por tipo
    """
    # Ejecutar detecciones
    fvg_resultados = detectar_fvg(data, max_patrones=max_patrones_por_tipo, ignorar_proximidad=ignorar_proximidad)
    bos_choch_resultados = detectar_bos_choch(data, max_patrones=max_patrones_por_tipo, ignorar_proximidad=ignorar_proximidad)

    # Construir resultados
    resultados = {
        "fvg": fvg_resultados,
        "bos_choch": bos_choch_resultados
    }

    # Resumen de tipos de patrones detectados
    total_patrones = len(fvg_resultados) + len(bos_choch_resultados)
    tipos_encontrados = []

    if fvg_resultados:
        tipos_encontrados.extend(list(set(p["tipo"] for p in fvg_resultados)))

    if bos_choch_resultados:
        tipos_encontrados.extend(list(set(f"{p['Esquema']}_{p['DireccionEstructural']}" for p in bos_choch_resultados)))

    resultados["resumen"] = {
        "total_patrones": total_patrones,
        "tipos_encontrados": tipos_encontrados
    }

    # 🔥 Agregamos resumen limpio para GUI
    resultados["resumen_estructura"] = generar_resumen_estructura(bos_choch_resultados)

    return resultados



def normalize_text(text: str) -> str:
    """Normaliza el texto para eliminar caracteres extraños y asegurar que esté en UTF-8."""
    if not isinstance(text, str):
        return text  # Si no es un string, devolverlo sin cambios
    return unicodedata.normalize("NFKD", text)
# Decorador para reintentos automáticos
def retry(max_retries=3, delay=5):
    def decorator(func):
        async def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    logging.error(f"Error en {func.__name__}: {e}. Reintento {attempt + 1}/{max_retries}")
                    if attempt < max_retries - 1:
                        await asyncio.sleep(delay)
                        continue
                    raise e
        return wrapper
    return decorator
# Clase para analizar datos en 30 minutos
class M30Analyzer:
    def __init__(self):
        self.lookback = 48  # Velas a analizar para 30 minutos
        self.trend_threshold = 5  # Nuevo umbral para confirmar la tendencia

    def get_trend(self, data):
        if len(data) < self.lookback:
            return 'Rango'

        highs = data['high'].tail(self.lookback).values
        lows = data['low'].tail(self.lookback).values

        higher_highs = 0
        higher_lows = 0
        lower_highs = 0
        lower_lows = 0

        for i in range(1, len(highs)):
            if highs[i] > highs[i-1]:
                higher_highs += 1
            if lows[i] > lows[i-1]:
                higher_lows += 1
            if highs[i] < highs[i-1]:
                lower_highs += 1
            if lows[i] < lows[i-1]:
                lower_lows += 1

        if higher_highs >= self.trend_threshold and higher_lows >= self.trend_threshold:
            return 'Alcista'
        elif lower_highs >= self.trend_threshold and lower_lows >= self.trend_threshold:
            return 'Bajista'
        else:
            return 'Rango'
    def identify_significant_levels(self, data):
        if len(data) < self.lookback:
            logging.warning(f"Datos insuficientes para analizar niveles en 30M. Velas disponibles: {len(data)}")
            return {'highs': [], 'lows': []}

        lookback = min(48, len(data))  # Analizar hasta 48 velas, o menos si no hay suficientes

        # Reemplaza el llamado a _calculate_levels por lógica válida
        highs = data['high'].tail(lookback).unique().tolist()
        lows = data['low'].tail(lookback).unique().tolist()
       
        def group_levels(levels, tolerance=0.0005):
            if not levels:
                logging.info("No hay niveles para agrupar.")
                return []
            levels.sort()
            grouped = [[levels[0]]]
            for i in range(1, len(levels)):
                if abs(levels[i] - grouped[-1][0]) <= tolerance:
                    grouped[-1].append(levels[i])
                else:
                    grouped.append([levels[i]])
            return [sum(group) / len(group) for group in grouped]

        significant_highs = group_levels(highs)
        significant_lows = group_levels(lows)

        if not significant_highs:
            recent_high = data['high'].tail(3).max()
            significant_highs = [recent_high]
            logging.info(f"Usando nivel alto reciente como respaldo: {recent_high}")
        if not significant_lows:
            recent_low = data['low'].tail(3).min()
            significant_lows = [recent_low]
            logging.info(f"Usando nivel bajo reciente como respaldo: {recent_low}")

        return {'highs': sorted(significant_highs, reverse=True)[:5], 'lows': sorted(significant_lows)[:5]}
# Clase para analizar datos en 5 minutos
class M5Analyzer:
    def __init__(self):
        self.lookback = 48  # Velas disponibles a analizar
        self.trend_lookback = 30  # Velas recientes a analizar para la tendencia
        self.trend_threshold = 5  # Umbral para confirmar la tendencia

    def get_trend(self, data):
        if len(data) < self.lookback:
            return 'Rango'

        highs = data['high'].tail(self.lookback).values
        lows = data['low'].tail(self.lookback).values

        higher_highs = 0
        higher_lows = 0
        lower_highs = 0
        lower_lows = 0

        # Analizar una ventana más reciente para la tendencia de 5M (ajustado)
        recent_highs = highs[-self.trend_lookback:]
        recent_lows = lows[-self.trend_lookback:]

        for i in range(1, len(recent_highs)):
            if recent_highs[i] > recent_highs[i-1]:
                higher_highs += 1
            if recent_lows[i] > recent_lows[i-1]:
                higher_lows += 1
            if recent_highs[i] < recent_highs[i-1]:
                lower_highs += 1
            if recent_lows[i] < recent_lows[i-1]:
                lower_lows += 1

        if higher_highs >= self.trend_threshold and higher_lows >= self.trend_threshold:
            return 'Alcista'
        elif lower_highs >= self.trend_threshold and lower_lows >= self.trend_threshold:
            return 'Bajista'
        else:
            return 'Rango'

    def validate_concepts(self, data, tested_levels, trend):
        """ 
        Valida múltiples señales en 5M: rebotes, rompimientos y falsos rompimientos.
        Devuelve una lista de todas las señales encontradas.
        """
        señales_validas = []

        if len(data) < 3 or not tested_levels:
            logging.warning("Datos insuficientes para analizar conceptos en 5M.")
            return []

        previous_candle = data.iloc[-2]
        last_candle = data.iloc[-1]
        tolerance = abs(data['high'].max() - data['low'].min()) * 0.01

        logging.info(f"Evaluando señales en 5M. Niveles testeados: {tested_levels}, Tendencia actual: {trend}")

        for level in tested_levels:
            close_price = last_candle['close']
            high_price = last_candle['high']
            low_price = last_candle['low']

            # Rebote Alcista
            if trend == 'Alcista' and low_price <= level + tolerance and close_price > level and close_price > last_candle['open']:
                logging.info(f"Rebote Alcista detectado en nivel {level}")
                señales_validas.append({'Type': 'Buy', 'Level': level, 'Reason': 'Rebote 5M', 'Confidence': 'Alta'})

            # Rebote Bajista
            if trend == 'Bajista' and high_price >= level - tolerance and close_price < level and close_price < last_candle['open']:
                logging.info(f"Rebote Bajista detectado en nivel {level}")
                señales_validas.append({'Type': 'Sell', 'Level': level, 'Reason': 'Rebote 5M', 'Confidence': 'Alta'})

            # Rompimiento Alcista
            if trend == 'Alcista' and close_price > level and previous_candle['close'] <= level and close_price > last_candle['open']:
                logging.info(f"Rompimiento Alcista confirmado en nivel {level}")
                señales_validas.append({'Type': 'Buy', 'Level': level, 'Reason': 'Rompimiento 5M', 'Confidence': 'Alta'})

            # Rompimiento Bajista
            if trend == 'Bajista' and close_price < level and previous_candle['close'] >= level and close_price < last_candle['open']:
                logging.info(f"Rompimiento Bajista confirmado en nivel {level}")
                señales_validas.append({'Type': 'Sell', 'Level': level, 'Reason': 'Rompimiento 5M', 'Confidence': 'Alta'})

            # Falso Rompimiento Alcista
            if trend == 'Bajista' and previous_candle['close'] > level and high_price > level and close_price < level and close_price < last_candle['open']:
                logging.info(f"Falso Rompimiento Alcista detectado en nivel {level}")
                señales_validas.append({'Type': 'Sell', 'Level': level, 'Reason': 'Falso Rompimiento Alcista 5M', 'Confidence': 'Media'})

            # Falso Rompimiento Bajista
            if trend == 'Alcista' and previous_candle['close'] < level and low_price < level and close_price > level and close_price > last_candle['open']:
                logging.info(f"Falso Rompimiento Bajista detectado en nivel {level}")
                señales_validas.append({'Type': 'Buy', 'Level': level, 'Reason': 'Falso Rompimiento Bajista 5M', 'Confidence': 'Media'})

        if not señales_validas:
            logging.info("No se detectaron señales válidas en 5M.")

        return señales_validas
    def find_tested_levels(self, data):
        """Identifica niveles frecuentemente testeados con margen dinámico."""
        if len(data) < self.lookback:
            return []

        closes = data['close'].tail(self.lookback)
        high = data['high'].tail(self.lookback).max()
        low = data['low'].tail(self.lookback).min()
        margin = (high - low) * 0.01  # MEJORA 3: Margen dinámico para detectar niveles testeados

        tested_levels = []
        for level in set(closes):
            interactions = sum(abs(closes - level) < margin)
            if interactions >= 3:
                tested_levels.append(level)
    
        # Fallback: Si no se encuentran niveles testeados
        if not tested_levels:
            tested_levels.append(high)
            tested_levels.append(low)
        
        return sorted(tested_levels)
    
# Clase para analizar datos en 1 minuto
class M1Analyzer:
    def __init__(self):
        self.lookback = 60  # Velas a analizar para 1 minuto
        self.trend_lookback = 20  # Velas para tendencia 1M

    def get_trend(self, data):
        if len(data) < self.trend_lookback:
            return 'Rango'

        highs = data['high'].tail(self.trend_lookback).values
        lows = data['low'].tail(self.trend_lookback).values

        higher_highs = 0
        higher_lows = 0
        lower_highs = 0
        lower_lows = 0

        for i in range(1, len(highs)):
            if highs[i] > highs[i - 1]:
                higher_highs += 1
            if lows[i] > lows[i - 1]:
                higher_lows += 1
            if highs[i] < highs[i - 1]:
                lower_highs += 1
            if lows[i] < lows[i - 1]:
                lower_lows += 1

        if higher_highs >= 3 and higher_lows >= 3:
            return 'Alcista'
        elif lower_highs >= 3 and lower_lows >= 3:
            return 'Bajista'
        else:
            return 'Rango'

   
    def analyze_price_action(self, data, level, trend, validated_levels_5m=None, is_flexible=False):
        """
        Analiza la acción del precio en 1M para generar señales basadas en rebotes, rompimientos,
        flips, o testeos frecuentes. Priorizando el primer concepto encontrado.
        """
        if len(data) < 3:
            logging.warning("Datos insuficientes para analizar el precio en 1M.")
            return None

        last_candle = data.iloc[-1]
        previous_candle = data.iloc[-2]
        tolerance = 0.0005  # Incrementar tolerancia para detectar interacciones

        if is_flexible or not validated_levels_5m:
            logging.info("Modo flexible activado: Analizando solo en 1M.")

            # Confirmación de continuación alcista
            if trend == 'Alcista' and last_candle['close'] > level and last_candle['open'] < level:
                logging.info("Confirmación de continuación alcista: Rompimiento en 1M.")
                return {'Type': 'Buy', 'Level': level, 'Reason': 'Rompimiento Alcista en 1M'}

            # Confirmación de continuación bajista
            if trend == 'Bajista' and last_candle['close'] < level and last_candle['open'] > level:
                logging.info("Confirmación de continuación bajista: Rompimiento en 1M.")
                return {'Type': 'Sell', 'Level': level, 'Reason': 'Rompimiento Bajista en 1M'}

            # Rebote alcista
            if trend == 'Alcista' and abs(last_candle['low'] - level) <= tolerance and last_candle['close'] > last_candle['open']:
                logging.info("Confirmación de rebote alcista en 1M.")
                return {'Type': 'Buy', 'Level': level, 'Reason': 'Rebote Alcista en 1M'}

            # Rebote bajista
            if trend == 'Bajista' and abs(last_candle['high'] - level) <= tolerance and last_candle['close'] < last_candle['open']:
                logging.info("Confirmación de rebote bajista en 1M.")
                return {'Type': 'Sell', 'Level': level, 'Reason': 'Rebote Bajista en 1M'}

        else:
            # Validar si el nivel actual está dentro de los niveles validados en 5M
            if level not in validated_levels_5m:
                logging.info("Nivel no validado por 5M, se descarta en análisis 1M.")
                return None

            # Confirmación del rompimiento con validación previa
            if trend == 'Alcista' and previous_candle['close'] < level and last_candle['close'] > level:
                return {'Type': 'Buy', 'Level': level, 'Reason': 'Rompimiento Alcista Validado'}

            if trend == 'Bajista' and previous_candle['close'] > level and last_candle['close'] < level:
                return {'Type': 'Sell', 'Level': level, 'Reason': 'Rompimiento Bajista Validado'}

        
           
            # **Detectar flips (resistencia a soporte o viceversa)**
            if last_candle['close'] > level and previous_candle['close'] < level:
                logging.info("Confirmación de Flip Zone: Resistencia rota en 1M.")
                return {'Type': 'Buy', 'Level': level, 'Reason': 'Flip Zone - Resistencia Rota', 'Confidence': 'Media'}

            elif last_candle['close'] < level and previous_candle['close'] > level:
                logging.info("Confirmación de Flip Zone: Soporte roto en 1M.")
                return {'Type': 'Sell', 'Level': level, 'Reason': 'Flip Zone - Soporte Roto', 'Confidence': 'Media'}

        # **Validaciones cruzadas con 5M**
        if validated_levels_5m:
            logging.info("Validaciones en 5M detectadas: Analizando en base a niveles validados.")
            if last_candle['close'] > level and last_candle['low'] <= level + tolerance:
                logging.info("Confirmación de Rebote Alcista en 1M.")
                return {'Type': 'Buy', 'Level': level, 'Reason': 'Rebote Alcista', 'Confidence': 'Alta'}

            elif last_candle['close'] < level and last_candle['high'] >= level - tolerance:
                logging.info("Confirmación de Rebote Bajista en 1M.")
                return {'Type': 'Sell', 'Level': level, 'Reason': 'Rebote Bajista', 'Confidence': 'Alta'}

        # Entrada por Testeo Frecuente (si no se validó nada en 5M o se está en modo flexible)
        if not validated_levels_5m or is_flexible:
            interactions = sum(abs(data['close'].tail(self.lookback) - level) < tolerance)
            if interactions >= 3:  # Si el nivel ha sido testeado al menos 3 veces
                logging.info(f"Nivel testeado encontrado con {interactions} interacciones. Nivel: {level}")
                if trend == 'Alcista' and last_candle['close'] > level:
                    logging.info("Señal por Testeo Frecuente Alcista en 1M.")
                    return {'Type': 'Buy', 'Level': level, 'Reason': 'Testeo Frecuente', 'Confidence': 'Baja'}
                elif trend == 'Bajista' and last_candle['close'] < level:
                    logging.info("Señal por Testeo Frecuente Bajista en 1M.")
                    return {'Type': 'Sell', 'Level': level, 'Reason': 'Testeo Frecuente', 'Confidence': 'Baja'}
        return None
    def find_tested_levels(self, data, current_price):
        """
        Identifica niveles testeados cercanos al precio actual en 1M.
        """
        if len(data) < self.lookback:
            return []

        closes = data['close'].tail(self.lookback)  # Últimos cierres de las velas
        tested_levels = []

        # Buscar niveles frecuentemente testeados
        for level in set(closes):
            interactions = sum(abs(closes - level) < 0.0001)  # Considera un margen para identificar testeos
            if interactions >= 3:  # Si ha sido testeado al menos 3 veces
                tested_levels.append(level)
            
        # Ordenar los niveles en función de la cercanía al precio actual
        tested_levels = sorted(tested_levels, key=lambda x: abs(x - current_price))

        return tested_levels
    def analyze_price_action(self, data, level, trend, validated_levels_5m=None, is_flexible=False):
        if len(data) < 3:
            logging.warning("Datos insuficientes para analizar el precio en 1M.")
            return None
    
class FlexibleM5Analyzer:
    """
    Clase para el análisis de niveles de soporte/resistencia y su comportamiento
    en el timeframe de 5 minutos, incluyendo identificación de niveles,
    polaridad, rompimientos y retesteos.
    """
    def __init__(self):
        self.levels_df = pd.DataFrame()
        
        # Parámetros definidos directamente en la clase, sin usar 'config'
        self.min_break_percentage = 0.001 # 0.1% del precio del nivel
        self.min_body_ratio_breakout = 0.7 # Porcentaje mínimo del cuerpo de la vela para un rompimiento fuerte
        self.max_wick_ratio_breakout = 0.3 # Porcentaje máximo de mecha contraria al rompimiento
        self.breakout_lookback_candles = 20 # Cuántas velas hacia atrás buscar rompimientos
        self.polarity_check_candles = 5  # Cuántas velas después del breakout revisar para cambio de polaridad
        self.strong_breakout_lookback_candles = 20 # Cuántas velas hacia atrás buscar rompimientos fuertes
        self.retest_lookback_candles = 10 # Cuántas velas después del breakout buscar retests
        self.retest_tolerance = 0.0002 # Tolerancia de proximidad al nivel para un retest (ej: 0.02%)
        self.continuation_check_candles = 3 # Cuántas velas después del retest buscar continuación
        

    def identify_key_levels(self, data: pd.DataFrame):
        """
        Identifica niveles clave (pivotes, flips, S/R tradicionales) en los datos de velas.
        Asegura el uso consistente de .iloc para acceso posicional y maneja el índice de tiempo.
        """
        levels = []

        if data.empty or len(data) < 5:
            logging.warning("FlexibleM5Analyzer: Datos insuficientes para identificar niveles clave. Se requieren al menos 5 velas.")
            self.levels_df = pd.DataFrame(columns=['Date', 'Level', 'Type', 'Trend'])
            return self.levels_df

        highs = data['high'].rolling(window=3, center=True).max()
        lows = data['low'].rolling(window=3, center=True).min()

        start_index = 2
        end_index = len(data) - 2 

        if start_index >= end_index:
            logging.warning("FlexibleM5Analyzer: Rango de bucle no válido para la identificación de niveles clave. Datos demasiado cortos.")
            self.levels_df = pd.DataFrame(columns=['Date', 'Level', 'Type', 'Trend'])
            return self.levels_df

        for i in range(start_index, end_index):
            # Pivotes Highs/Lows
            # Se ha añadido np.isnan check para robustez
            if not np.isnan(highs.iloc[i]) and data['high'].iloc[i] == highs.iloc[i]:
                levels.append({'Date': data.index[i], 'Level': highs.iloc[i], 'Type': 'High (A)', 'Trend': 'N/A'})
            elif not np.isnan(lows.iloc[i]) and data['low'].iloc[i] == lows.iloc[i]:
                levels.append({'Date': data.index[i], 'Level': lows.iloc[i], 'Type': 'Low (B)', 'Trend': 'N/A'})

            # Flips
            if (data['close'].iloc[i] > data['close'].iloc[i - 1] and
                data['close'].iloc[i] > data['close'].iloc[i + 1]):
                if data['close'].iloc[i - 1] > data['close'].iloc[i - 2]:
                    levels.append({'Date': data.index[i], 'Level': data['close'].iloc[i], 'Type': 'Flip AA+', 'Trend': 'Bullish'})
                else:
                    levels.append({'Date': data.index[i], 'Level': data['close'].iloc[i], 'Type': 'Flip BA+', 'Trend': 'Bullish'})
            elif (data['close'].iloc[i] < data['close'].iloc[i - 1] and
                  data['close'].iloc[i] < data['close'].iloc[i + 1]):
                if data['close'].iloc[i - 1] < data['close'].iloc[i - 2]:
                    levels.append({'Date': data.index[i], 'Level': data['close'].iloc[i], 'Type': 'Flip BB+', 'Trend': 'Bearish'})
                else:
                    levels.append({'Date': data.index[i], 'Level': data['close'].iloc[i], 'Type': 'Flip AB+', 'Trend': 'Bearish'})

            # AB-/BA-
            if (data['high'].iloc[i] > data['high'].iloc[i - 1] and data['high'].iloc[i] > data['high'].iloc[i + 1] and
                data['close'].iloc[i] < data['close'].iloc[i - 1] and data['close'].iloc[i] < data['close'].iloc[i + 1]):
                levels.append({'Date': data.index[i], 'Level': data['high'].iloc[i], 'Type': 'AB-', 'Trend': 'Bearish'})

            if (data['low'].iloc[i] < data['low'].iloc[i - 1] and data['low'].iloc[i] < data['low'].iloc[i + 1] and
                data['close'].iloc[i] > data['close'].iloc[i - 1] and data['close'].iloc[i] > data['close'].iloc[i + 1]):
                levels.append({'Date': data.index[i], 'Level': data['low'].iloc[i], 'Type': 'BA-', 'Trend': 'Bullish'})

            # S/R tradicionales
            if not np.isnan(highs.iloc[i]) and data['high'].iloc[i] == highs.iloc[i]:
                levels.append({'Date': data.index[i], 'Level': highs.iloc[i], 'Type': 'Resistance', 'Trend': 'N/A'})
            elif not np.isnan(lows.iloc[i]) and data['low'].iloc[i] == lows.iloc[i]:
                levels.append({'Date': data.index[i], 'Level': lows.iloc[i], 'Type': 'Support', 'Trend': 'N/A'})
        
        if levels:
            self.levels_df = pd.DataFrame(levels).drop_duplicates(subset=['Date', 'Level', 'Type']).sort_values(by='Date').reset_index(drop=True)
            logging.info(f"FlexibleM5Analyzer: Identificados {len(self.levels_df)} niveles clave.")
        else:
            self.levels_df = pd.DataFrame(columns=['Date', 'Level', 'Type', 'Trend'])
            logging.warning("FlexibleM5Analyzer: No se identificaron niveles clave.")
        
        return self.levels_df

    def _is_strong_breakout(self, candle: pd.Series, level: float, direction: str) -> bool:
        """
        Verifica si una vela representa un rompimiento "fuerte" de un nivel.
        """
        body_size = abs(candle['close'] - candle['open'])
        
        # Usar self.min_break_percentage directamente
        min_break_percentage = self.min_break_percentage 
        
        total_range = (candle['high'] - candle['low'])
        if total_range == 0:
            return False

        if direction == 'up':
            if candle['close'] > level and (candle['close'] - level) > level * min_break_percentage:
                # Usar self.min_body_ratio_breakout y self.max_wick_ratio_breakout directamente
                if body_size / total_range > self.min_body_ratio_breakout:
                    if (candle['high'] - candle['close']) / body_size < self.max_wick_ratio_breakout:
                        return True
        elif direction == 'down':
            if candle['close'] < level and (level - candle['close']) > level * min_break_percentage:
                # Usar self.min_body_ratio_breakout y self.max_wick_ratio_breakout directamente
                if body_size / total_range > self.min_body_ratio_breakout:
                    if (candle['open'] - candle['low']) / body_size < self.max_wick_ratio_breakout:
                        return True
        return False

    def _find_breakouts(self, data: pd.DataFrame, level_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Encuentra rompimientos de un nivel dado.
        """
        level = level_info['Level']
        level_type = level_info['Type']
        breakouts = []
        
        # Usar self.breakout_lookback_candles directamente
        lookback_period = self.breakout_lookback_candles 
        start_idx = max(0, len(data) - lookback_period)

        for i in range(start_idx, len(data)):
            candle = data.iloc[i]
            
            is_break = False
            direction = 'none'

            if level_type == 'Support':
                if candle['close'] < level:
                    is_break = True
                    direction = 'down'
            elif level_type == 'Resistance':
                if candle['close'] > level:
                    is_break = True
                    direction = 'up'
            
            if is_break and self._is_strong_breakout(candle, level, direction):
                breakouts.append({
                    'index': i,
                    'close_price': candle['close'],
                    'direction': direction,
                    'timestamp': data.index[i]
                })
        logging.debug(f"FlexibleM5Analyzer: Encontrados {len(breakouts)} rompimientos para nivel {level}.")
        return breakouts
    
    def _check_polarity_change(self, data: pd.DataFrame, level_info: Dict[str, Any], breakout: Dict[str, Any]) -> Optional[str]:
        """
        Verifica si un nivel cambia su polaridad después de un rompimiento.
        """
        level = level_info['Level']
        original_type = level_info['Type']
        breakout_index = breakout['index']
        
        # Usar self.polarity_check_candles directamente
        post_breakout_lookforward = self.polarity_check_candles 
        
        start_check_idx = breakout_index + 1
        end_check_idx = min(len(data), breakout_index + 1 + post_breakout_lookforward)

        if start_check_idx >= end_check_idx:
            return None

        if breakout['direction'] == 'down' and original_type == 'Support':
            for i in range(start_check_idx, end_check_idx):
                candle = data.iloc[i]
                is_retest_and_rejection = candle['high'] >= level and candle['close'] < level
                no_significant_close_above = not any(data.iloc[j]['close'] > level for j in range(breakout_index + 1, i + 1))
                
                if is_retest_and_rejection and no_significant_close_above:
                    logging.debug(f"FlexibleM5Analyzer: Polaridad cambiada de Soporte a Resistencia en {level}.")
                    return 'SupportToResistance'
        
        elif breakout['direction'] == 'up' and original_type == 'Resistance':
            for i in range(start_check_idx, end_check_idx):
                candle = data.iloc[i]
                is_retest_and_rejection = candle['low'] <= level and candle['close'] > level
                no_significant_close_below = not any(data.iloc[j]['close'] < level for j in range(breakout_index + 1, i + 1))
                
                if is_retest_and_rejection and no_significant_close_below:
                    logging.debug(f"FlexibleM5Analyzer: Polaridad cambiada de Resistencia a Soporte en {level}.")
                    return 'ResistanceToSupport'
                            
        return None

    def _identify_scheme(self, data: pd.DataFrame, level_info: Dict[str, Any], breakout: Dict[str, Any], polarity_change_type: Optional[str]) -> str:
        """
        Identifica un esquema basado en el rompimiento y cambio de polaridad o continuación.
        """
        level_type = level_info['Type']
        
        if polarity_change_type == 'SupportToResistance':
            return "Soporte_Roto_a_Resistencia"
        elif polarity_change_type == 'ResistanceToSupport':
            return "Resistencia_Rota_a_Soporte"
        
        if breakout['direction'] == 'down' and level_type == 'Support':
            return "Rompimiento_Bajista_Soporte"
        elif breakout['direction'] == 'up' and level_type == 'Resistance':
            return "Rompimiento_Alcista_Resistencia"
            
        return "Esquema_Desconocido"

    def _find_strong_breakouts(self, data: pd.DataFrame, level_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Encuentra rompimientos fuertes, que son el primer paso para una continuación.
        """
        level = level_info['Level']
        level_type = level_info['Type']
        strong_breakouts = []
        
        # Usar self.strong_breakout_lookback_candles directamente
        lookback_period = self.strong_breakout_lookback_candles 
        start_idx = max(0, len(data) - lookback_period)

        for i in range(start_idx, len(data)):
            candle = data.iloc[i]
            
            is_break = False
            direction = 'none'

            if level_type == 'Support' and candle['close'] < level:
                is_break = True
                direction = 'down'
            elif level_type == 'Resistance' and candle['close'] > level:
                is_break = True
                direction = 'up'
            
            if is_break and self._is_strong_breakout(candle, level, direction):
                strong_breakouts.append({
                    'index': i,
                    'close_price': candle['close'],
                    'direction': direction,
                    'timestamp': data.index[i]
                })
        logging.debug(f"FlexibleM5Analyzer: Encontrados {len(strong_breakouts)} rompimientos fuertes para nivel {level}.")
        return strong_breakouts

    def _find_retests(self, data: pd.DataFrame, level_info: Dict[str, Any], breakout: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Encuentra retesteos del nivel después de un rompimiento fuerte.
        """
        level = level_info['Level']
        breakout_index = breakout['index']
        retests = []
        
        # Usar self.retest_lookback_candles y self.retest_tolerance directamente
        retest_lookback_candles = self.retest_lookback_candles 
        retest_tolerance = self.retest_tolerance 
        
        start_retest_idx = breakout_index + 1
        end_retest_idx = min(len(data), breakout_index + 1 + retest_lookback_candles)

        if start_retest_idx >= end_retest_idx:
            return retests

        for i in range(start_retest_idx, end_retest_idx):
            candle = data.iloc[i]
            
            if breakout['direction'] == 'down':
                if candle['high'] >= level and abs(candle['high'] - level) <= level * retest_tolerance:
                    if candle['close'] < level:
                        retests.append({
                            'index': i,
                            'close_price': candle['close'],
                            'direction': 'retest_down',
                            'timestamp': data.index[i]
                        })
            elif breakout['direction'] == 'up':
                if candle['low'] <= level and abs(candle['low'] - level) <= level * retest_tolerance:
                    if candle['close'] > level:
                        retests.append({
                            'index': i,
                            'close_price': candle['close'],
                            'direction': 'retest_up',
                            'timestamp': data.index[i]
                        })
        logging.debug(f"FlexibleM5Analyzer: Encontrados {len(retests)} retests para nivel {level} y breakout en {data.index[breakout_index]}.")
        return retests

    def _check_continuation(self, data: pd.DataFrame, level_info: Dict[str, Any], breakout: Dict[str, Any], retest: Dict[str, Any]) -> bool:
        """
        Verifica si hay una continuación de la tendencia después de un retest.
        """
        retest_index = retest['index']
        breakout_direction = breakout['direction']
        level = level_info['Level']
        
        # Usar self.continuation_check_candles directamente
        continuation_candles = self.continuation_check_candles 
        
        start_check_idx = retest_index + 1
        end_check_idx = min(len(data), retest_index + 1 + continuation_candles)
        
        if start_check_idx >= end_check_idx:
            return False

        has_continued = False
        if breakout_direction == 'down':
            for i in range(start_check_idx, end_check_idx):
                if data.iloc[i]['close'] < level:
                    has_continued = True
                    break
        elif breakout_direction == 'up':
            for i in range(start_check_idx, end_check_idx):
                if data.iloc[i]['close'] > level:
                    has_continued = True
                    break
        
        logging.debug(f"FlexibleM5Analyzer: Continuación {has_continued} para retest en {data.index[retest_index]}.")
        return has_continued
    
    def analyze_polarity(self, data: pd.DataFrame, levels: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Analiza el cambio de polaridad de los niveles (resistencia a soporte, o viceversa)
        después de un rompimiento.
        """
        polarities = []
        if data.empty or not levels:
            logging.warning("FlexibleM5Analyzer: Datos o niveles vacíos para analyze_polarity.")
            return polarities

        for level in levels:
            breakouts = self._find_breakouts(data, level)
            for breakout in breakouts:
                polarity_change_type = self._check_polarity_change(data, level, breakout)
                if polarity_change_type:
                    scheme = self._identify_scheme(data, level, breakout, polarity_change_type)
                    polarities.append({
                        'Level': level['Level'],
                        'original_type': level['Type'],
                        'new_type': 'Resistance' if level['Type'] == 'Support' else 'Support',
                        'breakout_index': breakout['index'],
                        'direction': 'Sell' if level['Type'] == 'Support' else 'Buy',
                        'scheme': scheme,
                        'timestamp': data.index[breakout['index']]
                    })
        logging.info(f"FlexibleM5Analyzer: {len(polarities)} cambios de polaridad detectados.")
        return polarities

    def analyze_breakout_support(self, data: pd.DataFrame, levels: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Analiza los rompimientos y retesteos de niveles de soporte/resistencia
        para identificar continuaciones.
        """
        continuation_signals = []
        if data.empty or not levels:
            logging.warning("FlexibleM5Analyzer: Datos o niveles vacíos para analyze_breakout_support.")
            return continuation_signals

        for level in levels:
            strong_breakouts = self._find_strong_breakouts(data, level)
            for breakout in strong_breakouts:
                retests = self._find_retests(data, level, breakout)
                for retest in retests:
                    if self._check_continuation(data, level, breakout, retest):
                        scheme = self._identify_scheme(data, level, breakout, None)
                        continuation_signals.append({
                            'Level': level['Level'],
                            'original_type': level['Type'],
                            'breakout_index': breakout['index'],
                            'retest_index': retest['index'],
                            'direction': 'Buy' if level['Type'] == 'Resistance' else 'Sell',
                            'scheme': scheme,
                            'timestamp': data.index[retest['index']]
                        })
        logging.info(f"FlexibleM5Analyzer: {len(continuation_signals)} señales de continuación (rompimiento/retest) detectadas.")
        return continuation_signals

    def detect_polarity_change(self, row: dict, previous_level: Optional[dict]) -> bool:
        """
        Detecta si hay un cambio de polaridad entre el nivel actual y el anterior.
        """
        if previous_level is None:
            return False
        
        return (row['Type'] == 'Resistance' and previous_level['Type'] == 'Support') or \
               (row['Type'] == 'Support' and previous_level['Type'] == 'Resistance')

    def identify_scheme_falso_rompimiento(self, current_row: dict, next_candle: Optional[pd.Series], previous_level: Optional[dict]) -> Optional[str]:
        """
        Identifica el esquema de "Falso Rompimiento" (FR) o "Continuación"
        basado en la vela siguiente y el cambio de polaridad.
        """
        if next_candle is None:
            return None
        
        close = next_candle['close'] 
        level_price = current_row['Level']
        level_type = current_row['Type']
        
        polarity_change_detected = self.detect_polarity_change(current_row, previous_level)
        
        if polarity_change_detected:
            if level_type == 'Resistance' and close < level_price:
                return 'FR_Alcista_Fallido'
            elif level_type == 'Support' and close > level_price:
                return 'FR_Bajista_Fallido'
        
        return 'Nivel_Relevante'

    def analyze_5m_levels(self, candles_df: pd.DataFrame) -> pd.DataFrame:
        """
        Analiza los niveles de 5M y los enriquece con información de esquema
        de falso rompimiento/continuación.
        """
        enriched_levels = []
        if self.levels_df.empty:
            logging.warning("FlexibleM5Analyzer: No hay niveles identificados para analizar en 5M.")
            return pd.DataFrame(columns=['Date', 'Level', 'Type', 'polarityChange', 'scheme', 'timestamp'])

        for i, row in self.levels_df.iterrows():
            level_time = row['Date']
            
            next_candle_candidates = candles_df[candles_df.index > level_time]
            next_row = next_candle_candidates.iloc[0] if not next_candle_candidates.empty else None
            
            previous_level = self.levels_df.iloc[i-1].to_dict() if i > 0 else None
            
            polarity_change_for_level = self.detect_polarity_change(row.to_dict(), previous_level)
            
            scheme = self.identify_scheme_falso_rompimiento(row.to_dict(), next_row, previous_level)
            
            enriched_levels.append({
                'Date': row['Date'],
                'Level': row['Level'],
                'Type': row['Type'],
                'polarityChange': polarity_change_for_level,
                'scheme': scheme,
                'timestamp': row['Date']
            })
        logging.info(f"FlexibleM5Analyzer: Enriquecidos {len(enriched_levels)} niveles con esquemas de falso rompimiento.")
        return pd.DataFrame(enriched_levels)

    def analyze(self, data: pd.DataFrame) -> List[Dict[str, Any]]:
        """Análisis completo en 5M con salida unificada de señales/esquemas."""
        
        
        self.identify_key_levels(data)
        
        if self.levels_df.empty:
            logging.warning("FlexibleM5Analyzer: No hay niveles clave identificados. Saltando análisis de polaridad y breakout.")
            return []

        levels_as_list = self.levels_df.to_dict('records')
        
        polarity_analysis = self.analyze_polarity(data, levels_as_list)
        
        breakout_analysis = self.analyze_breakout_support(data, levels_as_list)
        
        enriched_levels_df = self.analyze_5m_levels(data)
        false_breakout_analysis = enriched_levels_df.to_dict('records')

        esquemas_unificados: List[Dict[str, Any]] = []

        for item in polarity_analysis:
            esquemas_unificados.append({
                'Level': item['Level'],
                'scheme': item['scheme'],
                'direction': item['direction'],
                'source': 'Polarity_5m',
                'timestamp': item['timestamp']
            })

        for item in breakout_analysis:
            esquemas_unificados.append({
                'Level': item['Level'],
                'scheme': item['scheme'],
                'direction': item['direction'],
                'source': 'BreakoutRetest_5m',
                'timestamp': item['timestamp']
            })
        
        for item in false_breakout_analysis:
            esquemas_unificados.append({
                'Level': item['Level'],
                'scheme': item['scheme'],
                'direction': item.get('Type', 'N/A'),
                'source': 'FalseBreakout_5m',
                'timestamp': item['timestamp']
            })
            
        
        return esquemas_unificados

class FlexibleM1Analyzer:
    """
    Clase para el análisis de niveles clave y patrones específicos en el timeframe de 1 minuto,
    combinando con esquemas de timeframes mayores.
    """
    def __init__(self):
        self.levels_df = pd.DataFrame()
        # Parámetros definidos directamente en la clase, sin usar 'config'
        self.proximity_threshold_5m = 0.0006 # Umbral de proximidad para confirmar esquemas de 5M en 1M
        

    def identify_key_levels(self, data: pd.DataFrame) -> List[Dict[str, Any]]:
        """
        Identifica niveles clave (Flips, Altos/Bajos, AB-/BA-, soportes y resistencias) en 1M.
        Asegura el uso consistente de .iloc para acceso posicional y maneja el índice de tiempo.
        """
        levels = []

        # Necesitamos al menos 3 velas para rolling(window=3) y 5 para i-2 y i+2 de forma segura
        if data.empty or len(data) < 5:
            logging.warning("FlexibleM1Analyzer: Datos insuficientes para identificar niveles clave (1M). Se requieren al menos 5 velas.")
            self.levels_df = pd.DataFrame(columns=['Date', 'Level', 'Type', 'Trend'])
            return self.levels_df.to_dict('records')

        highs = data['high'].rolling(window=3, center=True).max()
        lows = data['low'].rolling(window=3, center=True).min()

        # El rango del bucle debe asegurar que los accesos como i-2 y i+2 sean válidos.
        # i-2 requiere i >= 2. i+2 requiere i <= len(data) - 3.
        start_index = 2
        end_index = len(data) - 2 # Exclusivo, así que el último índice procesado es len(data) - 3

        if start_index >= end_index:
            logging.warning("FlexibleM1Analyzer: Rango de bucle no válido para la identificación de niveles clave (1M). Datos demasiado cortos.")
            self.levels_df = pd.DataFrame(columns=['Date', 'Level', 'Type', 'Trend'])
            return self.levels_df.to_dict('records')

        for i in range(start_index, end_index):
            # Pivotes Highs/Lows
            if data['high'].iloc[i] == highs.iloc[i]:
                levels.append({'Date': data.index[i], 'Level': highs.iloc[i], 'Type': 'High (A)', 'Trend': 'N/A'})
            elif data['low'].iloc[i] == lows.iloc[i]:
                levels.append({'Date': data.index[i], 'Level': lows.iloc[i], 'Type': 'Low (B)', 'Trend': 'N/A'})

            # Flips
            if (data['close'].iloc[i] > data['close'].iloc[i - 1] and
                data['close'].iloc[i] > data['close'].iloc[i + 1]):
                if data['close'].iloc[i - 1] > data['close'].iloc[i - 2]:
                    levels.append({'Date': data.index[i], 'Level': data['close'].iloc[i], 'Type': 'Flip AA+', 'Trend': 'Bullish'})
                else:
                    levels.append({'Date': data.index[i], 'Level': data['close'].iloc[i], 'Type': 'Flip BA+', 'Trend': 'Bullish'})
            elif (data['close'].iloc[i] < data['close'].iloc[i - 1] and
                  data['close'].iloc[i] < data['close'].iloc[i + 1]):
                if data['close'].iloc[i - 1] < data['close'].iloc[i - 2]:
                    levels.append({'Date': data.index[i], 'Level': data['close'].iloc[i], 'Type': 'Flip BB+', 'Trend': 'Bearish'})
                else:
                    levels.append({'Date': data.index[i], 'Level': data['close'].iloc[i], 'Type': 'Flip AB+', 'Trend': 'Bearish'})

            # AB- y BA-
            if (data['high'].iloc[i] > data['high'].iloc[i - 1] and data['high'].iloc[i] > data['high'].iloc[i + 1] and
                data['close'].iloc[i] < data['close'].iloc[i - 1] and data['close'].iloc[i] < data['close'].iloc[i + 1]):
                levels.append({'Date': data.index[i], 'Level': data['high'].iloc[i], 'Type': 'AB-', 'Trend': 'Bearish'})
            if (data['low'].iloc[i] < data['low'].iloc[i - 1] and data['low'].iloc[i] < data['low'].iloc[i + 1] and
                data['close'].iloc[i] > data['close'].iloc[i - 1] and data['close'].iloc[i] > data['close'].iloc[i + 1]):
                levels.append({'Date': data.index[i], 'Level': data['low'].iloc[i], 'Type': 'BA-', 'Trend': 'Bullish'})

            # S/R tradicionales (usando los mismos criterios de highs/lows)
            if data['high'].iloc[i] == highs.iloc[i]:
                levels.append({'Date': data.index[i], 'Level': highs.iloc[i], 'Type': 'Resistance', 'Trend': 'N/A'})
            elif data['low'].iloc[i] == lows.iloc[i]:
                levels.append({'Date': data.index[i], 'Level': lows.iloc[i], 'Type': 'Support', 'Trend': 'N/A'})

        # Eliminar duplicados y ordenar por fecha
        if levels:
            self.levels_df = pd.DataFrame(levels).drop_duplicates(subset=['Date', 'Level', 'Type']).sort_values(by='Date').reset_index(drop=True)
            logging.info(f"FlexibleM1Analyzer: Identificados {len(self.levels_df)} niveles clave en 1M.")
        else:
            self.levels_df = pd.DataFrame(columns=['Date', 'Level', 'Type', 'Trend'])
            logging.warning("FlexibleM1Analyzer: No se identificaron niveles clave en 1M.")

        return self.levels_df.to_dict('records') # Devuelve como lista de diccionarios

    def analyze_pullbacks(self, data: pd.DataFrame, levels: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Detecta 'Pullbacks'."""
        pullbacks = []
        if data.empty or not levels or len(data) < 2:
            return pullbacks

        for level in levels:
            for i in range(len(data) - 1): # Bucle hasta la penúltima vela para acceder a i+1
                if data['close'].iloc[i] < level['Level'] and data['close'].iloc[i + 1] > level['Level']:
                    pullbacks.append({
                        'Date': data.index[i],
                        'Level': level['Level'],
                        'Type': 'Pullback',
                        'Trend': 'Bullish' if level['Level'] > data['close'].iloc[i] else 'Bearish'
                    })
        logging.debug(f"FlexibleM1Analyzer: Detectados {len(pullbacks)} pullbacks.")
        return pullbacks

    def analyze_ranks(self, data: pd.DataFrame, levels: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Detecta 'Ranks'."""
        ranks = []
        if data.empty or not levels or len(data) < 2:
            return ranks

        for level in levels:
            for i in range(len(data) - 1): # Bucle hasta la penúltima vela para acceder a i+1
                if data['close'].iloc[i] > level['Level'] and data['close'].iloc[i + 1] < level['Level']:
                    ranks.append({
                        'Date': data.index[i],
                        'Level': level['Level'],
                        'Type': 'Rank',
                        'Trend': 'Bearish' if level['Level'] < data['close'].iloc[i] else 'Bullish'
                    })
        logging.debug(f"FlexibleM1Analyzer: Detectados {len(ranks)} ranks.")
        return ranks

    def analyze_baston_c(self, data: pd.DataFrame, levels: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Detecta patrones 'Baston C' (continuación alcista)."""
        baston_c = []
        if data.empty or not levels or len(data) < 2:
            return baston_c

        added_levels_for_baston = set() 

        for level in levels:
            for i in range(len(data) - 1):
                # Si el cierre actual y el siguiente están por encima del nivel
                if data['close'].iloc[i] > level['Level'] and data['close'].iloc[i + 1] > level['Level']:
                    # Usar una tupla (Level, Type) para identificar el nivel de forma única
                    level_key = (level['Level'], level['Type'])
                    if level_key not in added_levels_for_baston:
                        baston_c.append({
                            'Date': data.index[i],
                            'Level': level['Level'],
                            'Type': 'Baston C',
                            'Trend': 'Bullish'
                        })
                        added_levels_for_baston.add(level_key)
        logging.debug(f"FlexibleM1Analyzer: Detectados {len(baston_c)} baston_c.")
        return baston_c

    def analyze_baston_r(self, data: pd.DataFrame, levels: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Detecta patrones 'Baston R' (continuación bajista)."""
        baston_r = []
        if data.empty or not levels or len(data) < 2:
            return baston_r
        
        added_levels_for_baston = set()

        for level in levels:
            for i in range(len(data) - 1):
                # Si el cierre actual y el siguiente están por debajo del nivel
                if data['close'].iloc[i] < level['Level'] and data['close'].iloc[i + 1] < level['Level']:
                    level_key = (level['Level'], level['Type'])
                    if level_key not in added_levels_for_baston:
                        baston_r.append({
                            'Date': data.index[i],
                            'Level': level['Level'],
                            'Type': 'Baston R',
                            'Trend': 'Bearish'
                        })
                        added_levels_for_baston.add(level_key)
        logging.debug(f"FlexibleM1Analyzer: Detectados {len(baston_r)} baston_r.")
        return baston_r
    
    def analyze_concepts(self, data: pd.DataFrame, esquemas_5m: Optional[List[Dict[str, Any]]] = None) -> List[Dict[str, Any]]:
        """
        Análisis flexible en 1M. Combina esquemas de 5M con patrones locales en 1M.
        Este método es el que `TradingBot.analyze_flexible_strategy` llamará.
        """
        señales_1m_finales = []
        niveles_agregados = set() # Para evitar duplicados de señales

        if data.empty:
            logging.warning("FlexibleM1Analyzer.analyze_concepts: Datos de 1M vacíos.")
            return señales_1m_finales

        # 1. Identificar niveles clave locales en 1M
        levels_1m = self.identify_key_levels(data) # Esto devuelve una lista de dicts

        # 2. Análisis de patrones locales en 1M
        pullbacks = self.analyze_pullbacks(data, levels_1m)
        ranks = self.analyze_ranks(data, levels_1m)
        baston_c = self.analyze_baston_c(data, levels_1m)
        baston_r = self.analyze_baston_r(data, levels_1m)

        # === Señales desde ESQUEMAS DE 5M (confirmación en 1M) ===
        if esquemas_5m:
            current_price = data['close'].iloc[-1]
            # Umbral de proximidad para confirmar esquemas de 5M en 1M
            proximity_threshold_5m = self.proximity_threshold_5m # Acceso directo al atributo

            for esquema in esquemas_5m:
                # Asegúrate de que 'Level' exista y no sea NaN
                esquema_level = esquema.get('Level')
                if esquema_level is None or np.isnan(esquema_level):
                    continue

                if abs(current_price - esquema_level) < proximity_threshold_5m:
                    key = (esquema_level, esquema.get('scheme', 'Unknown_Scheme_5M'))
                    if key not in niveles_agregados:
                        señales_1m_finales.append({
                            'Type': esquema.get('direction', 'Unknown'), # Usar la dirección del esquema 5M
                            'Level': esquema_level,
                            'Reason': f"Confirmación esquema 5M: {esquema.get('scheme', 'N/A')}",
                            'Confidence': 'Alta',
                            'Categoria': 'Flexible_5M', # Nueva categoría para distinguir
                            'Strategy': 'FlexibleStrategy',
                            'Nombre': f"{esquema.get('scheme', 'N/A')} confirmado en 1M",
                            'Esquema': esquema.get('scheme', 'N/A'),
                            'OrderBlockRelacionado': "OrderBlock" in esquema.get('scheme', '') # Asumiendo que el esquema 5M podría indicar OB
                        })
                        niveles_agregados.add(key)
        
        # === Señales locales por patrones en 1M ===
        def agregar_patron(signals_list: List[Dict[str, Any]], name: str, force_type: Optional[str] = None):
            for señal in signals_list:
                # Asegúrate de que 'Level' exista y no sea NaN
                señal_level = señal.get('Level')
                if señal_level is None or np.isnan(señal_level):
                    continue

                tipo = 'Buy' if señal.get('Trend') == 'Bullish' else 'Sell'
                if force_type:
                    tipo = force_type
                
                key = (señal_level, name)
                if key not in niveles_agregados:
                    señales_1m_finales.append({
                        'Type': tipo,
                        'Level': señal_level,
                        'Reason': name,
                        'Confidence': 'Media',
                        'Categoria': 'Flexible_1M', # Nueva categoría
                        'Strategy': 'FlexibleStrategy',
                        'Nombre': f"Patrón {name} en 1M",
                        'Esquema': name, # El patrón mismo es el esquema
                        'OrderBlockRelacionado': False # Por defecto, a menos que tu patrón lo indique
                    })
                    niveles_agregados.add(key)

        agregar_patron(pullbacks, 'Pullback')
        agregar_patron(ranks, 'Rank')
        agregar_patron(baston_c, 'Baston C', force_type='Buy')
        agregar_patron(baston_r, 'Baston R', force_type='Sell')

        
        return señales_1m_finales
    
class MarketStructureManager:
    """
    Gestiona y consolida los niveles de estructura de mercado identificados por los analizadores
    y niveles adicionales.
    """
    def __init__(self, m1_analyzer: FlexibleM1Analyzer = None,
                 m5_analyzer: FlexibleM5Analyzer = None,
                 additional_levels: Optional[List[Dict[str, Any]]] = None):
        self.m1_analyzer = m1_analyzer
        self.m5_analyzer = m5_analyzer
        self.additional_levels = additional_levels if additional_levels is not None else []
        logging.info("MarketStructureManager inicializado.")

    def update_analyzers(self, m1_analyzer: FlexibleM1Analyzer, m5_analyzer: FlexibleM5Analyzer,
                         additional_levels: Optional[List[Dict[str, Any]]] = None):
        self.m1_analyzer = m1_analyzer
        self.m5_analyzer = m5_analyzer
        self.additional_levels = additional_levels if additional_levels is not None else []
        logging.info("MarketStructureManager: Analizadores y niveles adicionales actualizados.")

    def get_all_levels(self, level_types: Optional[List[str]] = None) -> List[Dict[str, Any]]:
        """
        Extrae todos los niveles de los DataFrames de los analizadores y los niveles adicionales.
        """
        all_levels_dfs = []

        if self.m1_analyzer and not self.m1_analyzer.levels_df.empty:
            df1 = self.m1_analyzer.levels_df.copy()
            df1['Timeframe'] = 'M1'
            all_levels_dfs.append(df1)
            logging.debug(f"MarketStructureManager: Añadidos {len(df1)} niveles de M1.")

        if self.m5_analyzer and not self.m5_analyzer.levels_df.empty:
            df5 = self.m5_analyzer.levels_df.copy()
            df5['Timeframe'] = 'M5'
            all_levels_dfs.append(df5)
            logging.debug(f"MarketStructureManager: Añadidos {len(df5)} niveles de M5.")

        if self.additional_levels:
            df_additional = pd.DataFrame(self.additional_levels)
            if 'Timeframe' not in df_additional.columns:
                df_additional['Timeframe'] = 'ATR_Filtered' # Un timeframe para los niveles filtrados por ATR
            all_levels_dfs.append(df_additional)
            logging.debug(f"MarketStructureManager: Añadidos {len(df_additional)} niveles adicionales (ATR filtrados).")

        if not all_levels_dfs:
            logging.warning("MarketStructureManager: No se encontraron DataFrames de niveles en los analizadores ni niveles adicionales.")
            return []

        combined_df = pd.concat(all_levels_dfs, ignore_index=True)
        combined_df = combined_df.drop_duplicates(subset=['Date', 'Level', 'Type'])
        logging.debug(f"MarketStructureManager: Total de {len(combined_df)} niveles combinados.")

        if level_types:
            filtered_df = combined_df[
                combined_df['Type'].apply(lambda x: any(lt in x for lt in level_types))
            ]
            logging.debug(f"MarketStructureManager: Filtrados a {len(filtered_df)} niveles por tipo: {level_types}.")
            return filtered_df.to_dict('records')
        
        return combined_df.to_dict('records')

    def get_closest_level(self, current_price: float, level_types: Optional[List[str]] = None,
                          tendencia: Optional[str] = None, max_dist_percent: float = 0.0006) -> Optional[Dict[str, Any]]:
        levels_to_consider = self.get_all_levels(level_types=level_types)
        if not levels_to_consider:
            return None
        filtrados = []
        for level_info in levels_to_consider:
            level_price = level_info['Level']
            distancia_absoluta = abs(level_price - current_price)
            distancia_porcentual = distancia_absoluta / current_price
            if distancia_porcentual <= max_dist_percent:
                if tendencia and level_info.get('Trend') != tendencia:
                    continue
                filtrados.append((distancia_absoluta, level_info))
        filtrados.sort(key=lambda x: x[0])
        return filtrados[0][1] if filtrados else None

    def get_all_flips(self) -> List[Dict[str, Any]]:
        return self.get_all_levels(level_types=['Flip'])
class TradingBot:
    def __init__(self, api,):
        self.api = api
        self.total_profit = 0
        self.current_amount = 10  # Monto que quieres arriesgar por operación
        self.target_profit = 10
        self.asset = None
        self.otc = False
        
        self.get_asset_info()

        # Inicializar analizadores
        self.m30_analyzer = M30Analyzer()
        self.m5_analyzer = M5Analyzer()
        self.m1_analyzer = M1Analyzer()
        self.flexible_m5_analyzer = FlexibleM5Analyzer()
        self.flexible_m1_analyzer = FlexibleM1Analyzer()
        
        # Cargar los modelos
        self.modelo_niveles = joblib.load("modelo_niveles.pkl")
        self.modelo_lightgbm = joblib.load("modelo_lightgbm.pkl")
        self.modelo_direccion = modelo_direccion  # Cargar el nuevo modelo
        self.scaler_direccion = scaler_direccion        # Cargar el scaler
        self.label_encoders_direccion = label_encoders_direccion  # Cargar los label encoders
        logging.info("Modelos de IA cargados correctamente.")
        # Control de tiempo
        self.last_trade_time = None
        self.data_30m = None
        self.data_5m = None
        self.data_1m = None

        # Nuevos atributos para manejar señales y flips
        self.current_signal = None  # La señal que el bot está esperando
        self.relevant_flips = []    # Flips relevantes para la señal actual
        self.recent_flips_1m = []  # Lista de flips recientes en 1 minuto
        
        # Parámetros para la detección de FVG
        self.fvg_max_patterns = 5
        self.fvg_ignore_proximity = True
        self.fvg_signals = [] # Para almacenar las señales FVG detectadas

        # Inicializar la lista de flips
        self.flip_1m_recientes = []
        self.orderblocks = []
        self.sibi_bisi = []
        self.bos_choch = []
        self.estructura_mercado = {}
       
        self.todas_las_senales = [] # Inicializar la lista de todas las señales
        self.relevant_flips = []
 
        logging.info(f"Bot configurado para operar con {self.asset}")
    
    def actualizar_estructura_con_resumen(self):
        """
        Procesa self.data_1m y actualiza self.estructura_mercado con un resumen de BOS y CHoCH
        """
        if self.data_1m is not None and not self.data_1m.empty:
            resultados_estructura = ejecutar_deteccion_completa(self.data_1m)
            estructura = resultados_estructura["resumen_estructura"]

            # Guardamos la estructura resumen
            self.estructura_mercado["bos"] = estructura["bos"]
            self.estructura_mercado["choch"] = estructura["choch"]

            # Mostrar en consola para debug
            print(" BOS:", estructura["bos"])
            print(" CHoCH:", estructura["choch"])
        else:
            print(" No hay data de 1M para analizar BOS/CHoCH.")
    def analizar_con_smc(self, data_1m, data_5m):
        """
        Usa SmartMoneyConcepts para detectar señales en los datos de 1m y 5m.
        """
        smc = SmartMoneyConcepts(data_1m, data_5m) # <-- Here you ARE passing data_1m and data_5m
        señales_smc = smc.analyze_smc(data_1m, '1m') + smc.analyze_smc(data_5m, '5m')

        # También podrías capturar estructura de mercado actual si quieres
        self.estructura_smc = smc.get_current_market_structure(data_1m)

        return señales_smc
    def evaluar_signal(self, señal):
        # Evaluar la señal con el Modelo LightGBM
        X_signal = pd.DataFrame([self.convertir_a_features_signal(señal)])
        prob_signal = self.modelo_signal.predict_proba(X_signal)
        print(f"Probabilidad de éxito de la señal (LightGBM): {prob_signal}")

        # Evaluar la señal con el Modelo de Dirección
        features_direccion = self.preparar_caracteristicas_direccion(señal) # Función para preparar las características
        if features_direccion is not None:
            features_df_direccion = pd.DataFrame([features_direccion])
            # Codificar categóricas y escalar
            features_df_direccion_encoded = features_df_direccion.apply(lambda col: self.label_encoders_direccion[col.name].transform(col) if col.name in self.label_encoders_direccion else col)
            features_scaled_direccion = self.scaler_direccion.transform(features_df_direccion_encoded)
            prob_direccion = self.modelo_direccion.predict_proba(features_scaled_direccion)[:, 1][0] # Obtener la probabilidad de "buena dirección"
            print(f"Probabilidad de buena dirección: {prob_direccion}")
        else:
            prob_direccion = 0.5 # Valor por defecto si faltan características
            print("Advertencia: No se pudo evaluar la dirección del precio. Usando probabilidad por defecto.")

        # Combinar probabilidades (ejemplo: promedio ponderado)
        probabilidad_win_total = (0.7 * prob_signal[0][1] + 0.3 * prob_direccion)  # Ejemplo de pesos
        return probabilidad_win_total >= self.umbral_signal # Devuelve si la probabilidad combinada supera el umbral
    
    def _ensure_volume_column(self, df, timeframe):
        if df is not None and not df.empty and 'volume' not in df.columns:
            # Volumen sintético basado en rango (más realista)
            df['volume'] = (df['high'] - df['low']) * 1000
            logging.info(f"Volumen sintético generado para {timeframe}")
            
        # Asegurar que sea numérico
        if 'volume' in df.columns:
            df['volume'] = pd.to_numeric(df['volume'], errors='coerce').fillna(1.0)
    def evaluar_niveles(self, señal):
        # Evaluar el nivel con el Modelo de Niveles
        X_nivel = pd.DataFrame([self.convertir_a_features_niveles(señal)])
        prob_nivel = self.modelo_niveles.predict_prob(X_nivel)
        print(f"Probabilidad de nivel: {prob_nivel}")
        return prob_nivel[0][1] >= self.umbral_niveles

    def elegir_mejor_senal(self):
        if not self.modelo_signal or not self.modelo_niveles or not self.señales:
            return None

        evaluadas = []
        for señal in self.señales:
            # Verificar si las features están completas
            try:
                features_signal = self.convertir_a_features_signal(señal)
                features_niveles = self.convertir_a_features_niveles(señal)
            except Exception as e:
                logging.error(f"Error al convertir señal a features: {e}")
                continue

            X_signal = pd.DataFrame([features_signal])
            X_nivel = pd.DataFrame([features_niveles])

            # Verificar que las columnas coincidan
            if list(X_signal.columns) != self.modelo_signal.feature_name_:
                logging.warning(f"Signal features inválidos: {X_signal.columns.tolist()}")
                continue

            if list(X_nivel.columns) != self.modelo_niveles.feature_name_:
                logging.warning(f"Nivel features inválidos: {X_nivel.columns.tolist()}")
                continue

            try:
                prob_signal = self.modelo_signal.predict_proba(X_signal)[0][1]
                prob_nivel = self.modelo_niveles.predict_proba(X_nivel)[0][1]
            except Exception as e:
                logging.error(f"Error en predicción: {e}")
                continue

            if prob_signal >= self.umbral_signal and prob_nivel >= self.umbral_niveles:
                señal["probabilidad_win"] = prob_signal # Esto ahora es la prob combinada.
                evaluadas.append(señal)

        if not evaluadas:
            return None

        mejor = sorted(evaluadas, key=lambda x: (x["probabilidad_win"], x.get("score", 0)), reverse=True)[0]
        return mejor

    def preparar_caracteristicas_direccion(self, señal):
        """
        Extrae y prepara las características de la señal para el modelo de dirección del mercado.
        Devuelve None si faltan características.
        """
        try:
            # Asegúrate de que los nombres de las claves en 'señal' coincidan con los nombres de las columnas que espera el modelo.
            features_direccion = {
                'price_action': señal['price_action'],
                'trend': señal['trend'],
                'body_size': señal['body_size'],
                'mecha_superior_pct': señal['mecha_superior_pct'],
                'mecha_inferior_pct': señal['mecha_inferior_pct'],
                'prev_body_size': señal['prev_body_size'],  # Asegúrate de tener esto en 'señal'
                'ob_body_size': señal['ob_body_size']     # Asegúrate de tener esto en 'señal'
            }
            # Verifica si alguna característica falta en la señal.
            if not all(key in señal for key in features_direccion):
                logging.warning(f"Faltan características para el modelo de dirección del mercado en la señal: {señal}")
                return None
            return pd.Series(features_direccion)
        except KeyError as e:
            logging.error(f"Error al extraer características para el modelo de dirección: {e}")
            return None
        except Exception as e:
            logging.error(f"Error inesperado al preparar características de dirección: {e}")
            return None
    
    def convertir_a_features_niveles(self, señal):
        """
        Convierte una señal en un diccionario de características para el modelo de niveles.
        """
        features = {
            'body_size': señal.get('body_size', 0),
            'mecha_superior_pct': señal.get('mecha_superior_pct', 0),
            'mecha_inferior_pct': señal.get('mecha_inferior_pct', 0),
            'prev_body_size': señal.get('prev_body_size', 0),
            'ob_body_size': señal.get('ob_body_size', 0),
            'price_action': 1 if señal['price_action'] == 'alcista' else 0,
            'trend': 1 if señal['trend'] == 'alcista' else 0,
            'time': señal['time'].timestamp()
        }
        return features

    def analizar_mercado(self, data_1m, data_5m, data_30m):
        """
        Integra todos los análisis y devuelve una lista de señales.
        """
        all_signals = []
        niveles_filtrados = self.detectar_niveles_relevantes(data_5m)  # Asegúrate de implementar esto

        # Asegúrate de pasar niveles_filtrados a las funciones que lo requieran
        all_signals.extend(self.detectar_orderblocks(data_5m, data_1m, niveles_filtrados))
        all_signals.extend(self.detectar_consolidaciones(data_5m, niveles_filtrados))
        all_signals.extend(self._detectar_fvg(data_5m))
        all_signals.extend(self._detectar_bos_choch(data_1m))
        all_signals.extend(self.get_flip_info(self.flexible_m1_analyzer,self.flexible_m5_analyzer))
        all_signals.extend(self.detectar_liquidez(data_1m))

        return all_signals

    def detectar_niveles_relevantes(self, data_5m: pd.DataFrame, ventana_atr: int = 14, factor_atr: float = 1.5) -> List[Dict[str, Any]]:
        """
        Filtra los niveles existentes (flips, S/R) de los analizadores (M1 y M5),
        identificando cuáles son "relevantes" basados en criterios de ATR en la vela de su origen.
        
        Args:
            data_5m (pd.DataFrame): DataFrame con datos de velas de 5 minutos. Se usa para calcular ATR
                                    y para buscar las velas de origen de los niveles.
                                    (Aunque el nombre sugiere solo 5m, internamente también se usará
                                    self.candles_m1 para niveles de M1).
            ventana_atr (int): Ventana para el cálculo del ATR.
            factor_atr (float): Factor para ajustar la sensibilidad de la detección de niveles.

        Returns:
            list: Lista de diccionarios, conteniendo solo los niveles de los analizadores
                  que cumplen los criterios de ATR.
        """
        relevant_levels_by_atr = []

        # Usar los parámetros de la instancia del bot si no se proporcionan
        ventana_atr = self.atr_window if ventana_atr is None else ventana_atr
        factor_atr = self.atr_factor if factor_atr is None else factor_atr

        # Obtener todos los niveles identificados por los analizadores M1 y M5
        # NOTA: Aquí accedemos directamente a los levels_df de los analizadores.
        # Es crucial que identify_key_levels ya se haya ejecutado en ambos analizadores.
        all_analyzer_levels = []
        if self.m1_analyzer and not self.m1_analyzer.levels_df.empty:
            df_m1 = self.m1_analyzer.levels_df.copy()
            df_m1['Timeframe'] = 'M1'
            all_analyzer_levels.extend(df_m1.to_dict('records'))
        if self.m5_analyzer and not self.m5_analyzer.levels_df.empty:
            df_m5 = self.m5_analyzer.levels_df.copy()
            df_m5['Timeframe'] = 'M5'
            all_analyzer_levels.extend(df_m5.to_dict('records'))
        
        if not all_analyzer_levels:
            logging.warning("detectar_niveles_relevantes: No se encontraron niveles en los analizadores M1/M5 para filtrar.")
            return []

        # Calcular ATR para los datos de 5m (según la firma de la función)
        # Y también para los datos de 1m, ya que los niveles pueden venir de M1
        atr_m5 = self._calcular_atr(data_5m, ventana_atr)
        atr_m1 = self._calcular_atr(self.candles_m1, ventana_atr) # Acceder a self.candles_m1

        for level_info in all_analyzer_levels:
            level_date = level_info['Date']
            level_price = level_info['Level']
            level_type = level_info['Type']
            timeframe = level_info.get('Timeframe')

            current_data_for_candle = None
            current_atr_series = None

            if timeframe == 'M1':
                current_data_for_candle = self.candles_m1
                current_atr_series = atr_m1
            elif timeframe == 'M5':
                current_data_for_candle = data_5m # Usa data_5m pasada como argumento
                current_atr_series = atr_m5
            else:
                logging.debug(f"Nivel sin timeframe válido para buscar vela: {level_info}. Saltando.")
                continue

            if current_data_for_candle.empty or level_date not in current_data_for_candle.index:
                logging.debug(f"No se encontraron datos de vela para el nivel en {level_date} ({timeframe}). Saltando.")
                continue

            try:
                candle = current_data_for_candle.loc[level_date]
                if isinstance(candle, pd.DataFrame):
                    candle = candle.iloc[0]
            except KeyError:
                logging.debug(f"Vela para la fecha {level_date} no encontrada en el DataFrame {timeframe}.")
                continue

            try:
                current_atr = current_atr_series.loc[level_date]
            except KeyError:
                logging.debug(f"ATR para la fecha {level_date} no encontrado en el DataFrame {timeframe}.")
                continue

            if np.isnan(current_atr) or current_atr == 0:
                logging.debug(f"ATR no válido para el nivel en {level_date} ({timeframe}). Saltando.")
                continue

            is_relevant = False

            # Lógica para niveles de resistencia, flips alcistas o altos (High (A))
            if 'Resistance' in level_type or level_type.startswith('Flip A') or level_type.startswith('High'):
                wick_size = candle['high'] - max(candle['open'], candle['close'])
                if wick_size >= factor_atr * current_atr:
                    is_relevant = True
                    logging.debug(f"Nivel {level_type} en {level_price} ({timeframe}) es relevante por ATR (Resistencia/Alcista).")
                
            # Lógica para niveles de soporte, flips bajistas o bajos (Low (B))
            elif 'Support' in level_type or level_type.startswith('Flip B') or level_type.startswith('Low'):
                wick_size = min(candle['open'], candle['close']) - candle['low']
                if wick_size >= factor_atr * current_atr:
                    is_relevant = True
                    logging.debug(f"Nivel {level_type} en {level_price} ({timeframe}) es relevante por ATR (Soporte/Bajista).")

            if is_relevant:
                # Añadir el nivel original si es relevante
                relevant_levels_by_atr.append(level_info)

        logging.info(f"TradingBot: {len(relevant_levels_by_atr)} niveles de analizadores filtrados por ATR.")
        return relevant_levels_by_atr

    def calcular_atr(self, data, ventana):
        """
        Calcula el Average True Range (ATR).

        Args:
            data (pd.DataFrame): DataFrame con columnas 'high', 'low', 'close'.
            ventana (int): Ventana para el cálculo del ATR.

        Returns:
            pd.Series: Serie con los valores del ATR.
        """
        data['TR'] = np.maximum(data['high'] - data['low'],
                              np.maximum(np.abs(data['high'] - data['close'].shift(1)),
                                         np.abs(data['low'] - data['close'].shift(1))))
        atr = data['TR'].rolling(window=ventana).mean()
        return atr

    def exportar_estructura_mercado(self):
        """
        Exporta la estructura del mercado actual a un archivo JSON.
        """
        try:
            filename = f"estructura_mercado_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(filename, "w", encoding="utf-8") as f:
                json.dump(self.estructura_mercado, f, indent=4, ensure_ascii=False)
            print(f"Estructura del mercado exportada a {filename}")
        except Exception as e:
            print(f"Error al exportar la estructura del mercado: {e}")
    
    def actualizar_estructura_mercado(self, data_1m, data_5m, data_30m):
        """
        Updates the overall market structure by running various detection methods
        and consolidating their results into self.estructura_mercado.
        """
        logging.info("Updating market structure...")
        
        # It's good practice to ensure dataframes are not empty before processing
        if data_1m.empty or data_5m.empty or data_30m.empty:
            logging.warning("Cannot update market structure: one or more dataframes are empty.")
            self.estructura_mercado = {} # Reset or keep previous state if preferred
            self.todas_las_senales = []
            return

        # --- IMPORTANT: Ensure data is assigned to instance variables before calling methods ---
        self.data_1m = data_1m
        self.data_5m = data_5m
        self.data_30m = data_30m
        
        # Reset lists of detailed signals/events before populating them
        self.orderblocks = []
        self.sibi_bisi = []
        self.bos_choch = []
        self.todas_las_senales = []
        self.relevant_flips = []
        self.flip_1m_recientes = [] # If used separately from relevant_flips

        # 1. Detect Order Blocks (assuming you have a detectar_order_blocks method/function)
        self.orderblocks = self.detectar_order_blocks(self.data_1m) # If it's a method
        self.todas_las_senales.extend(self.orderblocks)

        # 2. Detect FVG, BISI, SIBI (this calls the standalone detectar_fvg which handles all three)
        # This populates self.sibi_bisi with detailed signals (list of dicts)
        self.detectar_sibi_bisi() # This updates self.sibi_bisi internally
        self.todas_las_senales.extend(self.sibi_bisi) # Add these detailed signals to overall list

        # 3. Detect BOS/CHoCH (this calls the standalone detectar_bos_choch)
        # This populates self.bos_choch with detailed events (list of dicts)
        self.detectar_bos_choch() # This updates self.bos_choch internally
        self.todas_las_senales.extend(self.bos_choch) # Add these detailed events to overall list

        # 4. Detect Liquidez (assuming you have this method)
        self.liquidez = self.detectar_liquidez(self.data_1m) # If it's a method
        self.todas_las_senales.extend(self.liquidez)

        # 5. Detect Niveles Relevantes (assuming you have this method)
        self.relevant_levels = self.detectar_niveles_relevantes(self.flexible_m1_analyzer) # If it's a method
        self.todas_las_senales.extend(self.relevant_levels)

        # 6. Detect Flips (assuming you have this method)
        self.relevant_flips = self.get_flip_info() # If it's a method
        self.todas_las_senales.extend(self.relevant_flips)
        # 7. Detect Flip 1m Recientes (assuming you have this method)
        self.flip_1m_recientes = self.get_flip_info() # If it's a method
        self.todas_las_senales.extend(self.flip_1m_recientes)

        # --- NEW: Call _calculate_sibi_bisi_and_bos_choch to get the simplified summary strings ---
        # This is the crucial step to get the 'simple' BOS/CHoCH/SIBI/BISI strings
        sibi_summary_str, bisi_summary_str, bos_summary_str, choch_summary_str = \
        self._calculate_sibi_bisi_and_bos_choch(self.data_30m, self.data_5m)
        # --- END NEW ---

        # Construir la estructura del mercado consolidada
        # This dictionary will be the value for 'estructura_mercado' in your final JSON
        self.estructura_mercado = {
            # Order Blocks (if detected and populated)
            "order_blocks": self.orderblocks, 
            
            # FVG signals from the detailed detection (list of dicts)
            "fvg_signals_detailed": [s for s in self.sibi_bisi if s.get('Reason') == 'FVG'],
            
            # SIBI and BISI as simplified strings (from _calculate_sibi_bisi_and_bos_choch)
            "sibi": sibi_summary_str,
            "bisi": bisi_summary_str,
            
            # BOS and CHoCH as simplified strings (from _calculate_sibi_bisi_and_bos_choch)
            "bos": bos_summary_str,
            "choch": choch_summary_str,
            
            # Detailed BOS/CHoCH events (list of dicts)
            "bos_choch_events_detailed": self.bos_choch, 
            
            # Detailed SIBI/BISI signals (list of dicts) from the general fvg detection.
            # Note: The _detectar_bisi and _detectar_sibi functions are called by detectar_fvg.
            # So, self.sibi_bisi contains all of them. Filter if you only want BISI/SIBI here.
            "sibi_bisi_signals_detailed": [s for s in self.sibi_bisi if s.get('Reason') in ['SIBI', 'BISI']],
            
            # Other structural elements (if detected and populated)
            "flips": self.relevant_flips, # Assuming this gets populated by detect_flips
            "liquidez": self.liquidez,   # Assuming this gets populated by detect_liquidez
            
            # Summaries from state objects (if these classes are properly managed and populated)
            # You might need to check if these attributes exist and are populated
            "resumen_niveles": self.relevant_levels_state.__dict__ if hasattr(self, 'relevant_levels_state') else {},
            "resumen_alertas": self.alert_manager.__dict__ if hasattr(self, 'alert_manager') else {},
            "resumen_extremes": self.trailing_extremes.__dict__ if hasattr(self, 'trailing_extremes') else {},
            
            # The full consolidated list of all signals (for other uses)
            "todas_las_senales_consolidadas": self.todas_las_senales 
        }
        logging.info("Market structure updated.")


    async def analizar_mercado_v2(self, price_data=None):
        """
        Analiza el mercado utilizando todos los métodos de detección disponibles.
        """
        try:
            logging.info("Iniciando análisis de mercado...")

            if not self.data_1m.empty and not self.data_5m.empty and not self.data_30m.empty:
                data_1m = self.data_1m.copy()
                data_5m = self.data_5m.copy()
                data_30m = self.data_30m.copy()
            else:
                logging.warning("Datos insuficientes para el análisis.")
                return {"estado": "error", "mensaje": "Datos insuficientes para el análisis.", "señales": []}

            # 1. Limpiar y preparar datos
            for df in [data_1m, data_5m, data_30m]:
                if 'time' in df:
                    df['time'] = pd.to_datetime(df['time'], unit='s')
                if 'volume' in df:
                    df.drop(columns=['volume'], inplace=True, errors='ignore')

            # 2. Calcular indicadores y detectar patrones
            self.actualizar_estructura_mercado(data_1m, data_5m, data_30m)
            # Añadir señales detectadas por SmartMoneyConcepts
            señales_smc = self.analizar_con_smc(self.data_1m, self.data_5m)
            self.todas_las_senales.extend(señales_smc)
        
            

            # 3. Combinar todas las señales detectadas
            self.todas_las_senales = [
                *self.estructura_mercado["order_blocks"],
                *self.estructura_mercado["fvg"],
                *self.estructura_mercado["bisi"],
                *self.estructura_mercado["sibi"],
                *self.estructura_mercado["bos_choch"],
                *self.estructura_mercado["flips"],
                *self.estructura_mercado["liquidez"]
            ]

            # 4. Filtrar y priorizar señales
            # (El código de filtrado y priorización se mantiene, pero se adapta para usar la nueva estructura)
            # Ejemplo de adaptación (necesitarás revisar y ajustar según tus necesidades):
            # for señal in self.todas_las_senales:
            #     if señal['tipo'] == 'BOS':
            #         # Lógica específica para BOS

            # 5. Evaluación de señales con IA (si está habilitado)
            # (El código de evaluación con IA se mantiene)

            # 6. Preparar el resultado final
            resultado = {
                "timestamp": datetime.now().isoformat(),
                "precio_actual": price_data["final_price_used"] if price_data else None,
                "info_precios": price_data if price_data else {},
                "estructura_mercado": self.estructura_mercado,
                "estructura_smc": self.estructura_smc,  #  AÑADE ESTA LÍNEA
                "señales_analizadas": len(self.todas_las_senales),
                "mejores_señales": [],  # Llenar esto después de la evaluación
                "estado": "exito",
                "mensaje": "Análisis completado"
            }

            # 7. Guardar el resultado en un archivo JSON
            filename = f"analisis_mercado_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open("estructura_smc.json", "w", encoding="utf-8") as f:
                json.dump(self.estructura_smc, f, indent=2, ensure_ascii=False)

            logging.info(f"Análisis del mercado guardado en {filename}")

            return resultado

        except Exception as e:
            logging.error(f"Error durante el análisis del mercado: {e}")
            traceback.print_exc()
            return {
                "timestamp": datetime.now().isoformat(),
                "estado": "error",
                "mensaje": str(e),
                "señales_analizadas": 0,
                "mejores_señales": [],
                "estructura_mercado": {}
            } 
    
    def _clean_for_json(self, data):
        """
        Limpia un objeto (diccionario o lista) para asegurar que sea serializable a JSON.
        Convierte objetos no serializables como datetime, NaN, Infinity y funciones a strings.
        """
        if isinstance(data, dict):
            return {k: self._clean_for_json(v) for k, v in data.items()}
        elif isinstance(data, list):
            return [self._clean_for_json(elem) for elem in data]
        elif isinstance(data, datetime):
            return data.isoformat()
        elif isinstance(data, (np.float32, np.float64, np.int32, np.int64)):
            # Convertir tipos numéricos de NumPy a tipos nativos de Python
            return float(data)
        elif isinstance(data, float) and (np.isnan(data) or np.isinf(data)):
            return None # O 'NaN' o 'Infinity' como string
        elif callable(data):
            logging.warning(f"Objeto de tipo función encontrado durante la limpieza JSON: {data}. Convirtiendo a string.")
            return str(data)
       
        # --- FIN NUEVA ADICIÓN ---
        else:
            return data
    def _convertir_a_serie(self, vela, nombre_funcion):
        """
        Función auxiliar para convertir diferentes tipos de entrada a pd.Series
        
        Args:
            vela: Entrada que podría ser pd.Series, pd.DataFrame o diccionario
            nombre_funcion: Nombre de la función que llama para mejor logging
            
        Returns:
            pd.Series o None si hay error
        """
        try:
            # Si es un número o un tipo primitivo, este no es un valor válido
            if isinstance(vela, (int, float, str, bool)) or vela is None:
                stack_trace = traceback.format_stack()
                caller_info = stack_trace[-3] if len(stack_trace) > 2 else "Desconocido"
                logging.warning(f"Valor no válido para 'vela' en {nombre_funcion}: {vela}. Se esperaba un pd.Series o diccionario.")
                logging.warning(f"Llamado desde: {caller_info}")
                return None
                
            # Si es un DataFrame, tomamos la última fila
            if isinstance(vela, pd.DataFrame):
                if vela.empty:
                    logging.warning(f"DataFrame vacío pasado a {nombre_funcion}")
                    return None
                return vela.iloc[-1]  # Tomamos la última fila como Series
                
            # Si ya es una Series, lo devolvemos tal cual
            if isinstance(vela, pd.Series):
                return vela
                
            # Intentamos convertir a Series si es un diccionario
            try:
                return pd.Series(vela)
            except Exception as e:
                logging.error(f"Error al convertir a Series en {nombre_funcion}: {str(e)}, tipo: {type(vela)}")
                return None
                
        except Exception as e:
            logging.error(f"Error en _convertir_a_serie: {str(e)}")
            return None

    def calcular_body_size(self, vela):
        """
        Calcula el tamaño del cuerpo de una vela.

        Args:
            vela (pd.Series, pd.DataFrame o dict-like): Datos de la vela
                                         debe contener 'close' y 'open'.

        Returns:
            float: El tamaño del cuerpo de la vela.
        """
        try:
            # Convertir a Series si es necesario
            vela_serie = self._convertir_a_serie(vela, "calcular_body_size")
            if vela_serie is None:
                return 0
            
            if 'close' not in vela_serie or 'open' not in vela_serie:
                logging.error("Error: La serie 'vela' debe contener las columnas 'close' y 'open'.")
                return 0
            
            return abs(vela_serie['close'] - vela_serie['open'])
        except Exception as e:
            stack_trace = traceback.format_stack()
            caller_info = stack_trace[-2] if len(stack_trace) > 1 else "Desconocido"
            logging.error(f"Error en calcular_body_size: {str(e)}, tipo de vela: {type(vela)}")
            logging.error(f"Llamado desde: {caller_info}")
            return 0

    def calcular_price_action(self, data):
        """
        Calcula el price action de la última vela.

        Args:
            data (pd.DataFrame): DataFrame con los datos OHLC de 1 minuto.

        Returns:
            str: El tipo de price action detectado ('alcista', 'bajista' o 'neutro').
        """
        try:
            if data is None or not isinstance(data, pd.DataFrame):
                logging.error("Error: El argumento 'data' debe ser un pd.DataFrame.")
                return 'neutro'
                
            if data.empty or len(data) < 1:
                return 'neutro'  # No hay suficientes datos

            last_candle = data.iloc[-1]

            if last_candle['close'] > last_candle['open']:
                return 'alcista'
            elif last_candle['close'] < last_candle['open']:
                return 'bajista'
            else:
                return 'neutro'
        except Exception as e:
            logging.error(f"Error en calcular_price_action: {str(e)}")
            return 'neutro'

    def obtener_tendencia(self, data):
        """
        Determina la tendencia basada en los cierres de las velas.
        Considera un período de 5 velas.
        Args:
            data (pd.DataFrame): DataFrame con datos de velas (close).
        Returns:
            str: "ALCISTA", "BAJISTA" o "RANGO".
        """
        try:
            if data is None or not isinstance(data, pd.DataFrame):
                logging.error("Error: El argumento 'data' debe ser un pd.DataFrame.")
                return "RANGO"
                
            if len(data) < 5:
                logging.warning("No hay datos suficientes para determinar la tendencia.")
                return "RANGO"
                
            closes = data['close'].values[-5:]
            if all(closes[i] < closes[i + 1] for i in range(len(closes)-1)):
                tendencia = "ALCISTA"
            elif all(closes[i] > closes[i + 1] for i in range(len(closes)-1)):
                tendencia = "BAJISTA"
            else:
                tendencia = "RANGO"
                
            return tendencia
        except Exception as e:
            logging.error(f"Error en obtener_tendencia: {str(e)}")
            return "RANGO"

    def calcular_mecha_superior_pct(self, vela):
        """
        Calcula el porcentaje de la mecha superior con respecto al rango de la vela.
        Args:
            vela (pd.Series, pd.DataFrame o dict-like): Datos de la vela,
                                         debe contener 'high', 'open', 'close', 'low'.
        Returns:
            float: Porcentaje de la mecha superior.
        """
        try:
            # Convertir a Series si es necesario
            vela_serie = self._convertir_a_serie(vela, "calcular_mecha_superior_pct")
            if vela_serie is None:
                return 0
                
            if not all(col in vela_serie for col in ['high', 'low', 'close', 'open']):
                logging.error(
                    "Error: La serie 'vela' debe contener las columnas 'high', 'low', 'close' y 'open'.")
                return 0
                
            candle_range = vela_serie['high'] - vela_serie['low']
            if candle_range == 0:
                return 0
                
            if vela_serie['close'] > vela_serie['open']:
                mecha_superior = vela_serie['high'] - vela_serie['close']
            else:
                mecha_superior = vela_serie['high'] - vela_serie['open']
                
            mecha_superior_pct = (mecha_superior / candle_range) * 100
            return mecha_superior_pct
        except Exception as e:
            stack_trace = traceback.format_stack()
            caller_info = stack_trace[-2] if len(stack_trace) > 1 else "Desconocido"
            logging.error(f"Error en calcular_mecha_superior_pct: {str(e)}, tipo de vela: {type(vela)}")
            logging.error(f"Llamado desde: {caller_info}")
            return 0

    def calcular_mecha_inferior_pct(self, vela):
        """
        Calcula el porcentaje de la mecha inferior con respecto al rango de la vela.
        Args:
            vela (pd.Series, pd.DataFrame o dict-like): Datos de la vela,
                                         debe contener 'low', 'open', 'close', 'high'.
        Returns:
            float: Porcentaje de la mecha inferior.
        """
        try:
            # Convertir a Series si es necesario
            vela_serie = self._convertir_a_serie(vela, "calcular_mecha_inferior_pct")
            if vela_serie is None:
                return 0
                
            if not all(col in vela_serie for col in ['high', 'low', 'close', 'open']):
                logging.error(
                    "Error: La serie 'vela' debe contener las columnas 'high', 'low', 'close' y 'open'.")
                return 0
                
            candle_range = vela_serie['high'] - vela_serie['low']
            if candle_range == 0:
                return 0
                
            if vela_serie['close'] > vela_serie['open']:
                mecha_inferior = vela_serie['open'] - vela_serie['low']
            else:
                mecha_inferior = vela_serie['close'] - vela_serie['low']
                
            mecha_inferior_pct = (mecha_inferior / candle_range) * 100
            return mecha_inferior_pct
        except Exception as e:
            stack_trace = traceback.format_stack()
            caller_info = stack_trace[-2] if len(stack_trace) > 1 else "Desconocido"
            logging.error(f"Error en calcular_mecha_inferior_pct: {str(e)}, tipo de vela: {type(vela)}")
            logging.error(f"Llamado desde: {caller_info}")
            return 0

    def calcular_prev_body_size(self, vela):
        """
        Calcula el tamaño del cuerpo de la vela anterior a la última.
        Args:
            vela (pd.Series, pd.DataFrame o dict-like): Datos de la vela,
                                         debe contener 'open' y 'close'.
        Returns:
            float: Tamaño del cuerpo de la vela anterior.
        """
        try:
            # Convertir a Series si es necesario
            vela_serie = self._convertir_a_serie(vela, "calcular_prev_body_size")
            if vela_serie is None:
                return 0
                
            if 'close' not in vela_serie or 'open' not in vela_serie:
                logging.error("Error: La serie 'vela' debe contener las columnas 'close' y 'open'.")
                return 0
                
            return abs(vela_serie['close'] - vela_serie['open'])
        except Exception as e:
            stack_trace = traceback.format_stack()
            caller_info = stack_trace[-2] if len(stack_trace) > 1 else "Desconocido"
            logging.error(f"Error en calcular_prev_body_size: {str(e)}, tipo de vela: {type(vela)}")
            logging.error(f"Llamado desde: {caller_info}")
            return 0

    def calcular_ob_body_size(self, vela):
        """
        Calcula el tamaño del cuerpo de la vela del order block.
        Args:
            vela (pd.Series, pd.DataFrame o dict-like): Datos de la vela,
                                         debe contener 'open' y 'close'.
        Returns:
            float: Tamaño del cuerpo de la vela del order block.
        """
        try:
            # Convertir a Series si es necesario
            vela_serie = self._convertir_a_serie(vela, "calcular_ob_body_size")
            if vela_serie is None:
                return 0
                
            if 'close' not in vela_serie or 'open' not in vela_serie:
                logging.error("Error: La serie 'vela' debe contener las columnas 'close' y 'open'.")
                return 0
                
            return abs(vela_serie['close'] - vela_serie['open'])
        except Exception as e:
            stack_trace = traceback.format_stack()
            caller_info = stack_trace[-2] if len(stack_trace) > 1 else "Desconocido"
            logging.error(f"Error en calcular_ob_body_size: {str(e)}, tipo de vela: {type(vela)}")
            logging.error(f"Llamado desde: {caller_info}")
            return 0
    def evaluar_con_modelos_ia(self, señal):
        try:
            # === Modelo 1: Basado en datos de la señal (niveles, OB, etc.) ===
            try:
                # Normalizar el trend a un valor numérico
                trend_valor = 0  # Valor predeterminado para "Rango"
                trend_str = str(señal.get("Trend", "Rango")).lower()  # Asegurar que sea string y en minúsculas
                if trend_str == "alcista":
                    trend_valor = 1
                elif trend_str == "bajista":
                    trend_valor = -1
                
                # Asegurar que price_action sea numérico
                try:
                    price_action = float(señal.get("price_action", 0))
                except (ValueError, TypeError):
                    price_action = 0
                    
                # Asegurar que confidence sea numérico (1 por defecto)
                try:
                    confidence = float(señal.get("confidence", 1))
                except (ValueError, TypeError):
                    confidence = 1
                    
                # Asegurar que score sea numérico
                try:
                    score = float(señal.get("score", 0))
                except (ValueError, TypeError):
                    score = 0
                    
                # Asegurar que todos los valores sean numéricos
                features_1 = [
                    price_action,
                    trend_valor,
                    confidence,
                    score,
                    float(señal.get("flip_distance", 0)),
                    float(señal.get("body_size", 0)),
                    float(señal.get("mecha_superior_pct", 0)),
                    float(señal.get("mecha_inferior_pct", 0)),
                ]
                
                df_1 = pd.DataFrame([features_1], columns=[
                    'price_action', 'trend', 'confidence', 'score', 'flip_distance', 'body_size',
                    'mecha_superior_pct', 'mecha_inferior_pct'
                ])
                if self.modelo_niveles is not None:
                    proba_niveles = self.modelo_niveles.predict_proba(df_1)
                    if proba_niveles.shape[1] > 1:
                        prob1 = proba_niveles[0][1]
                    elif proba_niveles.shape[1] == 1:
                        prob1 = proba_niveles[0][0]
                    else:
                        prob1 = 0.5
                else:
                    prob1 = 0.0 # Si el modelo no está cargado, no puede predecir
            except Exception as e:
                logging.error(f"Error en Modelo 1: {str(e)}")
                prob1 = 0.0
                
            # === Modelo 2: Basado en contexto/vela actual (probabilidad de win) ===
            try:
                # Obtener el diccionario de vela actual
                vela_dict = self.get_current_candle()
                
                # Verificar que vela_dict sea un diccionario
                if not isinstance(vela_dict, dict):
                    logging.warning("get_current_candle() no devolvió un diccionario. Creando uno nuevo.")
                    vela_dict = {}
                
                # Asegurar que todos los valores estén presentes y sean del tipo correcto
                vela_dict['score'] = float(señal.get('score', 0))
                vela_dict['Level'] = float(señal.get('Level', 0)) 
                
                # Normalizar Trend como string
                trend_str = str(señal.get('Trend', 'Rango'))
                vela_dict['Trend'] = trend_str
                
                # Normalizar Confidence como string
                confidence_str = str(señal.get('Confidence', 'Media'))
                vela_dict['Confidence'] = confidence_str
                
                # Determinar Type basado en price_action numérico
                try:
                    price_action_val = float(señal.get('price_action', 0))
                    vela_dict['Type'] = 'Buy' if price_action_val > 0 else 'Sell'
                except (ValueError, TypeError):
                    vela_dict['Type'] = 'Sell'  # Valor por defecto
                
                # Asegurar que los demás valores sean numéricos
                vela_dict['flip_distance'] = float(señal.get('flip_distance', 0))
                vela_dict['body_size'] = float(señal.get('body_size', 0))
                vela_dict['mecha_superior_pct'] = float(señal.get('mecha_superior_pct', 0))
                vela_dict['mecha_inferior_pct'] = float(señal.get('mecha_inferior_pct', 0))
                
                # Asegurarse de que todas las columnas OHLC estén presentes
                for col in ['open', 'high', 'low', 'close', 'volume']:
                    if col not in vela_dict:
                        vela_dict[col] = 0.0
                
                # Convertir a Series para evitar el error
                vela = pd.Series(vela_dict)
                
                # Verificar que vela sea una Series antes de continuar
                if not isinstance(vela, pd.Series):
                    logging.error("No se pudo convertir vela_dict a pd.Series")
                    prob2 = 0.0
                else:
                    flips = self.relevant_flips if hasattr(self, 'relevant_flips') else []
                    logging.info(f"Relevant Flips: {flips}")
                    features_2_dict = self.extraer_features_lightgbm(vela, flips)
                    df_2 = pd.DataFrame([features_2_dict])
                    
                    if self.modelo_lightgbm is not None:
                        # Asumiendo que extraer_features_lightgbm devuelve 10 características
                        if df_2.shape[1] == 10: 
                            prob2 = self.modelo_lightgbm.predict_proba(df_2)[0][1]
                        else:
                            logging.warning(f"LightGBM: Número incorrecto de características ({df_2.shape[1]}). Se esperaban 10.")
                            prob2 = 0.0
                    else:
                        prob2 = 0.0
            except Exception as e:
                logging.error(f"Error en Modelo 2: {str(e)}")
                prob2 = 0.0
                
            # === Modelo 3: Basado en la dirección del precio ===
            try:
                signal_type = str(señal.get("Type", "")).lower()
                
                if signal_type == "buy":
                    direccion_precio = "Buy"
                    prob3_direccion = 0.7
                elif signal_type == "sell":
                    direccion_precio = "Sell"
                    prob3_direccion = 0.3
                else:
                    if hasattr(self, 'predecir_direccion_precio') and self.predecir_direccion_precio is not None:
                        direccion_precio = self.predecir_direccion_precio()
                    else:
                        try:
                            price_action = float(señal.get("price_action", 0))
                            direccion_precio = "Buy" if price_action > 0 else "Sell"
                        except (ValueError, TypeError):
                            direccion_precio = "Buy"
                    
                    prob3_direccion = 0.7 if direccion_precio == "Buy" else 0.3
                
                señal["direccion_predicha"] = direccion_precio
                
            except Exception as e:
                logging.error(f"Error en Modelo 3: {str(e)}")
                signal_type = str(señal.get("Type", "")).lower()
                if signal_type == "buy":
                    prob3_direccion = 0.7
                    señal["direccion_predicha"] = "Buy"
                else:
                    prob3_direccion = 0.5
                    señal["direccion_predicha"] = "Undecided"
                
            # === Decisión combinada ===
            score_final = (prob1 + prob2 + prob3_direccion) / 3
            
            score_final = max(0.0, min(1.0, score_final)) 

            # Los campos que se añadirán/actualizarán en la señal
            señal["probabilidad_win"] = round(score_final * 100) # De 0-1 a 0-100%
            señal["ia_decision"] = "buena" if score_final >= 0.6 else "mala"
            señal["score_ia_1"] = round(prob1, 4) # Redondea para mejor legibilidad en JSON
            señal["score_ia_2"] = round(prob2, 4)
            señal["score_ia_3"] = round(prob3_direccion, 4)
            # Opcional: añadir los detalles de los scores de IA para depuración
            señal["score_detalle_ia"] = {
                "modelo_niveles": round(prob1, 4),
                "modelo_lightgbm": round(prob2, 4),
                "modelo_direccion": round(prob3_direccion, 4),
                "score_final_combinado": round(score_final, 4)
            }
            
            return score_final
        
        except Exception as e:
            logging.error(f"Error general en evaluar_con_modelos_ia: {str(e)}")
            señal["probabilidad_win"] = 0 
            señal["ia_decision"] = "error"
            señal["score_ia_1"] = 0.0
            señal["score_ia_2"] = 0.0
            señal["score_ia_3"] = 0.0
            señal["score_detalle_ia"] = {"error": str(e)}
            return 0.0

    def extraer_features_lightgbm(self, vela_actual, niveles_flip):
        """
        Extrae las 10 características para el modelo LightGBM.

        Args:
            vela_actual: pd.Series con información de la vela actual.
            niveles_flip: lista de niveles relevantes.
            
        Returns:
            dict: Diccionario con las características extraídas.
        """
        try:
            # Validar explícitamente que vela_actual sea un pd.Series
            if not isinstance(vela_actual, pd.Series):
                logging.error("Error: El argumento 'vela_actual' debe ser un pd.Series.")
                return self._get_default_lightgbm_features_10()
            
            # Extraer los features con verificación de valores
            features = {}
            
            # Para cada característica, usar get() con valor predeterminado y convertir a float
            try:
                features['score'] = float(vela_actual.get('score', 0))
            except (TypeError, ValueError):
                features['score'] = 0.0
                
            try:
                features['key_level'] = float(vela_actual.get('Level', 0))
            except (TypeError, ValueError):
                features['key_level'] = 0.0
                
            # Valor booleano para OTC
            features['is_otc'] = int(getattr(self, 'otc', False))
            
            # Codificación de variables categóricas
            trend_str = str(vela_actual.get("Trend", "Rango"))
            features['trend_encoded'] = {"Alcista": 1, "Bajista": -1, "Rango": 0, "Indefinida": 0}.get(trend_str, 0)
            
            confidence_str = str(vela_actual.get("Confidence", "Media"))
            features['confidence_encoded'] = {"Alta": 2, "Media": 1, "Baja": 0, "N/A": 0}.get(confidence_str, 1)
            
            # Tipo de señal
            features['signal_encoded'] = 1 if str(vela_actual.get("Type", "")) == "Buy" else 0
            
            # Características numéricas con validación
            for key, default in [
                ('flip_distance', 0),
                ('body_size', 0),
                ('mecha_superior_pct', 0),
                ('mecha_inferior_pct', 0)
            ]:
                try:
                    features[key] = float(vela_actual.get(key, default))
                except (TypeError, ValueError):
                    features[key] = float(default)
            
            return features

        except Exception as e:
            logging.error(f"Error en extraer_features_lightgbm: {e}")
            return self._get_default_lightgbm_features_10()
    def preparar_caracteristicas_direccion(self, señal):
        """
        Extrae y prepara las características de la señal para el modelo de dirección del mercado.
        Devuelve None si faltan características.
        """
        try:
            # Asegúrate de que los nombres de las claves en 'señal' coincidan con los nombres de las columnas que espera el modelo.
            features_direccion = {
                'price_action': señal.get('price_action'),
                'trend': señal.get('Trend'),
                'body_size': señal.get('body_size'),
                'mecha_superior_pct': señal.get('mecha_superior_pct'),
                'mecha_inferior_pct': señal.get('mecha_inferior_pct'),
                'prev_body_size': señal.get('prev_body_size'),
                'ob_body_size': señal.get('ob_body_size')
            }
            # Verifica si alguna característica falta en la señal o es None.
            if not all(key in features_direccion and features_direccion[key] is not None for key in features_direccion):
                logging.warning(f"Faltan características o hay valores None para el modelo de dirección del mercado en la señal: {señal}")
                return None
            return pd.Series(features_direccion)
        except KeyError as e:
            logging.error(f"Error al extraer características para el modelo de dirección: {e}")
            return None
        except Exception as e:
            logging.error(f"Error inesperado al preparar características de dirección: {e}")
            return None
    
    def evaluar_signal(self, señal):
        """
        Evalúa una señal con el modelo de LightGBM (signal) y el modelo de dirección (modelo_direccion).
        Devuelve True si pasa ambos umbrales de probabilidad.
        """

        try:
            # === Paso 1: Evaluar con modelo de señales (LightGBM) ===
            features_signal = self.convertir_a_features_signal(señal)
            X_signal = pd.DataFrame([features_signal])

            # Verificar columnas esperadas
            columnas_esperadas = list(self.modelo_signal.feature_name_)
            columnas_recibidas = list(X_signal.columns)

            if columnas_recibidas != columnas_esperadas:
                logging.error(f" Columnas incompatibles para modelo_signal:\nEsperadas: {columnas_esperadas}\nRecibidas: {columnas_recibidas}")
                return False

            # Predicción del modelo signal
            prob_signal = self.modelo_signal.predict_proba(X_signal)[0][1]
            logging.info(f" Probabilidad de éxito con modelo_signal: {prob_signal:.4f}")

        except Exception as e:
            logging.error(f" Error al evaluar modelo_signal: {e}")
            prob_signal = 0.0

        # === Paso 2: Evaluar con modelo de dirección ===
        try:
            features_direccion = self.preparar_caracteristicas_direccion(señal)

            if features_direccion is None:
                logging.warning(" No se pudieron extraer características de dirección. Usando probabilidad por defecto.")
                prob_direccion = 0.5
            else:
                df_direccion = pd.DataFrame([features_direccion])
                # Codificar y escalar
                for col in df_direccion.columns:
                    if col in self.label_encoders_direccion:
                        df_direccion[col] = self.label_encoders_direccion[col].transform(df_direccion[col])

                df_scaled = self.scaler_direccion.transform(df_direccion)
                prob_direccion = self.modelo_direccion.predict_proba(df_scaled)[0][1]
                logging.info(f" Probabilidad de buena dirección: {prob_direccion:.4f}")

        except Exception as e:
            logging.error(f" Error al evaluar modelo_direccion: {e}")
            prob_direccion = 0.5

        # === Paso 3: Combinación y decisión final ===
        try:
            score_total = (0.7 * prob_signal + 0.3 * prob_direccion)
            señal["score_signal"] = round(prob_signal, 4)
            señal["score_direccion"] = round(prob_direccion, 4)
            señal["score_total"] = round(score_total, 4)
            señal["decision_ia"] = "buena" if score_total >= self.umbral_signal else "mala"

            logging.info(f" Evaluación IA final: {señal['decision_ia'].upper()} con score: {score_total:.4f}")
            return score_total >= self.umbral_signal

        except Exception as e:
            logging.error(f" Error al calcular score total de IA: {e}")
            return False
    
    def get_current_candle(self):
        """Obtiene la vela actual de los datos de 1 minuto"""
        if self.data_1m is not None and len(self.data_1m) > 0:
            return {
                'open': self.data_1m['open'].iloc[-1],
                'high': self.data_1m['high'].iloc[-1],
                'low': self.data_1m['low'].iloc[-1],
                'close': self.data_1m['close'].iloc[-1]
            }
        else:
            logging.warning("No hay datos de 1 minuto disponibles para obtener la vela actual")
            return {'open': 0, 'high': 0, 'low': 0, 'close': 0}

    def mostrar_mejores_señales(self, resultado):
        """Muestra un resumen de las mejores señales en consola de forma legible"""
        if not resultado or "mejores_señales" not in resultado:
            print("No hay señales disponibles para mostrar")
            return
        
        print("\n================ MEJORES SEÑALES DE TRADING ================")
        print(f"Timestamp: {resultado['timestamp']}")
        print(f"Precio actual: {resultado['precio_actual']}")
        print(f"Tendencia 30m: {resultado['tendencia_30m']}, Tendencia 5m: {resultado['tendencia_5m']}")
        print(f"Total señales detectadas: {resultado['total_señales_detectadas']}")
        print("-----------------------------------------------------------")
        
        for i, señal in enumerate(resultado['mejores_señales'], 1):
            print(f"\n{i}. {señal.get('Nombre', 'Señal sin nombre')} ({señal.get('Type', 'N/A')})")
            print(f"   Nivel: {señal.get('Level', 'N/A')}")
            print(f"   Categoría: {señal.get('Categoria', 'N/A')}")
            print(f"   Confianza: {señal.get('Confidence', 'N/A')}")
            print(f"   Score: {señal.get('score', 0):.2f}")
            print(f"   Decisión IA: {señal.get('ia_decision', 'N/A')}")
            print(f"   Probabilidad: {señal.get('probabilidad_win', 0):.2f}")
            print(f"   Confirmación FVG: {'Sí' if señal.get('confirmacion_fvg', False) else 'No'}")
            print(f"   Confirmación Total: {'Sí' if señal.get('confirmacion_total', False) else 'No'}")
        
        print("\n============================================================")

    async def run(self):
        """Bucle principal del bot que analiza el mercado y reporta las mejores señales
        sin ejecutar operaciones reales."""
        logging.info("Bot de análisis iniciado correctamente.")
        errores_consecutivos = 0
        max_errores_permitidos = 5
        intervalo_analisis = 30  # Segundos entre cada análisis

        while True:
            try:
                logging.info(f"Actualizando datos de velas...")
                await self.update_candles()
                
                if any(df is None or df.empty for df in [self.data_30m, self.data_5m, self.data_1m]):
                    logging.warning("No se pudieron obtener datos de velas completos. Reintentando en 15 segundos...")
                    await asyncio.sleep(15)
                    continue
                    
                logging.info(f"Iniciando análisis de mercado...")
                resultado_analisis = await self.analyze_and_report()
                
                if isinstance(resultado_analisis, dict):
                    errores_consecutivos = 0  # Resetear errores si el análisis fue exitoso
                    
                    if resultado_analisis.get("estado") == "sin_datos":
                        logging.warning("No hay datos suficientes para análisis. Esperando...")
                        await asyncio.sleep(15)
                        continue
                        
                    if resultado_analisis.get("estado") == "sin_señales":
                        logging.info("Análisis completado: No se detectaron señales válidas")
                    elif resultado_analisis.get("mejores_señales"):
                        num_señales = len(resultado_analisis.get("mejores_señales", []))
                        logging.info(f"Análisis completado: Se encontraron {num_señales} mejores señales")
                        # Mostrar resumen en consola usando el método de la clase
                        self.mostrar_mejores_señales(resultado_analisis)
                        
                    logging.info(f"Esperando {intervalo_analisis} segundos para el próximo análisis...")
                    await asyncio.sleep(intervalo_analisis)
                else:
                    errores_consecutivos += 1
                    logging.error(f"Resultado inesperado de analyze_and_report. Reintentando en 15 segundos...")
                    await asyncio.sleep(15)

                if errores_consecutivos >= max_errores_permitidos:
                    logging.error(f"Demasiados errores consecutivos ({errores_consecutivos}). Reiniciando bot...")
                    await self.restart_bot()

            except Exception as e:
                logging.error(f"Error grave en el bucle principal: {e}")
                import traceback
                logging.error(traceback.format_exc())
                errores_consecutivos += 1
                await asyncio.sleep(15)

                if errores_consecutivos >= max_errores_permitidos:
                    logging.error(f"Demasiados errores graves ({errores_consecutivos}). Reiniciando bot...")
                    await self.restart_bot()
    async def restart_bot(self):
        """Reinicia el script completo para recuperar el bot automáticamente."""
        logging.info("Reiniciando script...")
        await asyncio.sleep(5)
        python = sys.executable
        os.execl(python, python, *sys.argv)
    def get_asset_info(self):
        """Obtiene el par de divisas y si es OTC del usuario."""
        while True:
            self.asset = input("Ingrese el par de divisas (ej: EURUSD): ").upper()
            self.otc = input("¿Es OTC? (s/n): ").lower() == 's'  # Usa 'otc' en lugar de 'is_otc'
            otc_suffix = "_otc" if self.otc else ""
            self.asset_with_otc = self.asset + otc_suffix
            
            if self.asset.isalpha() and len(self.asset) >= 6:
                break
            else:
                print("Par inválido. Intente de nuevo.")
    
    def extraer_features_niveles(self, señal):
        """
        Esta función extrae las características de los niveles de soporte y resistencia
        necesarias para la predicción del modelo.
        Maneja casos donde las columnas no existen.
        """
        try:
            # Verificar si las columnas existen, usar valores predeterminados si no
            features = [
                señal.get("nivel_soporte_1", 0),
                señal.get("nivel_resistencia_1", 0),
                señal.get("nivel_soporte_2", 0),
                señal.get("nivel_resistencia_2", 0),
                señal.get("nivel_soporte_3", 0),
                señal.get("nivel_resistencia_3", 0),
                señal.get("distancia_a_soporte", 0),
                señal.get("distancia_a_resistencia", 0),
            ]
            
            # Verificar si todos los valores son válidos
            if all(isinstance(x, (int, float)) for x in features):
                return features
            else:
                logging.warning("Algunos valores de características no son numéricos")
                return [0] * 8  # Valores predeterminados si no son numéricos
                
        except Exception as e:
            logging.error(f"Error al extraer características de niveles: {e}")
            return [0] * 8  # Devuelve una lista de valores por defecto en caso de error

    def extraer_features_de_señal(self, señal):
        """
        Extrae las características relevantes de una señal de trading para el modelo de predicción.
        Incluye manejo de columnas faltantes y valores por defecto.
        """
        try:
            # Conversión segura de valores numéricos
            def safe_get_float(key, default=0):
                try:
                    return float(señal.get(key, default))
                except:
                    return default
            
            # Mapas de codificación para variables categóricas
            trend_map = {
                'alcista': 1, 'bajista': -1, 'neutral': 0,
                'bullish': 1, 'bearish': -1
            }
            confidence_map = {
                'alta': 3, 'media': 2, 'baja': 1
            }
            flip_type_map = {
                'soporte': 1, 'resistencia': 2, 'ninguno': 0
            }

            # Normalización segura de strings
            trend = trend_map.get(str(señal.get('trend', 'neutral')).lower(), 0)
            confidence = confidence_map.get(str(señal.get('confidence', 'media')).lower(), 2)
            flip_type = flip_type_map.get(str(señal.get('flip_type', 'ninguno')).lower(), 0)

            return {
                'price_action': safe_get_float('price_action'),
                'trend': trend,
                'confidence': confidence,
                'score': safe_get_float('score'),
                'flip_distance': safe_get_float('flip_distance'),
                'body_size': safe_get_float('body_size'),
                'mecha_superior_pct': safe_get_float('mecha_superior_pct'),
                'mecha_inferior_pct': safe_get_float('mecha_inferior_pct'),
                'ob_body_size': safe_get_float('ob_body_size'),           # NUEVO
                'prev_body_size': safe_get_float('prev_body_size'),       # NUEVO
                'flip_type': flip_type,                                   # NUEVO
                'estructura': int(señal.get('estructura', 0)),            # NUEVO
                'orderblock': int(señal.get('orderblock', 0)),            # NUEVO
                'validacion5m': int(señal.get('validacion5m', 0)),        # NUEVO
            }

        except Exception as e:
            logging.error(f"❌ Error al extraer features de señal: {e}")
            # Devolver un diccionario con todas las claves necesarias en caso de error
            return {
                'price_action': 0,
                'trend': 0,
                'confidence': 2,
                'score': 0,
                'flip_distance': 0,
                'body_size': 0,
                'mecha_superior_pct': 0,
                'mecha_inferior_pct': 0,
                'ob_body_size': 0,
                'prev_body_size': 0,
                'flip_type': 0,
                'estructura': 0,
                'orderblock': 0,
                'validacion5m': 0,
            }


    def preparar_features_para_modelo_lgbm(self, senal):
        """
        Prepara exactamente las 10 características esperadas por el modelo LightGBM,
        con valores por defecto si faltan datos.
        """
        try:
            # Codificar valores categóricos como numéricos
            trend_map = {'alcista': 1, 'Alcista': 1, 'bullish': 1, 'Bullish': 1, 'bajista': -1, 'Bajista': -1, 'bearish': -1, 'Bearish': -1, 'neutral': 0, 'Neutral': 0}
            confidence_map = {'alta': 3, 'Alta': 3, 'high': 3, 'High': 3, 'media': 2, 'Media': 2, 'medium': 2, 'Medium': 2, 'baja': 1, 'Baja': 1, 'low': 1, 'Low': 1}
            signal_map = {'buy': 1, 'Buy': 1, 'sell': -1, 'Sell': -1, 'wait': 0, 'Wait': 0}
            
            # Obtener valores con manejo de errores
            trend_str = str(senal.get('trend', 'neutral')).lower()
            confidence_str = str(senal.get('confidence', 'media')).lower()
            signal_str = str(senal.get('Type', 'wait')).lower()
            
            trend_encoded = trend_map.get(trend_str, 0)
            confidence_encoded = confidence_map.get(confidence_str, 2)
            signal_encoded = signal_map.get(signal_str, 0)
            
            # Asegurar que todos los valores son numéricos
            score = float(senal.get('score', 0)) if isinstance(senal.get('score'), (int, float)) else 0
            key_level = float(senal.get('Level', 0)) if isinstance(senal.get('Level'), (int, float)) else 0
            is_otc = 1 if senal.get('is_otc', self.otc) else 0
            flip_distance = float(senal.get('flip_distance', 0)) if isinstance(senal.get('flip_distance'), (int, float)) else 0
            body_size = float(senal.get('body_size', 0)) if isinstance(senal.get('body_size'), (int, float)) else 0
            mecha_superior_pct = float(senal.get('mecha_superior_pct', 0)) if isinstance(senal.get('mecha_superior_pct'), (int, float)) else 0
            mecha_inferior_pct = float(senal.get('mecha_inferior_pct', 0)) if isinstance(senal.get('mecha_inferior_pct'), (int, float)) else 0
            
            # Arreglo de características en el orden exacto esperado por el modelo
            features = [
                score,
                key_level,
                is_otc,
                trend_encoded,
                confidence_encoded,
                signal_encoded,
                flip_distance,
                body_size,
                mecha_superior_pct,
                mecha_inferior_pct
            ]
            
            return features
            
        except Exception as e:
            logging.error(f"Error preparando features para LGBM: {e}")
            # Retornar valores predeterminados en caso de error (10 características como espera el modelo)
            return [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

    def extraer_features_lightgbm(self, vela_actual, niveles_flip):
        """
        Extrae las 10 características para el modelo LightGBM.

        vela_actual: pd.Series con información de la vela actual.
        niveles_flip: lista de niveles relevantes.
        """
        try:
            # Validar que vela_actual sea un pd.Series
            if not isinstance(vela_actual, pd.Series):
                raise TypeError("El argumento 'vela' debe ser un pd.Series.")
            
            # Extraer los features asegurando que sean numéricos donde corresponda
            features = {
                'score': float(vela_actual.get('score', 0)),
                'key_level': float(vela_actual.get('Level', 0)),
                'is_otc': int(getattr(self, 'otc', False)),
                'trend_encoded': {"Alcista": 1, "Bajista": -1, "Rango": 0, "Indefinida": 0}.get(
                    str(vela_actual.get("Trend", "Rango")), 0),
                'confidence_encoded': {"Alta": 2, "Media": 1, "Baja": 0, "N/A": 0}.get(
                    str(vela_actual.get("Confidence", "Media")), 1),
                'signal_encoded': 1 if str(vela_actual.get("Type")) == "Buy" else 0,
                'flip_distance': float(vela_actual.get('flip_distance', 0)),
                'body_size': float(vela_actual.get('body_size', 0)),
                'mecha_superior_pct': float(vela_actual.get('mecha_superior_pct', 0)),
                'mecha_inferior_pct': float(vela_actual.get('mecha_inferior_pct', 0)),
            }
            return features

        except Exception as e:
            logging.error(f"Error en extraer_features_lightgbm: {e}")
            return self._get_default_lightgbm_features_10()

    def _get_default_lightgbm_features_10(self):
        """Devuelve valores por defecto para las características del modelo LightGBM."""
        return {
            'score': 0.0,
            'key_level': 0.0,
            'is_otc': 0,
            'trend_encoded': 0,
            'confidence_encoded': 1,
            'signal_encoded': 0,
            'flip_distance': 0.0,
            'body_size': 0.0,
            'mecha_superior_pct': 0.0,
            'mecha_inferior_pct': 0.0,
        }

    
    @retry(max_retries=5, delay=10)
    async def update_candles(self):
        """Actualiza los datos de velas para 30M, 5M y 1M."""
        try:
            logging.info("Actualizando velas...")
            candles_1m, candles_5m, candles_30m = await get_candles_three_timeframes(
                self.api, self.asset_with_otc, 60, 300, 1800, 3600 * 24
            )
            self.data_1m = candles_1m
            self.data_5m = candles_5m
            self.data_30m = candles_30m
            logging.info("Velas actualizadas correctamente.")
        except Exception as e:
            logging.error(f"Error al actualizar velas: {e}")
            self.data_1m, self.data_5m, self.data_30m = None, None, None
    
   
    async def actualizar_datos_1m(self):
        """Actualiza las velas de 1 minuto."""
        try:
            data = await self.api.get_candles(self.asset_with_otc, 60, 60)  # Últimos 60 velas de 1m
            # Convertirlo en DataFrame
            self.data_1m = pd.DataFrame(data)
            logging.info(" Velas de 1M actualizadas correctamente.")
        except Exception as e:
            logging.error(f" Error actualizando velas de 1M: {e}")

    def analyze_independent_1m(self, data_1m, tested_levels_1m):
        """
        Analiza múltiples señales independientes en 1M, considerando la proximidad al precio actual.
        Devuelve todas las señales encontradas, incluyendo las características para el modelo de dirección.
        """
        señales = []
        if data_1m is None or data_1m.empty or len(data_1m) < 3 or not tested_levels_1m:
            logging.warning("No hay suficientes datos para analizar en 1M o no hay niveles testeados.")
            return señales

        last = data_1m.iloc[-1]
        prev = data_1m.iloc[-2]
        #tolerance = 0.0002  # Ya no usamos un tolerance fijo, ahora es adaptativo
        
        current_price = data_1m['close'].iloc[-1]
        proximidad_relativa = current_price * 0.001  # 0.1% del precio actual
        proximidad_absoluta = 0.1  # Por ejemplo, 0.1 unidades de precio

        for level in tested_levels_1m:
            # Rebote Alcista
            if last['low'] <= level + min(proximidad_relativa, proximidad_absoluta) and last['close'] > level and last['close'] > last['open']:
                price_action = self.calcular_price_action(data_1m)
                trend = "Buy"
                body_size = self.calcular_body_size(last)
                mecha_superior_pct = self.calcular_mecha_superior_pct(last)
                mecha_inferior_pct = self.calcular_mecha_inferior_pct(last)
                prev_body_size = self.calcular_prev_body_size(prev)
                ob_body_size = self.calcular_ob_body_size(last)
                señal = {
                    "Type": "Buy",
                    "Level": level,
                    "Reason": "Rebote 1M",
                    "Confidence": "Media",
                    "price_action": price_action,
                    "Trend": trend,
                    "body_size": body_size,
                    "mecha_superior_pct": mecha_superior_pct,
                    "mecha_inferior_pct": mecha_inferior_pct,
                    "prev_body_size": prev_body_size,
                    "ob_body_size": ob_body_size,
                }
                señales.append(señal)

            # Rebote Bajista
            elif last['high'] >= level - min(proximidad_relativa, proximidad_absoluta) and last['close'] < level and last['close'] < last['open']:
                price_action = self.calcular_price_action(data_1m)
                trend = "Sell"
                body_size = self.calcular_body_size(last)
                mecha_superior_pct = self.calcular_mecha_superior_pct(last)
                mecha_inferior_pct = self.calcular_mecha_inferior_pct(last)
                prev_body_size = self.calcular_prev_body_size(prev)
                ob_body_size = self.calcular_ob_body_size(last)
                señal = {
                    "Type": "Sell",
                    "Level": level,
                    "Reason": "Rebote 1M",
                    "Confidence": "Media",
                    "price_action": price_action,
                    "Trend": trend,
                    "body_size": body_size,
                    "mecha_superior_pct": mecha_superior_pct,
                    "mecha_inferior_pct": mecha_inferior_pct,
                    "prev_body_size": prev_body_size,
                    "ob_body_size": ob_body_size,
                }
                señales.append(señal)

            # Rompimiento Alcista
            elif last['close'] > level and prev['close'] <= level and last['close'] > last['open']:
                price_action = self.calcular_price_action(data_1m)
                trend = "Buy"
                body_size = self.calcular_body_size(last)
                mecha_superior_pct = self.calcular_mecha_superior_pct(last)
                mecha_inferior_pct = self.calcular_mecha_inferior_pct(last)
                prev_body_size = self.calcular_prev_body_size(prev)
                ob_body_size = self.calcular_ob_body_size(last)
                señal = {
                    "Type": "Buy",
                    "Level": level,
                    "Reason": "Rompimiento 1M",
                    "Confidence": "Media",
                    "price_action": price_action,
                    "Trend": trend,
                    "body_size": body_size,
                    "mecha_superior_pct": mecha_superior_pct,
                    "mecha_inferior_pct": mecha_inferior_pct,
                    "prev_body_size": prev_body_size,
                    "ob_body_size": ob_body_size,
                }
                señales.append(señal)

            # Rompimiento Bajista
            elif last['close'] < level and prev['close'] >= level and last['close'] < last['open']:
                price_action = self.calcular_price_action(data_1m)
                trend = "Sell"
                body_size = self.calcular_body_size(last)
                mecha_superior_pct = self.calcular_mecha_superior_pct(last)
                mecha_inferior_pct = self.calcular_mecha_inferior_pct(last)
                prev_body_size = self.calcular_prev_body_size(prev)
                ob_body_size = self.calcular_ob_body_size(last)
                señal = {
                    "Type": "Sell",
                    "Level": level,
                    "Reason": "Rompimiento 1M",
                    "Confidence": "Media",
                    "price_action": price_action,
                    "Trend": trend,
                    "body_size": body_size,
                    "mecha_superior_pct": mecha_superior_pct,
                    "mecha_inferior_pct": mecha_inferior_pct,
                    "prev_body_size": prev_body_size,
                    "ob_body_size": ob_body_size,
                }
                señales.append(señal)

            # Falso rompimiento Alcista
            elif prev['close'] > level and last['close'] < level and last['close'] < last['open']:
                price_action = self.calcular_price_action(data_1m)
                trend = "Sell"
                body_size = self.calcular_body_size(last)
                mecha_superior_pct = self.calcular_mecha_superior_pct(last)
                mecha_inferior_pct = self.calcular_mecha_inferior_pct(last)
                prev_body_size = self.calcular_prev_body_size(prev)
                ob_body_size = self.calcular_ob_body_size(last)
                señal = {
                    "Type": "Sell",
                    "Level": level,
                    "Reason": "Falso Rompimiento 1M",
                    "Confidence": "Baja",
                    "price_action": price_action,
                    "Trend": trend,
                    "body_size": body_size,
                    "mecha_superior_pct": mecha_superior_pct,
                    "mecha_inferior_pct": mecha_inferior_pct,
                    "prev_body_size": prev_body_size,
                    "ob_body_size": ob_body_size,
                }
                señales.append(señal)

            # Falso rompimiento Bajista
            elif prev['close'] < level and last['close'] > level and last['close'] > last['open']:
                price_action = self.calcular_price_action(data_1m)
                trend = "Buy"
                body_size = self.calcular_body_size(last)
                mecha_superior_pct = self.calcular_mecha_superior_pct(last)
                mecha_inferior_pct = self.calcular_mecha_inferior_pct(last)
                prev_body_size = self.calcular_prev_body_size(prev)
                ob_body_size = self.calcular_ob_body_size(last)
                señal = {
                    "Type": "Buy",
                    "Level": level,
                    "Reason": "Falso Rompimiento 1M",
                    "Confidence": "Baja",
                    "price_action": price_action,
                    "Trend": trend,
                    "body_size": body_size,
                    "mecha_superior_pct": mecha_superior_pct,
                    "mecha_inferior_pct": mecha_inferior_pct,
                    "prev_body_size": prev_body_size,
                    "ob_body_size": ob_body_size,
                }
                señales.append(señal)
        return señales

   
    def analyze_validacion_5m(self, data_1m, validated_5m, ob_signals):
        """
        Genera señales basadas en la validación de niveles de 5M, incluyendo la proximidad al precio actual
        y las características necesarias para el modelo de dirección del mercado.

        Args:
            data_1m (pd.DataFrame): DataFrame con datos de 1 minuto.
            validated_5m (list): Lista de niveles validados en 5M.
            ob_signals (list): Lista de señales de Order Blocks.

        Returns:
            list: Lista de señales generadas.
        """
        if not validated_5m:
            return []

        señales = []
        last_candle_1m = data_1m.iloc[-1]
        direction = "Buy" if last_candle_1m['close'] > last_candle_1m['open'] else "Sell"
        
        current_price = data_1m['close'].iloc[-1]
        proximidad_relativa = current_price * 0.001  # 0.1% del precio actual
        proximidad_absoluta = 0.1  # Por ejemplo, 0.1 unidades de precio

        for nivel_5m in validated_5m:
            # Verifica la proximidad del nivel al precio actual
            if abs(current_price - nivel_5m) <= min(proximidad_relativa, proximidad_absoluta):
                # Calcula las características para el modelo de dirección
                price_action = self.calcular_price_action(data_1m)
                trend = self.obtener_tendencia(data_1m)  # Usa data_1m para la tendencia a corto plazo
                body_size = self.calcular_body_size(data_1m)
                mecha_superior_pct = self.calcular_mecha_superior_pct(data_1m)
                mecha_inferior_pct = self.calcular_mecha_inferior_pct(data_1m)
                prev_body_size = self.calcular_prev_body_size(data_1m)
                ob_body_size = self.calcular_ob_body_size(data_1m)

                señal = {
                    "Type": direction,
                    "Level": nivel_5m,
                    "Confidence": "Media",  # O el valor que corresponda
                    "Categoria": "Validacion5M",
                    "Reason": "Nivel probado 5M",
                    # Añade las características para el modelo de dirección
                    "price_action": price_action,
                    "Trend": trend,
                    "body_size": body_size,
                    "mecha_superior_pct": mecha_superior_pct,
                    "mecha_inferior_pct": mecha_inferior_pct,
                    "prev_body_size": prev_body_size,
                    "ob_body_size": ob_body_size,
                    "OrderBlockRelacionado": any(abs(nivel_5m - ob['nivel_ob']) <= 0.0008 for ob in ob_signals),
                }
                señales.append(señal)
        return señales

    def analyze_coincidencias_1m_5m(self, data_1m, tested_1m, validated_5m, ob_signals):
        """
        Evalúa coincidencias entre niveles 1M y 5M, combinando proximidad relativa y absoluta.
        Devuelve una lista de señales válidas.
        """
        señales = []
        if not tested_1m or not validated_5m:
            return señales

        current_price = data_1m['close'].iloc[-1]
        proximidad_relativa = current_price * 0.001  # 0.1% del precio actual
        proximidad_absoluta = 0.1  # Por ejemplo, 0.1 unidades de precio

        last = data_1m.iloc[-1]
        prev = data_1m.iloc[-2]  # Agregamos la vela anterior
        direction = 'Buy' if last['close'] > last['open'] else 'Sell'

        for lvl1 in tested_1m:
            for lvl5 in validated_5m:
                # Combinamos ambos criterios: la proximidad debe ser menor que *ambos* límites.
                if abs(lvl1 - lvl5) <= min(proximidad_relativa, proximidad_absoluta):
                    # Aseguramos que todas las características estén presentes
                    price_action = self.calcular_price_action(data_1m)
                    trend = direction  # La tendencia aquí se basa en la última vela de 1M
                    body_size = self.calcular_body_size(last)
                    mecha_superior_pct = self.calcular_mecha_superior_pct(last)
                    mecha_inferior_pct = self.calcular_mecha_inferior_pct(last)
                    prev_body_size = self.calcular_prev_body_size(prev)  # Usamos prev
                    ob_body_size = self.calcular_ob_body_size(last)

                    señal = {
                        "Type": direction,
                        "Level": lvl1,
                        "Reason": "Coincidencia 1M-5M",
                        "Confidence": "Alta",
                        "OrderBlockRelacionado": any(abs(lvl1 - ob['nivel_ob']) <= 0.0008 for ob in ob_signals),
                        # Características para el modelo de dirección
                        "price_action": price_action,
                        "Trend": trend,
                        "body_size": body_size,
                        "mecha_superior_pct": mecha_superior_pct,
                        "mecha_inferior_pct": mecha_inferior_pct,
                        "prev_body_size": prev_body_size,
                        "ob_body_size": ob_body_size,
                    }
                    señales.append(señal)
        return señales

    def analyze_flexible_strategy(self, data_1m, data_5m, flexible_m5_analyzer, flexible_m1_analyzer):
        """
        Ejecuta la estrategia flexible detectando niveles en 5M y buscando confirmaciones en 1M,
        considerando la proximidad del precio actual al nivel.
        Asegura que se proporcionen todas las características necesarias para el modelo de dirección.
        """
        señales_finales = []

        try:
            esquemas_5m = flexible_m5_analyzer.analyze(data_5m)
            señales_1m = flexible_m1_analyzer.analyze_concepts(data_1m, esquemas_5m)
            
            current_price = data_1m['close'].iloc[-1]
            proximidad_relativa = current_price * 0.001  # 0.1% del precio actual
            proximidad_absoluta = 0.1  # Por ejemplo, 0.1 unidades de precio

            for señal in señales_1m:
                level = señal.get("Level")
                tipo = señal.get("Type", "Unknown")
                reason = señal.get("Reason", "Flexible")
                confidence = señal.get("Confidence", "Media")

                # Verificamos si esta señal tiene un esquema 5M cerca
                esquema_relacionado = None
                for esquema in esquemas_5m:
                    if abs(level - esquema['Level']) <= 0.0005:
                        esquema_relacionado = esquema
                        break
                
                # Solo considerar la señal si el precio está cerca del nivel
                if abs(current_price - level) <= min(proximidad_relativa, proximidad_absoluta):

                    # Dirección asegurada
                    direccion = tipo if tipo in ["Buy", "Sell"] else "Buy"  # define dirección correctamente

                    # *** Aseguramos que todas las características estén presentes ***
                    price_action = self.calcular_price_action(data_1m)  # Debes implementar esta función
                    trend = self.obtener_tendencia(data_5m)  # Debes implementar esta función
                    body_size = self.calcular_body_size(data_1m)  # Debes implementar esta función
                    mecha_superior_pct = self.calcular_mecha_superior_pct(data_1m)  # Debes implementar esta función
                    mecha_inferior_pct = self.calcular_mecha_inferior_pct(data_1m)  # Debes implementar esta función
                    prev_body_size = self.calcular_prev_body_size(data_1m)  # Debes implementar esta función
                    ob_body_size = self.calcular_ob_body_size(data_1m)  # Debes implementar esta función

                    señal_flexible = {
                        "Type": direccion,
                        "Level": level,
                        "Confidence": confidence,
                        "Categoria": "Flexible",
                        "Reason": reason,
                        "Strategy": "Flexible_M1M5",
                        "Nombre": f"{reason} confirmado en esquema flexible",
                        "Esquema": esquema_relacionado['scheme'] if esquema_relacionado else "Sin esquema",
                        "OrderBlockRelacionado": False,
                        "price_action": price_action,
                        "Trend": trend,
                        "body_size": body_size,
                        "mecha_superior_pct": mecha_superior_pct,
                        "mecha_inferior_pct": mecha_inferior_pct,
                        "prev_body_size": prev_body_size,
                        "ob_body_size": ob_body_size,
                    }

                    señales_finales.append(señal_flexible)

        except Exception as e:
            logging.error(f"Error en estrategia flexible: {e}")

        return señales_finales

    def _detectar_bos_choch(self):
        """
        Detecta niveles BOS/CHOCH para diagnóstico de estructura.
        Retorna lista de niveles/señales detectadas.
        """
        try:
            # Verificar datos disponibles
            if self.data_1m is None or self.data_5m is None:
                logging.warning("Datos 1M o 5M no disponibles para BOS/CHOCH")
                self.bos_choch = []
                return []
            
            # Obtener tendencia
            tendencia = self.m5_analyzer.get_trend(self.data_5m)
            
            # Verificar analyzers
            if self.flexible_m1_analyzer is None or self.flexible_m5_analyzer is None:
                logging.warning("Analyzers no disponibles para BOS/CHOCH")
                self.bos_choch = []
                return []
            
           
            
            # Detectar BOS/CHOCH (asumiendo que la función existe)
            if hasattr(self, 'detectar_bos_choch') or 'detectar_bos_choch' in globals():
                bos_choch_results = detectar_bos_choch(self.data_1m, tendencia_actual=tendencia)
            else:
                # Si no existe la función externa, crear estructura básica
                logging.warning("Función detectar_bos_choch no encontrada, creando estructura vacía")
                bos_choch_results = []
            
            # Asignar y retornar
            self.bos_choch = bos_choch_results if isinstance(bos_choch_results, list) else []
            
            logging.info(f"BOS/CHOCH detectados: {len(self.bos_choch)}")
            return self.bos_choch
            
        except Exception as e:
            logging.error(f"Error en _detectar_bos_choch: {e}")
            self.bos_choch = []
            return []

    def detectar_sibi_bisi(self):
        if self.data_1m is not None:
            self.sibi_bisi = detectar_fvg(self.data_1m)
        else:
            self.sibi_bisi = []
    
    def _calculate_sibi_bisi_and_bos_choch(self, data_30m, data_5m):
        """
        Calculates simplified string states for SIBI, BISI, BOS, and CHoCH
        based on overall market context (30M, 5M data).
        """
        sibi_estado = "none"
        bisi_estado = "none"
        bos_resultado = "none"
        choch_resultado = "none"

        try:
            if not data_30m.empty and len(data_30m) >= 2 and not data_5m.empty and len(data_5m) >= 2:
                last_30m_close = data_30m['close'].iloc[-1]
                last_5m_close = data_5m['close'].iloc[-1]

                # Simplified SIBI/BISI logic based on your provided snippet
                if last_30m_close > last_5m_close:
                    sibi_estado = "presente"
                else:
                    bisi_estado = "presente"
                
                # Simplified BOS logic based on your provided snippet
                if data_5m['close'].iloc[-1] > data_5m['close'].iloc[-2]:
                    bos_resultado = "alcista"
                else:
                    bos_resultado = "bajista"
                
                # Simplified CHoCH logic based on your provided snippet
                # If CHoCH is always 'bajista' as per your log, you can set it directly.
                # If it should be based on something else, modify this logic.
                choch_resultado = "bajista" 

            elif not data_30m.empty or not data_5m.empty: # One is empty, one is not
                logging.warning("Insufficient candles in 30M or 5M for precise SIBI/BISI/BOS/CHoCH calculation. Using default values.")
            else: # Both are empty
                logging.warning("30M or 5M DataFrames are empty, cannot calculate SIBI/BISI/BOS/CHoCH.")

        except Exception as e:
            logging.error(f"Error during SmartMoneyConcepts calculation: {e}", exc_info=True) # Use exc_info for full traceback
        
        return sibi_estado, bisi_estado, bos_resultado, choch_resultado

    def resumen_bos_choch(self): # <--- PLACE THE FUNCTION HERE
        """
        Genera un resumen de los últimos eventos BOS y CHoCH detectados.
        """
        resumen = {"bos": "none", "choch": "none"}
        for item in self.bos_choch:
            if item.get("tipo") == "bos":
                resumen["bos"] = item.get("direccion", "unknown")
            elif item.get("tipo") == "choch":
                resumen["choch"] = item.get("direccion", "unknown")
        return resumen
    def detectar_orderblocks(self):
        if self.data_5m is not None and self.data_1m is not None:
            niveles = self.m5_analyzer.find_tested_levels(self.data_5m)
            resultado = detectar_order_blocks(self.data_5m, self.data_1m, niveles)

            if isinstance(resultado, list) and all(isinstance(x, dict) for x in resultado):
                self.orderblocks = resultado
            else:
                print(" detectar_order_blocks devolvió un tipo inesperado")
                self.orderblocks = []
        else:
            self.orderblocks = []
    def _detect_fvg(self, data: pd.DataFrame) -> List[Dict[str, Any]]:
        """
        Detecta Fair Value Gaps (FVG), BISI y SIBI en los datos de precio y genera señales.
        Este es el método interno de la clase TradingBot.

        Args:
            data (pd.DataFrame): DataFrame con datos de velas (high, low, open, close, time).
                                 Debería ser self.candles_m1 o self.candles_m5.

        Returns:
            list: Lista de diccionarios, donde cada diccionario representa un FVG, BISI o SIBI
                  y contiene información para generar una señal de trading.
        """
        fvg_zonas = []
        
        if data.empty or len(data) < 3:
            logging.debug("FVG: Datos insuficientes para detectar FVG. Se requieren al menos 3 velas.")
            return fvg_zonas

        current_price = data['close'].iloc[-1]
        proximidad_relativa = current_price * 0.005  # 0.5% del precio actual
        proximidad_absoluta = 0.5  # 0.5 unidades de precio (ajusta según el instrumento)
        
        # Iteramos en orden inverso para encontrar los patrones más recientes primero
        for i in range(len(data) - 1, 2, -1):
            # Si ya tenemos suficientes patrones, paramos
            if len(fvg_zonas) >= self.fvg_max_patterns:
                break
                
            vela_1 = data.iloc[i - 2]
            vela_2 = data.iloc[i - 1]
            vela_3 = data.iloc[i]

            # --- FVG Alcista ---
            # Un FVG alcista ocurre cuando el low de la vela 2 es mayor que el high de la vela 1
            # y el low de la vela 2 es mayor que el high de la vela 3.
            # Esto crea un "vacío" de liquidez que el precio tiende a rellenar.
            if vela_2['low'] > vela_1['high'] and vela_2['low'] > vela_3['high']:
                nivel_fvg = vela_2['low']
                # Solo comprobamos proximidad si no estamos ignorándola
                if self.fvg_ignore_proximity or abs(current_price - nivel_fvg) <= min(proximidad_relativa, proximidad_absoluta):
                    fvg_zonas.append({
                        'tipo': 'fvg_alcista',
                        'señal': 'Compra',  # Señal de compra para FVG alcista
                        'zona_superior': vela_1['high'],
                        'zona_inferior': vela_3['low'],
                        'nivel': nivel_fvg,  # Añadimos el nivel específico
                        'timestamp': vela_2['time'],
                        'esquema': 'FVG',
                        'Confidence': 'Media',
                        'distancia_precio': abs(current_price - nivel_fvg)
                    })

            # --- FVG Bajista ---
            # Un FVG bajista ocurre cuando el high de la vela 2 es menor que el low de la vela 1
            # y el high de la vela 2 es menor que el low de la vela 3.
            # Esto también crea un "vacío" de liquidez.
            elif vela_2['high'] < vela_1['low'] and vela_2['high'] < vela_3['low']:
                nivel_fvg = vela_2['high']
                if self.fvg_ignore_proximity or abs(current_price - nivel_fvg) <= min(proximidad_relativa, proximidad_absoluta):
                    fvg_zonas.append({
                        'tipo': 'fvg_bajista',
                        'señal': 'Venta',  # Señal de venta para FVG bajista
                        'zona_superior': vela_1['low'],
                        'zona_inferior': vela_3['high'],
                        'nivel': nivel_fvg,  # Añadimos el nivel específico
                        'timestamp': vela_2['time'],
                        'esquema': 'FVG',
                        'Confidence': 'Media',
                        'distancia_precio': abs(current_price - nivel_fvg)
                    })

            # --- BISI (Buy-Side Imbalance Sell-Side Inefficiency) ---
            # Un BISI indica una ineficiencia del lado de la venta, a menudo un área donde el precio
            # podría subir para rellenar.
            elif (vela_1['close'] > vela_1['open'] and   # Vela 1 alcista (verde)
                  vela_3['close'] < vela_3['open'] and   # Vela 3 bajista (roja)
                  vela_2['low'] > max(vela_1['high'], vela_3['high'])):  # Vela 2 por encima
                nivel_bisi = vela_2['low']
                if self.fvg_ignore_proximity or abs(current_price - nivel_bisi) <= min(proximidad_relativa, proximidad_absoluta):
                    fvg_zonas.append({
                        'tipo': 'bisi',
                        'señal': 'Venta',  # Señal de venta para BISI (esperamos que el precio caiga para rellenar)
                        'zona_superior': vela_2['low'],
                        'zona_inferior': max(vela_1['high'], vela_3['high']),
                        'nivel': nivel_bisi,  # Añadimos el nivel específico
                        'timestamp': vela_2['time'],
                        'esquema': 'BISI',
                        'Confidence': 'Alta',
                        'distancia_precio': abs(current_price - nivel_bisi)
                    })

            # --- SIBI (Sell-Side Imbalance Buy-Side Inefficiency) ---
            # Un SIBI indica una ineficiencia del lado de la compra, a menudo un área donde el precio
            # podría caer para rellenar.
            elif (vela_1['close'] < vela_1['open'] and   # Vela 1 bajista (roja)
                  vela_3['close'] > vela_3['open'] and   # Vela 3 alcista (verde)
                  vela_2['high'] < min(vela_1['low'], vela_3['low'])):  # Vela 2 por debajo
                nivel_sibi = min(vela_1['low'], vela_3['low'])
                if self.fvg_ignore_proximity or abs(current_price - nivel_sibi) <= min(proximidad_relativa, proximidad_absoluta):
                    fvg_zonas.append({
                        'tipo': 'sibi',
                        'señal': 'Compra',  # Señal de compra para SIBI (esperamos que el precio suba para rellenar)
                        'zona_superior': min(vela_1['low'], vela_3['low']),
                        'zona_inferior': vela_2['high'],
                        'nivel': nivel_sibi,  # Añadimos el nivel específico
                        'timestamp': vela_2['time'],
                        'esquema': 'SIBI',
                        'Confidence': 'Alta',
                        'distancia_precio': abs(current_price - nivel_sibi)
                    })
        
        # Ordenamos por distancia al precio actual para priorizar los más cercanos
        fvg_zonas.sort(key=lambda x: x['distancia_precio'])
        return fvg_zonas
    def detectar_consolidaciones(self):
        if self.data_5m is not None:
            niveles = self.m5_analyzer.find_tested_levels(self.data_5m)
            self.consolidaciones = detectar_consolidaciones(self.data_5m, niveles)
        else:
            self.consolidaciones = []

    def analizar_estructura_total(self):
        self.detectar_bos_choch()
        self.detectar_sibi_bisi()
        self.detectar_orderblocks()
        self.detectar_consolidaciones()

    def estructura_valida(self):
        return bool(self.bos_choch) or any(x['tipo'] in ['sibi', 'bisi'] for x in self.sibi_bisi)

    def analizar_y_validar_estructura(self):
        self.analizar_estructura_total()
        if not self.estructura_valida():
            print(" Estructura inválida: no hay BOS/CHOCH ni SIBI/BISI.")
            return False
        print(" Estructura válida detectada.")
        return True

    def determinar_tendencia(self, data, ventana=10):
        """
        Determina la tendencia predominante en los datos usando un método simple de comparación de medias móviles.

        Args:
            data (pd.DataFrame): DataFrame con datos de velas.
            ventana (int): Número de velas para el cálculo de la media móvil.

        Returns:
            str: "Alcista" o "Bajista".
        """
        data['SMA'] = data['close'].rolling(window=ventana).mean()
        ultima_media = data['SMA'].iloc[-1]
        penultima_media = data['SMA'].iloc[-2]

        if ultima_media > penultima_media:
            return "Alcista"
        else:
            return "Bajista"
    # ========== Funciones auxiliares de gestión de flips ==========

    def get_flip_info(self, level, distance_threshold=float('inf'), time_threshold=float('inf')):
        """
        Obtiene flips ya detectados por FlexibleM1Analyzer y FlexibleM5Analyzer,
        filtrando por distancia y tiempo.
        """
        relevant_flips = []
        now = time.time()

        fuentes = []

        # 1. Flips del M5Analyzer
        if hasattr(self, 'flexible_m5_analyzer') and hasattr(self.flexible_m5_analyzer, 'levels_df'):
            df = self.flexible_m5_analyzer.levels_df
            if not df.empty:
                flips_m5 = df[df['Type'].str.contains('Flip', case=False)].to_dict('records')
                for flip in flips_m5:
                    flip['Source'] = 'M5'
                fuentes.extend(flips_m5)

        # 2. Flips del M1Analyzer
        if hasattr(self, 'flexible_m1_analyzer') and hasattr(self.flexible_m1_analyzer, 'levels_df'):
            df = self.flexible_m1_analyzer.levels_df
            if not df.empty:
                flips_m1 = df[df['Type'].str.contains('Flip', case=False)].to_dict('records')
                for flip in flips_m1:
                    flip['Source'] = 'M1'
                fuentes.extend(flips_m1)

        # 3. Flips recientes (si están)
        if hasattr(self, 'flip_1m_recientes') and self.flip_1m_recientes:
            for flip in self.flip_1m_recientes:
                flip['Source'] = 'Recientes'
            fuentes.extend(self.flip_1m_recientes)

        # 4. Filtrar por distancia y tiempo
        for flip in fuentes:
            distancia = abs(level - flip.get('Level', 0))
            timestamp = flip.get('timestamp', now)
            tiempo_pasado = now - timestamp if isinstance(timestamp, (float, int)) else 0

            if distancia <= distance_threshold and tiempo_pasado <= time_threshold:
                relevant_flips.append(flip)

        return relevant_flips


    def find_relevant_flips(self, signal_level, signal_type, distance_threshold=0.0005, time_threshold=30):
        try:
            return [
                flip for flip in self.get_flip_info(signal_level, distance_threshold, time_threshold)
                if flip.get('Trend', '').lower() == signal_type.lower()
            ]
        except Exception as e:
            logging.error(f"Error al encontrar flips relevantes: {e}")
            return []


    def check_flip_distance(self, current_price, flip_level, max_distance=0.002):
        return abs(current_price - flip_level) <= max_distance


    def get_new_signal_based_on_flip(self, current_price, trend_direction):
        flip_levels = [f['Level'] for f in self.get_flip_info(current_price, distance_threshold=0.001)]
        closest_flip = None

        for level in sorted(flip_levels):
            if trend_direction == "Alcista" and level > current_price:
                closest_flip = level
                break
            elif trend_direction == "Bajista" and level < current_price:
                closest_flip = level
                break

        if closest_flip:
            return {
                "Type": "Buy" if trend_direction == "Alcista" else "Sell",
                "Level": closest_flip,
                "Reason": "Flip cercano basado en tendencia",
                "Confidence": "Alta",
                "Categoria": "Flip Detectado",
                "Strategy": "Reversión",
                "Nombre": f"Flip en nivel {closest_flip}",
                "OrderBlockRelacionado": False,
                "Esquema": "Reversión"
            }
        return None


    def detectar_flip_tocado(self, current_price, vela, tolerancia_precio=0.0002, tolerancia_vela=0.0002):
        """
        Verifica si el precio actual o la vela ha tocado un flip detectado por los analyzers.
        """
        flip_tocado = None
        max_price = vela.get('high')
        min_price = vela.get('low')

        for flip in self.get_flip_info(current_price, distance_threshold=0.002):
            nivel = flip.get('Level')
            tipo = flip.get('Type')
            if nivel is not None:
                try:
                    nivel = float(nivel)
                    # Check por precio actual
                    if abs(current_price - nivel) <= tolerancia_precio:
                        flip_tocado = {"Level": nivel, "Type": tipo, "Source": flip.get('Source', 'Unknown')}
                        logging.info(f"Flip tocado por precio actual en {nivel} (Tipo: {tipo})")
                        return flip_tocado
                    # Check por vela
                    if max_price and min_price and (min_price - tolerancia_vela <= nivel <= max_price + tolerancia_vela):
                        flip_tocado = {"Level": nivel, "Type": tipo, "Source": flip.get('Source', 'Unknown')}
                        logging.warning(f"Flip tocado por vela en {nivel} (rango: {min_price}-{max_price}, Tipo: {tipo})")
                        return flip_tocado
                except Exception as e:
                    logging.warning(f"Error al procesar flip: {e}")
                    continue

        return None


    def detectar_liquidez(self, data_1m, ventana=10):
        """
        Identifica zonas de liquidez (Equal Highs/Lows) en el gráfico de 1 minuto.
        """
        liquidez_signals = []
        current_price_1m = data_1m['close'].iloc[-1]
        proximidad_relativa = current_price_1m * 0.001  # 0.1% del precio actual
        proximidad_absoluta = 0.1  # Por ejemplo, 0.1 unidades de precio

        for i in range(ventana, len(data_1m)):
            ventana_velas = data_1m.iloc[i - ventana:i]
            vela_actual = data_1m.iloc[i]

            # Equal Highs
            maximos = ventana_velas['high']
            if (len(set(maximos)) <= 2 and  # Casi todos los máximos iguales
                    maximos.max() == ventana_velas['high'].iloc[-1] and  # Máximo reciente
                    abs(current_price_1m - maximos.max()) <= min(proximidad_relativa, proximidad_absoluta)):
                liquidez_signals.append({
                    'tipo': 'Equal Highs',
                    'nivel': maximos.max(),
                    'timestamp': vela_actual['time'],
                    'esquema': 'Liquidez'
                })

            # Equal Lows
            minimos = ventana_velas['low']
            if (len(set(minimos)) <= 2 and  # Casi todos los mínimos iguales
                    minimos.min() == ventana_velas['low'].iloc[-1] and  # Mínimo reciente
                    abs(current_price_1m - minimos.min()) <= min(proximidad_relativa, proximidad_absoluta)):
                liquidez_signals.append({
                    'tipo': 'Equal Lows',
                    'nivel': minimos.min(),
                    'timestamp': vela_actual['time'],
                    'esquema': 'Liquidez'
                })
        return liquidez_signals    
    def deep_check_json_serializable(obj):
        try:
            json.dumps(obj)
            return True
        except Exception as e:
            raise ValueError(f"No serializable: {e}")
    async def analyze_and_report(self):
        """
        Analiza señales de trading utilizando la IA para la decisión principal,
        con detección integrada de estructura de mercado (BOS/CHOCH/FVG) como confirmación
        y FLIPS como factor de influencia para señales recientes y cercanas al precio.
        No ejecuta operaciones, solo reporta las 3 mejores señales y las guarda en diagnostico_actual.json.
        """
        try:
            logging.info("Iniciando análisis de señales (sin ejecución)...")

            await self.update_candles()

            if any(df is None or not isinstance(df, pd.DataFrame) or df.empty for df in [self.data_30m, self.data_5m, self.data_1m]):
                logging.warning("Datos de velas no disponibles o vacíos.")
                return {
                    "estado": "sin_datos",
                    "mensaje": "Datos de velas no disponibles o vacíos",
                    "señales": [],
                    "estructura_mercado": {"sibi": "none", "bisi": "none", "bos": "none", "choch": "none"}
                }

            # Asegurar columna de volumen
            self._ensure_volume_column(self.data_30m, '30m')
            self._ensure_volume_column(self.data_5m, '5m')
            self._ensure_volume_column(self.data_1m, '1m')
                
            # Resetear contenedores de señales
            self.todas_las_senales = [s for s in self.todas_las_senales if isinstance(s, dict)]

            self.bos_choch = []
            
            self.consolidaciones = []
            self.sibi_bisi = []
            self.orderblocks = [ob for ob in self.orderblocks if isinstance(ob, dict)]

            # ======= OBTENER PRECIO ACTUAL =======
            async def get_current_price():
                """Obtiene el precio actual priorizando broker sobre chart"""
                broker_price = None
                try:
                    if hasattr(self, 'get_broker_price') and callable(getattr(self, 'get_broker_price')):
                        broker_price = await self.get_broker_price()
                    elif hasattr(self, 'current_tick') and hasattr(self.current_tick, 'price'):
                        broker_price = self.current_tick.price
                except Exception as e:
                    logging.debug(f"No se pudo obtener precio del broker: {e}")
                
                chart_price = self.data_1m['close'].iloc[-1] if not self.data_1m.empty else None
                current_price = broker_price if broker_price is not None else chart_price
                
                return {
                    "price": current_price,
                    "broker_price": broker_price,
                    "chart_price": chart_price,
                    "source": "broker" if broker_price is not None else "chart",
                    "timestamp": datetime.now().isoformat()
                }

            price_data = await get_current_price()
            current_price = price_data["price"]
            
            if current_price is None:
                logging.error("No se pudo obtener el precio actual. Abortando análisis.")
                return {
                    "estado": "error",
                    "mensaje": "No se pudo obtener el precio actual",
                    "señales": [],
                    "estructura_mercado": {"sibi": "none", "bisi": "none", "bos": "none", "choch": "none"}
                }
            
            logging.info(f"Precio actual: {current_price} (fuente: {price_data['source']})")

            # ======= ANÁLISIS DE TENDENCIAS =======
            trend_30m = self.m30_analyzer.get_trend(self.data_30m)
            trend_5m = self.m5_analyzer.get_trend(self.data_5m)
            m1_trend = self.m1_analyzer.get_trend(self.data_1m)
            
            logging.info(f"Tendencia 30M: {trend_30m}, Tendencia 5M: {trend_5m}")

            # ======= DETECCIÓN DE FLIPS RECIENTES (PRIORIDAD ALTA) =======
            logging.info("Detectando flips recientes en 1M...")
            self.flip_1m_recientes = []
            flip_influence_zones = []  # Zonas de influencia de flips
             # ======= DETECCIÓN DE FLIPS RECIENTES (PRIORIDAD ALTA) =======
            logging.info("Detectando flips recientes en 1M...")
            self.flip_1m_recientes = []
            flip_influence_zones = []  # Zonas de influencia de flips
            if (hasattr(self.flexible_m1_analyzer, 'levels_df') and 
                isinstance(self.flexible_m1_analyzer.levels_df, pd.DataFrame) and 
                not self.flexible_m1_analyzer.levels_df.empty):
                
                # Detectar flips recientes (últimas 20 velas para mayor contexto)
                recent_cutoff = datetime.now() - timedelta(minutes=20)
                
                for _, row in self.flexible_m1_analyzer.levels_df.iterrows():
                    if "Flip" in str(row['Type']):
                        flip_timestamp = row.get('timestamp')
                        flip_level = float(row.get('Level', 0))
                        
                        # Determinar si es flip reciente
                        is_recent = True
                        if flip_timestamp:
                            try:
                                flip_time = datetime.fromisoformat(flip_timestamp) if isinstance(flip_timestamp, str) else flip_timestamp
                                is_recent = flip_time >= recent_cutoff
                            except:
                                pass
                        
                        # Calcular distancia al precio actual
                        distance_to_price = abs(flip_level - current_price)
                        proximity_score = max(0, 1 - distance_to_price / (current_price * 0.002))
                        
                        # Crear señal de flip con scoring mejorado
                        flip_signal = {
                            "Level": flip_level,
                            "Type": "Buy" if "Bullish" in str(row.get("Trend", "")) else "Sell",
                            "timestamp": flip_timestamp or datetime.now().isoformat(),
                            "Categoria": "Flip",
                            "Strategy": "Flip_1M_Reciente",
                            "Confidence": "Alta" if is_recent and proximity_score > 0.7 else "Media",
                            "Reason": f"Flip {'reciente' if is_recent else 'histórico'} en nivel 1M",
                            "OrderBlockRelacionado": False,
                            "Esquema": "Level_Flip",
                            "Nombre": f"Flip {'alcista' if 'Bullish' in str(row.get('Trend', '')) else 'bajista'} {'reciente' if is_recent else ''}",
                            "is_recent_flip": is_recent,
                            "proximity_to_current_price": proximity_score,
                            "distancia_precio_actual": distance_to_price,
                            "flip_influence_radius": current_price * 0.0015  # Radio de influencia del flip
                        }
                        
                        self.flip_1m_recientes.append(flip_signal)
                        self.todas_las_senales.extend(flip_signal)

                        # Crear zona de influencia para potenciar otras señales
                        if is_recent and proximity_score > 0.5:
                            flip_influence_zones.append({
                                "center": flip_level,
                                "radius": current_price * 0.0015,
                                "type": flip_signal["Type"],
                                "strength": proximity_score,
                                "timestamp": flip_signal["timestamp"]
                            })
                
                logging.info(f"Detectados {len(self.flip_1m_recientes)} flips, {len(flip_influence_zones)} con influencia activa")

            # ======= DETECCIÓN DE ESTRUCTURA DE MERCADO (UNIFICADA) =======
            # 1. Detectar BOS y CHOCH
            bos_choch_signals = self._detectar_bos_choch() 
            self.bos_choch.extend(bos_choch_signals)
            self.todas_las_senales.extend(bos_choch_signals)
            
            # 2. Detectar FVGs (BISI/SIBI)
            fvg_signals = detectar_fvg(self.data_1m, max_patrones=5, ignorar_proximidad=False)
            for fvg_s in fvg_signals:
                fvg_s.update({
                    'Categoria': 'FVG',
                    'Strategy': 'FVG_Strategy',
                    'OrderBlockRelacionado': False,
                    'Nombre': f"{fvg_s.get('Esquema', 'FVG')} {'alcista' if fvg_s.get('Type') == 'Buy' else 'bajista'} detectado en 1M",
                    'timestamp': fvg_s.get('timestamp', datetime.now().isoformat())
                })
            
            self.sibi_bisi.extend(fvg_signals)
            self.todas_las_senales.extend(fvg_signals)

            # 3. Generar resumen de estructura una sola vez
            resumen_estructura = generar_resumen_estructura(bos_choch_signals)
            
            
            # Analizar estado FVG reciente (últimas 10 velas)
            sibi_estado = "none"
            bisi_estado = "none"
            num_velas_recientes = 10
            
            if fvg_signals and not self.data_1m.empty:
                try:
                    last_1m_time = pd.to_datetime(self.data_1m.index[-1])
                    for fvg in sorted(fvg_signals, key=lambda x: x.get('timestamp', ''), reverse=True)[:num_velas_recientes]:
                        if 'timestamp' not in fvg:
                            continue
                        try:
                            fvg_time = datetime.fromisoformat(fvg['timestamp'])
                            time_diff = (last_1m_time.to_pydatetime() - fvg_time).total_seconds()
                            if time_diff <= (num_velas_recientes * 60):
                                if fvg.get('tipo') == 'sibi' or fvg.get('Esquema') == 'SIBI':
                                    sibi_estado = "reciente"
                                elif fvg.get('tipo') == 'bisi' or fvg.get('Esquema') == 'BISI':
                                    bisi_estado = "reciente"
                        except (ValueError, TypeError):
                            continue

                except Exception as e:
                    logging.warning(f"Error al analizar FVGs recientes: {e}")

            # Estado final de estructura de mercado
            self.estructura_mercado = {
                "sibi": sibi_estado,
                "bisi": bisi_estado,
                "bos": resumen_estructura.get("bos", "none"),
                "choch": resumen_estructura.get("choch", "none"),
                "flips_recientes": len([f for f in self.flip_1m_recientes if f.get("is_recent_flip", False)]),
                "flip_influence_active": len(flip_influence_zones) > 0
            }

            # ======= DETECCIÓN DE ORDER BLOCKS Y CONSOLIDACIONES =======
            tested_levels_5m = self.m5_analyzer.find_tested_levels(self.data_5m)
            ob_signals = detectar_order_blocks(self.data_5m, self.data_1m, tested_levels_5m)
            consolidation_signals = detectar_consolidaciones(self.data_5m, tested_levels_5m)
            
            if isinstance(consolidation_signals, list):
                ob_signals.extend(consolidation_signals)
            
            # Procesar señales OB y consolidación
            for ob in ob_signals:
                if isinstance(ob, dict):
                    ob_entry = {
                        "Type": "Buy" if ob.get("tipo") == "compra" else "Sell",
                        "Level": float(ob.get("nivel_ob", ob.get("Level", 0))),
                        "Reason": ob.get("Reason", "OrderBlock"),
                        "Confidence": ob.get("Confidence", "Media"),
                        "Categoria": ob.get("Categoria", "OrderBlock"),
                        "Strategy": ob.get("Strategy", "OB_Strategy"),
                        "Nombre": f"OrderBlock {'alcista' if ob.get('tipo') == 'compra' else 'bajista'}",
                        "OrderBlockRelacionado": ob.get("OrderBlockRelacionado", True),
                        "Esquema": ob.get("Esquema", "N/A"),
                        "timestamp": ob.get("timestamp", datetime.now().isoformat())
                    }
                    self.todas_las_senales.append(ob_entry)
                    
                    if ob_entry.get("Categoria") == "OrderBlock":
                        self.orderblocks.append(ob_entry)
                    elif ob_entry.get("Categoria") == "Consolidacion":
                        self.consolidaciones.append(ob_entry)

            # ======= VALIDACIONES EN 5M =======
            validated_5m = self.m5_analyzer.validate_concepts(self.data_5m, tested_levels_5m, trend_30m)
            if not validated_5m:
                validated_5m = [
                    {
                        "Level": lvl,
                        "Type": "Buy" if trend_5m == "Alcista" else "Sell",
                        "Confidence": "Media",
                        "Categoria": "Validacion5M",
                        "Reason": "Nivel probado 5M",
                        "timestamp": self.data_5m.index[-1].isoformat() if not self.data_5m.empty else datetime.now().isoformat()
                    }
                    for lvl in tested_levels_5m
                ]
            self.todas_las_senales.extend(validated_5m)

            # ======= COINCIDENCIAS 1M-5M =======
            tested_levels_1m = self.m1_analyzer.find_tested_levels(self.data_1m, current_price)
            proximidad_coincidencia = current_price * 0.0001
            
            for lvl1 in tested_levels_1m:
                for lvl5 in validated_5m:
                    if isinstance(lvl5, dict) and abs(lvl1 - lvl5.get("Level", 0)) <= proximidad_coincidencia:
                        self.todas_las_senales.append({
                            "Type": "Buy" if trend_5m == "Alcista" else "Sell",
                            "Level": lvl1,
                            "Reason": "Coincidencia 1M-5M",
                            "Confidence": "Alta",
                            "Categoria": "Coincidencia",
                            "Strategy": "Coincidencia_1M5M",
                            "Nombre": "Coincidencia niveles",
                            "OrderBlockRelacionado": any(
                                abs(lvl1 - ob.get("Level", 0)) <= 0.0008 
                                for ob in self.todas_las_senales 
                                if isinstance(ob, dict) and ob.get("Categoria")
                            ),
                            "timestamp": self.data_1m.index[-1].isoformat() if not self.data_1m.empty else datetime.now().isoformat()
                        })
            
            # ======= SEÑALES INDEPENDIENTES 1M =======
            señales_indep = self.analyze_independent_1m(self.data_1m, tested_levels_1m)
            for señal in señales_indep:
                if isinstance(señal, dict):
                    señal.update({
                        "Categoria": "Independiente",
                        "Strategy": "1M_Patrones",
                        "OrderBlockRelacionado": False,
                        "timestamp": señal.get("timestamp", self.data_1m.index[-1].isoformat() if not self.data_1m.empty else datetime.now().isoformat())
                    })
                    self.todas_las_senales.append(señal)

            # ======= ESTRATEGIAS FLEXIBLES =======
            logging.info("Evaluando estrategias flexibles...")
            
            # Análisis flexible 5M
            esquemas_5m = self.flexible_m5_analyzer.analyze(self.data_5m)
            
            # Análisis flexible 1M
            señales_1m_flexible = self.flexible_m1_analyzer.analyze_concepts(self.data_1m, esquemas_5m)
            for s in señales_1m_flexible:
                if 'timestamp' not in s:
                    s['timestamp'] = datetime.now().isoformat()
                self.todas_las_senales.append(s)

            # ======= INTEGRACIÓN COMPLETA DE FLIPS =======
            logging.info(f"Integrando {len(self.flip_1m_recientes)} flips al análisis principal...")
            self.todas_las_senales.extend(self.flip_1m_recientes)

            # ======= INFORMACIÓN DE PRECIOS Y ESTRUCTURA BASE =======
            precio_info = {
                "broker_price": price_data["broker_price"],
                "chart_price": price_data["chart_price"],
                "final_price_used": current_price,
                "price_source": price_data["source"],
                "timestamp_precio": price_data["timestamp"]
            }

            resultado_base = {
                "timestamp": datetime.now().isoformat(),
                "precio_actual": current_price,
                "info_precios": precio_info,
                "tendencia_30m": trend_30m,
                "tendencia_5m": trend_5m,
                "total_señales_detectadas": len(self.todas_las_senales),
                "estructura_mercado": self.estructura_mercado,
                "flips_info": {
                    "total_flips": len(self.flip_1m_recientes),
                    "flips_recientes": len([f for f in self.flip_1m_recientes if f.get("is_recent_flip", False)]),
                    "zonas_influencia_activas": len(flip_influence_zones)
                }
            }

            # Validación de estructura (solo informativa)
            if not self.estructura_valida():
                logging.warning("⚠️ Estructura inválida: No hay BOS/CHOCH ni SIBI/BISI claros. Las operaciones se basarán en otras señales.")

            if not self.todas_las_senales:
                logging.info("No se detectaron señales válidas.")
                resultado_base.update({
                    "estado": "sin_señales",
                    "mensaje": "No se detectaron señales válidas en ningún criterio.",
                    "señales": []
                })
                
                resultado_limpio = self._clean_for_json(resultado_base)
                with open("diagnostico_actual.json", "w", encoding="utf-8") as f:
                    json.dump(resultado_limpio, f, indent=2, ensure_ascii=False)
                return resultado_limpio

            # ======= RESUMEN DE SEÑALES =======
            categorias = {}
            for señal in self.todas_las_senales:
                cat = señal.get("Categoria", "Desconocido") if isinstance(señal, dict) else "Desconocido"
                categorias[cat] = categorias.get(cat, 0) + 1
            
            logging.info("Resumen de señales encontradas:")
            for categoria, cantidad in categorias.items():
                logging.info(f"    {categoria}: {cantidad}")

            # ======= FUNCIÓN DE SCORING MEJORADA CON INFLUENCIA DE FLIPS =======
            def score_signal(señal, current_price_for_scoring):
                """Función de scoring optimizada con influencia de flips recientes"""
                tipo = señal.get("Type")
                nivel = señal.get("Level", current_price_for_scoring)
                distancia = abs(nivel - current_price_for_scoring)
                cercania = max(0, 1 - distancia / (current_price_for_scoring * 0.001))
                
                # Factores base MEJORADOS para flips
                base_scores = {
                    "OrderBlock": 30, 
                    "Coincidencia": 20, 
                    "Flip": 35,  # ← SCORE BASE ALTO para flips
                    "Independiente": 20, 
                    "Flexible": 20, 
                    "Validacion5M": 20, 
                    "FVG": 10, 
                    "Estructura": 30
                }
                confidence_multiplier = {"Alta": 1, "Media": 0.7, "Baja": 0.3}
                
                # Cálculo de scores
                base_score = base_scores.get(señal.get("Categoria", ""), 0)
                confidence_score = confidence_multiplier.get(señal.get("Confidence", "Media"), 0.7) * 5
                cercania_score = cercania * 2.5
                
                # Bonificaciones estándar
                ob_bonus = 8 if señal.get("OrderBlockRelacionado", False) else 0
                esquema_bonus = {
                    "BOS": 15, "CHoCH": 15, "FVG": 10, "BISI": 12, "SIBI": 12,
                    "Level_Flip": 20  # ← BONUS ALTO para flips
                }.get(señal.get("Esquema", señal.get("esquema", "")), 0)
                
                # ======= NUEVA LÓGICA DE INFLUENCIA DE FLIPS =======
                flip_influence_bonus = 0
                flip_recency_bonus = 0
                flip_proximity_bonus = 0
                
                # Si es un flip, bonificaciones especiales
                if señal.get("Categoria") == "Flip":
                    # Bonus por flip reciente
                    if señal.get("is_recent_flip", False):
                        flip_recency_bonus = 25  # Bonus significativo por ser reciente
                    
                    # Bonus por proximidad al precio actual
                    proximity_score = señal.get("proximity_to_current_price", 0)
                    flip_proximity_bonus = proximity_score * 15  # Hasta 15 puntos extra
                    
                    # Bonus por coherencia con tendencia
                    trend_coherence_bonus = 0
                    if (tipo == "Buy" and trend_5m == "Alcista") or (tipo == "Sell" and trend_5m == "Bajista"):
                        trend_coherence_bonus = 10
                    flip_influence_bonus += trend_coherence_bonus
                
                # Para señales NO-flip: verificar si están en zona de influencia de algún flip
                elif flip_influence_zones:
                    for zone in flip_influence_zones:
                        zone_distance = abs(nivel - zone["center"])
                        if zone_distance <= zone["radius"]:
                            # Señal está en zona de influencia de flip
                            influence_strength = zone["strength"] * (1 - zone_distance / zone["radius"])
                            direction_match = (tipo == zone["type"])
                            
                            # Bonus por estar en zona de flip
                            flip_influence_bonus += influence_strength * 12
                            
                            # Bonus adicional si la dirección coincide
                            if direction_match:
                                flip_influence_bonus += influence_strength * 8
                            
                            logging.debug(f"Señal {señal.get('Nombre', 'Sin nombre')} influenciada por flip (bonus: +{flip_influence_bonus:.1f})")
                            break
                
                # Penalizaciones por contra-tendencia (reducidas para flips recientes)
                contra_tendencia = (
                    (tipo == "Buy" and trend_30m == "Bajista") or
                    (tipo == "Sell" and trend_30m == "Alcista")
                )
                if señal.get("Esquema") != "CHoCH" and (
                    (tipo == "Buy" and trend_5m == "Bajista") or
                    (tipo == "Sell" and trend_5m == "Alcista")
                ):
                    contra_tendencia = True
                
                # Penalización reducida para flips recientes
                if señal.get("Categoria") == "Flip" and señal.get("is_recent_flip", False):
                    tendencia_penalty = -5 if contra_tendencia else 0  # Penalización reducida
                else:
                    tendencia_penalty = -10 if contra_tendencia else 0
                
                # Bonus por cercanía extrema (aumentado para flips)
                super_close_threshold = current_price_for_scoring * 0.0005
                if señal.get("Categoria") == "Flip":
                    super_close_bonus = 20 if distancia < super_close_threshold else 0
                else:
                    super_close_bonus = 15 if distancia < super_close_threshold else 0
                
                # CÁLCULO FINAL
                total_score = (
                    base_score + confidence_score + ob_bonus + cercania_score + 
                    esquema_bonus + tendencia_penalty + super_close_bonus +
                    flip_influence_bonus + flip_recency_bonus + flip_proximity_bonus
                )
                
                # Probabilidad de éxito mejorada para flips
                base_win_rate = 50
                if señal.get("Categoria") == "Flip":
                    base_win_rate = 55  # Base más alta para flips
                    if señal.get("is_recent_flip", False):
                        base_win_rate += 8  # Bonus por ser reciente
                
                win_probability = min(95, max(5, base_win_rate +
                    (5 if señal.get("Confidence") == "Alta" else 0) +
                    (4 if señal.get("OrderBlockRelacionado", False) else 0) +
                    (5 if señal.get("Esquema") in ["BOS", "CHoCH", "Level_Flip"] else 0) +
                    (int(flip_influence_bonus / 3)) +  # Convertir bonus de flip en probabilidad
                    (-8 if contra_tendencia else 3)))
                
                señal.update({
                    "score": round(total_score, 2),
                    "win_rate": win_probability,
                    "distancia_precio_actual": distancia,
                    "flip_influence_bonus": round(flip_influence_bonus + flip_recency_bonus + flip_proximity_bonus, 2)
                })
                
                return total_score

            # Aplicar scoring a todas las señales
            for señal in self.todas_las_senales:
                if not isinstance(señal, dict):
                    continue  # Ignora cualquier cosa que no sea un diccionario

                if 'timestamp' not in señal:
                    señal['timestamp'] = datetime.now().isoformat()
                score_signal(señal, current_price)



            # ======= SELECCIÓN DE MEJORES SEÑALES CON PRIORIDAD A FLIPS RECIENTES =======
            UMBRAL_CERCANIA = current_price * 0.0008
            
            # Separar flips recientes para priorización
            flips_recientes = [s for s in self.todas_las_senales if isinstance(s, dict) 
                    and s.get("Categoria") == "Flip" and s.get("is_recent_flip", False)]
            otras_señales = [s for s in self.todas_las_senales if isinstance(s, dict)
                    and not (s.get("Categoria") == "Flip" and s.get("is_recent_flip", False))]

            
            # Filtrar señales cercanas
            flips_cercanos = [s for s in flips_recientes if s["distancia_precio_actual"] <= UMBRAL_CERCANIA]
            otras_cercanas = [s for s in otras_señales if s["distancia_precio_actual"] <= UMBRAL_CERCANIA]
            
            # Estrategia de selección inteligente
            if flips_cercanos:
                # Priorizar flips recientes cercanos
                flips_ordenados = sorted(flips_cercanos, key=lambda s: s.get("score", 0), reverse=True)
                otras_ordenadas = sorted(otras_cercanas, key=lambda s: s.get("score", 0), reverse=True)
                
                # Combinar: 60% flips, 40% otras (mínimo 1 de cada tipo si están disponibles)
                señales_ordenadas = []
                max_flips = max(1, min(len(flips_ordenados), 3))  # Hasta 3 flips
                max_otras = max(1, 5 - max_flips)  # El resto para otras señales
                
                señales_ordenadas.extend(flips_ordenados[:max_flips])
                señales_ordenadas.extend(otras_ordenadas[:max_otras])
                
                logging.info(f"Priorizando {len(flips_ordenados[:max_flips])} flips recientes cercanos")
            else:
                # Si no hay flips cercanos, usar lógica estándar pero dar preferencia a flips en general
                if flips_recientes:
                    flips_ordenados = sorted(flips_recientes, key=lambda s: s.get("score", 0), reverse=True)
                    otras_ordenadas = sorted(otras_señales, key=lambda s: s.get("score", 0), reverse=True)
                    
                    # Mezclar inteligentemente
                    señales_ordenadas = []
                    for i in range(5):
                        if i < len(flips_ordenados):
                            señales_ordenadas.append(flips_ordenados[i])
                        if len(señales_ordenadas) < 5 and i < len(otras_ordenadas):
                            señales_ordenadas.append(otras_ordenadas[i])
                        if len(señales_ordenadas) >= 5:
                            break
                else:
                    # Sin flips, lógica estándar
                    if otras_cercanas:
                        señales_ordenadas = sorted(otras_cercanas, key=lambda s: s.get("score", 0), reverse=True)
                    else:
                        señales_ordenadas = sorted(self.todas_las_senales, key=lambda s: s.get("score", 0), reverse=True)
            
            # Seleccionar hasta 5 mejores para evaluación IA
            señales_a_evaluar = señales_ordenadas[:5]
            
            logging.info(f"Señales seleccionadas para evaluación IA: {len(señales_a_evaluar)}")
            flip_count = len([s for s in señales_a_evaluar if s.get("Categoria") == "Flip"])
            if flip_count > 0:
                logging.info(f"  - {flip_count} son flips (priorizados por ser recientes/cercanos)")
            
            # Evaluar con IA
            for señal in señales_a_evaluar:
                self.evaluar_con_modelos_ia(señal)

                    # ======= CONFIRMACIÓN CON FVG Y TESTEO MEJORADA =======
            def confirmar_con_fvg_y_testeo(señal):
                if not fvg_signals:
                    if señal.get("Categoria") == "Flip" and señal.get("is_recent_flip", False):
                        señal["ConfirmacionFVG"] = "Parcial"
                        return True
                    return False
                for fvg in fvg_signals:
                    distancia = abs(señal["Level"] - fvg["Level"])
                    max_distancia = current_price * 0.0015
                    if distancia <= max_distancia:
                        señal["ConfirmacionFVG"] = "Sí"
                        return True
                señal["ConfirmacionFVG"] = "No"
                return False

            for señal in señales_a_evaluar:
                confirmar_con_fvg_y_testeo(señal)

            # ======= GUARDADO FINAL DE DIAGNÓSTICO =======
            resultado_base.update({
                "estado": "ok",
                "mensaje": "Análisis completado",
                "señales": señales_a_evaluar
            })

            resultado_limpio = self._clean_for_json(resultado_base)
            with open("diagnostico_actual.json", "w", encoding="utf-8") as f:
                json.dump(resultado_limpio, f, indent=2, ensure_ascii=False)
            return resultado_limpio

        except Exception as e:
            logging.error(f" Error en analyze_and_report: {e}")
            traceback.print_exc()
            return {
                "estado": "error",
                "mensaje": str(e),
                "señales": [],
                "estructura_mercado": {"sibi": "none", "bisi": "none", "bos": "none", "choch": "none"}
            }
        
async def restart_bot(self):
    """Reinicia el script completo para recuperar el bot automáticamente."""
    logging.info("Reiniciando script...")
    await asyncio.sleep(5)
    python = sys.executable
    os.execl(python, python, *sys.argv)@retry(max_retries=3, delay=5)
async def get_candles_three_timeframes(api, symbol, timeframe1, timeframe2, timeframe3, period):
    """Obtiene datos de velas para tres temporalidades diferentes."""
    try:
        raw_candles1 = await api.get_candles(symbol, timeframe1, period)
        raw_candles2 = await api.get_candles(symbol, timeframe2, period)
        raw_candles3 = await api.get_candles(symbol, timeframe3, period)

        def process_raw_candles(raw_data, timeframe_label):
            if not raw_data: # Handle empty list of candles
                logging.warning(f"No raw candle data received for {timeframe_label}.")
                return pd.DataFrame() # Return an empty DataFrame

            df = pd.DataFrame.from_dict(raw_data)

            # Ensure 'time' column is present and convert to datetime and set as index
            if 'time' in df.columns:
                # *** FIX HERE: Remove unit='ms' as the time is already a string timestamp ***
                df['time'] = pd.to_datetime(df['time'])
                df = df.set_index('time')
                df.index.name = 'time' # Ensure index name is consistent
            else:
                logging.error(f"Missing 'time' column in {timeframe_label} candle data.")
                return pd.DataFrame() # Return empty if no time column

            # Ensure numeric columns are correct and handle potential NaNs
            numeric_cols = ['open', 'high', 'low', 'close']
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                else:
                    logging.warning(f"Missing '{col}' column in {timeframe_label} candle data.")

            # Ensure 'volume' column exists and is numeric
            if 'volume' not in df.columns:
            # Volumen sintético basado en rango de vela (más realista)
                df['volume'] = (df['high'] - df['low']) * 1000
                logging.info(f"Volumen sintético generado para {timeframe_label}")
            else:
                df['volume'] = pd.to_numeric(df['volume'], errors='coerce')

            # Llenar NaNs en volumen
            df['volume'] = df['volume'].fillna((df['high'] - df['low']) * 1000)
                        
            # Fill any remaining NaNs in numeric columns with 0 or a sensible default
            df = df.fillna(0) # Or another appropriate fill value like the previous candle's value

            # Sort by index (time) to ensure chronological order
            df = df.sort_index()

            return df

        df1 = process_raw_candles(raw_candles1, timeframe1)
        df2 = process_raw_candles(raw_candles2, timeframe2)
        df3 = process_raw_candles(raw_candles3, timeframe3)

        return df1, df2, df3

    except Exception as e:
        logging.error(f"Error obteniendo velas: {e}")
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame() # Return empty DataFrames on error
async def main(ssid):
    api = PocketOptionAsync(ssid)
    await asyncio.sleep(5)
    bot = TradingBot(api)
    await bot.run()

if __name__ == '__main__':
    # Tu SSID REAL aquí:
    ssid = '42["auth",{"session":"jvhu08qp216l4v746aau0sqn2f","isDemo":1,"uid":82503292,"platform":2}]'
    asyncio.run(main(ssid))
